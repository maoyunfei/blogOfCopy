<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Docker端口映射与容器互联]]></title>
    <url>%2Fdocker%2Fef9116e4%2F</url>
    <content type="text"><![CDATA[除了通过网络访问外，Docker还提供了两个很方便的功能来满足服务访问的基本需求：一个是允许映射容器内应用的服务端口到本地宿主主机；另一个是互联机制实现多个容器间通过容器名来快速访问。端口映射实现访问容器从外部访问容器应用在启动容器时，如果不指定对应的参数，在容器外是无法通过网络访问容器内的网络应用和服务的。当容器中运行一些网络应用，要让外部访问这些应用时，可以通过-P或-p参数来指定端口映射。当使用-P(大写)标记时，Docker会随机映射一个49000~49900的端口到内部容器开放的网络端口。-p(小写)可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有IP:HostPort:ContainerPort | IP::ContainerPort | HostPort:ContainerPort。映射所有接口地址使用HostPort:ContainerPort默认会绑定所有接口上的所有地址，多次使用-p标记可以绑定多个端口。1docker run -d -p 5000:5000 -p 3000:80 training/webapp python app.py映射到指定地址的指定端口可以使用IP:HostPort:ContainerPort格式指定映射使用一个特定地址。1docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py映射到指定地址的任意端口可以使用IP::ContainerPort格式绑定指定地址任意端口到容器端口，本地主机会自动分配一个端口。1docker run -d -p 127.0.0.1::5000 training/webapp python app.py查看映射端口配置使用docker port命令可以查看当前映射的端口配置，也可以查看到绑定的地址：1docker port nostalgic_morse 5000注意： 容器有自己的内部网络和IP地址，使用docker inspect + 容器ID可以获取容器的具体信息。互联网机制实现便捷互访容器的互联是一种让多个容器中应用进行快速交互的方式。它会在源和接收容器之间创建连接关系，接收容器可以通过容器名快速访问到源容器，而不用指定具体的IP地址。自定义容器命名连接系统依据容器的名称来执行，因此首先需要定义一个好记的容器名，虽然创建容器时系统会默认分配一个名字。使用--name标记可以为容器自定义命名：1docker run -d -P --name web training/webapp python app.py注意： 容器的名称是唯一的。如果已经命名了一个叫web的容器，当要再次使用web这个名称的时候，需要先用docker rm来删除之前创建的同名容器。容器互联使用--link参数可以让容器之间安全地进行交互。--link参数的格式为--link name:alias，其中name是要连接的容器名称，alias是这个连接的别名。新建一个web容器，并将它连接到db容器：1docker run -d -P --name web --link db:db training/webapp python app.py使用docker ps可以看到db容器的names列有db，也有web/db，这表示web容器连接到db容器，这允许web容器访问db容器的信息。Docker相当于在两个互联的容器之间创建了一个虚机通道，而且不用映射它们的端口到宿主机上。docker通过两种方式来为容器公开连接信息更新环境变量更新/etc/hosts文件使用env命令来查看web容器的环境变量：1234567$ docker run -rm --name web --link db:db training/webapp env...DB_NAME=/web2/dbDB_PORT=tcp://172.17.0.5:5432DB_PORT_5000_TCP=tcp://172.17.0.5:5432DB_PORT_5000_TCP_PROTO=tcp...其中DB_开头的环境变量是供web容器连接db容器使用的，前缀采用大写的连接别名。除了环境变量之外，Docker还添加host信息到父容器的/etc/hosts文件。下面是父容器web的hosts文件：12345$ docker run -rm --name web --link db:db training/webapp /bin/bash$ cat /etc/hosts172.17.0.7 aed84ee21bde...172.17.0.5 db这里有两个hosts信息，第一个是web容器，web容器用自己的id作为默认主机名，第二个是db容器的IP和主机名。用户可以连接多个子容器到父容器。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查找给定值的k个最接近的元素]]></title>
    <url>%2Falgorithms%2Fbf55dfa7%2F</url>
    <content type="text"><![CDATA[查找给定值的k个最接近的元素给定一个有序数组arr[]和一个值X，在arr[]中找到与X最接近的k个元素。请注意，如果元素存在于数组中，则不应该输出，只需要其他最接近的元素。算法思路：首先用二分搜索找到最接近X的交叉点（交叉点之前的元素小于或等于X，之后的元素大于或等于X）。这一步需要$O\left( \log n\right)$次。一旦我们找到交叉点，我们可以比较交叉点两侧的元素来打印k个最接近的元素。这一步需要$O\left( k\right)$次。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677 // Java program to find k closest elements to a given valuepublic class KClosest &#123; /* Function to find the cross over point (the point before which elements are smaller than or equal to x and after which greater than x)*/ int findCrossOver(int arr[], int low, int high, int x) &#123; // Base cases if (arr[high] &lt;= x) // x is greater than all return high; if (arr[low] &gt; x) // x is smaller than all return low; // Find the middle point int mid = (low + high) / 2; /* low + (high - low)/2 */ /* If x is same as middle element, then return mid */ if (arr[mid] &lt;= x &amp;&amp; arr[mid + 1] &gt;= x) return mid; /* If x is greater than arr[mid], then either arr[mid + 1] is ceiling of x or ceiling lies in arr[mid+1...high] */ if (arr[mid] &lt; x) return findCrossOver(arr, mid + 1, high, x); return findCrossOver(arr, low, mid - 1, x); &#125; // This function prints k closest elements to x in arr[]. // n is the number of elements in arr[] void printKclosest(int arr[], int x, int k, int n) &#123; // Find the crossover point int l = findCrossOver(arr, 0, n - 1, x); int r = l + 1; // Right index to search int count = 0; // To keep track of count of elements // already printed // If x equals to arr[l], then reduce left index while (l &gt;= 0 &amp;&amp; arr[l] == x) l--; // If x equals to arr[r], then increase right index while (r &lt; n &amp;&amp; arr[r] == x) r++; // Compare elements on left and right of crossover // point to find the k closest elements while (l &gt;= 0 &amp;&amp; r &lt; n &amp;&amp; count &lt; k) &#123; if (x - arr[l] &lt; arr[r] - x) System.out.print(arr[l--] + " "); else System.out.print(arr[r++] + " "); count++; &#125; // If there are no more elements on right side, then // print left elements while (count &lt; k &amp;&amp; l &gt;= 0) &#123; System.out.print(arr[l--] + " "); count++; &#125; // If there are no more elements on left side, then // print right elements while (count &lt; k &amp;&amp; r &lt; n) &#123; System.out.print(arr[r++] + " "); count++; &#125; &#125; /* Driver program to check above functions */ public static void main(String args[]) &#123; KClosest ob = new KClosest(); int arr[] = &#123;1, 2, 2, 2, 5, 6&#125;; int n = arr.length; int x = 2, k = 2; ob.printKclosest(arr, x, k, n); &#125;&#125;时间复杂度：$O\left( \log n+k\right)$]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法]]></title>
    <url>%2Falgorithms%2F735e5788%2F</url>
    <content type="text"><![CDATA[选择排序（Selection Sort）选择排序算法通过重复查找未排序部分的最小元素（考虑升序）并将其放在开头来排序数组。算法在给定数组中维护两个子数组。已经排序好的子数组剩下未排序的子数组在选择排序的每一次迭代中，挑选未排序子数组中的最小元素（考虑升序），并将其移至排序后的子数组中。123456789101112131415161718192021222324252627282930313233343536373839404142// Java program for implementation of Selection Sortclass SelectionSort&#123; void sort(int arr[]) &#123; int n = arr.length; // One by one move boundary of unsorted subarray for (int i = 0; i &lt; n-1; i++) &#123; // Find the minimum element in unsorted array int min_idx = i; for (int j = i+1; j &lt; n; j++) if (arr[j] &lt; arr[min_idx]) min_idx = j; // Swap the found minimum element with the first element int temp = arr[min_idx]; arr[min_idx] = arr[i]; arr[i] = temp; &#125; &#125; // Prints the array void printArray(int arr[]) &#123; int n = arr.length; for (int i=0; i&lt;n; ++i) System.out.print(arr[i]+" "); System.out.println(); &#125; // Driver code to test above public static void main(String args[]) &#123; SelectionSort ob = new SelectionSort(); int arr[] = &#123;64,25,12,22,11&#125;; ob.sort(arr); System.out.println("Sorted array"); ob.printArray(arr); &#125;&#125;时间复杂度：$O\left( n^{2}\right)$冒泡排序（Bubble Sort）冒泡排序通过反复交换相邻元素（如果顺序错误）来工作。123456789101112131415161718192021222324252627282930313233343536// Java program for implementation of Bubble Sortclass BubbleSort&#123; void bubbleSort(int arr[]) &#123; int n = arr.length; for (int i = 0; i &lt; n-1; i++) for (int j = 0; j &lt; n-i-1; j++) if (arr[j] &gt; arr[j+1]) &#123; // swap temp and arr[i] int temp = arr[j]; arr[j] = arr[j+1]; arr[j+1] = temp; &#125; &#125; /* Prints the array */ void printArray(int arr[]) &#123; int n = arr.length; for (int i=0; i&lt;n; ++i) System.out.print(arr[i] + " "); System.out.println(); &#125; // Driver method to test above public static void main(String args[]) &#123; BubbleSort ob = new BubbleSort(); int arr[] = &#123;64, 34, 25, 12, 22, 11, 90&#125;; ob.bubbleSort(arr); System.out.println("Sorted array"); ob.printArray(arr); &#125;&#125;优化实现： 即使数组已经有序，上述函数也会运行$O\left( n^{2}\right)$时间。如果内部循环没有引起任何交换，可以通过停止算法来优化它。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// Optimized java implementation of Bubble sort class GFG &#123; // An optimized version of Bubble Sort static void bubbleSort(int arr[], int n) &#123; int i, j, temp; boolean swapped; for (i = 0; i &lt; n - 1; i++) &#123; swapped = false; for (j = 0; j &lt; n - i - 1; j++) &#123; if (arr[j] &gt; arr[j + 1]) &#123; // swap arr[j] and arr[j+1] temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; swapped = true; &#125; &#125; // IF no two elements were // swapped by inner loop, then break if (swapped == false) break; &#125; &#125; // Function to print an array static void printArray(int arr[], int size) &#123; int i; for (i = 0; i &lt; size; i++) System.out.print(arr[i] + " "); System.out.println(); &#125; // Driver program public static void main(String args[]) &#123; int arr[] = &#123; 64, 34, 25, 12, 22, 11, 90 &#125;; int n = arr.length; bubbleSort(arr, n); System.out.println("Sorted array: "); printArray(arr, n); &#125;&#125;时间复杂度：$O\left( n^{2}\right)$插入排序（Insertion Sort）1234// Sort an arr[] of size ninsertionSort(arr, n)Loop from i = 1 to n-1.……a) Pick element arr[i] and insert it into sorted sequence arr[0…i-1]123456789101112131415161718192021222324252627282930313233343536373839404142434445// Java program for implementation of Insertion Sortclass InsertionSort&#123; /*Function to sort array using insertion sort*/ void sort(int arr[]) &#123; int n = arr.length; for (int i=1; i&lt;n; ++i) &#123; int key = arr[i]; int j = i-1; /* Move elements of arr[0..i-1], that are greater than key, to one position ahead of their current position */ while (j&gt;=0 &amp;&amp; arr[j] &gt; key) &#123; arr[j+1] = arr[j]; j = j-1; &#125; arr[j+1] = key; &#125; &#125; /* A utility function to print array of size n*/ static void printArray(int arr[]) &#123; int n = arr.length; for (int i=0; i&lt;n; ++i) System.out.print(arr[i] + " "); System.out.println(); &#125; // Driver method public static void main(String args[]) &#123; int arr[] = &#123;12, 11, 13, 5, 6&#125;; InsertionSort ob = new InsertionSort(); ob.sort(arr); printArray(arr); &#125;&#125;时间复杂度：$O\left( n^{2}\right)$链表的插入排序12341) Create an empty sorted (or result) list2) Traverse the given list, do following for every node.......a) Insert current node in sorted way in sorted or result list.3) Change head of given linked list to head of sorted (or result) list.归并排序（Merge Sort）——分治思想12345678910MergeSort(arr[], l, r)If r &gt; l 1. Find the middle point to divide the array into two halves: middle m = (l+r)/2 2. Call mergeSort for first half: Call mergeSort(arr, l, m) 3. Call mergeSort for second half: Call mergeSort(arr, m+1, r) 4. Merge the two halves sorted in step 2 and 3: Call merge(arr, l, m, r)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/* Java program for Merge Sort */class MergeSort&#123; // Merges two subarrays of arr[]. // First subarray is arr[l..m] // Second subarray is arr[m+1..r] void merge(int arr[], int l, int m, int r) &#123; int[] tmp = new int[r - l + 1]; int i = l, j = m, k = 0; while (i &lt; m &amp;&amp; j &lt;= r) &#123; if (arr[i] &lt;= arr[j]) &#123; tmp[k] = arr[i]; k++; i++; &#125; else &#123; tmp[k] = arr[j]; j++; k++; &#125; &#125; while (i &lt; m) &#123; tmp[k] = arr[i]; i++; k++; &#125; while (j &lt;= r) &#123; tmp[k] = arr[j]; j++; k++; &#125; &#125; // Main function that sorts arr[l..r] using // merge() void sort(int arr[], int l, int r) &#123; if (l &lt; r) &#123; // Find the middle point int m = (l+r)/2; // Sort first and second halves sort(arr, l, m); sort(arr , m+1, r); // Merge the sorted halves merge(arr, l, m, r); &#125; &#125; /* A utility function to print array of size n */ static void printArray(int arr[]) &#123; int n = arr.length; for (int i=0; i&lt;n; ++i) System.out.print(arr[i] + " "); System.out.println(); &#125; // Driver method public static void main(String args[]) &#123; int arr[] = &#123;12, 11, 13, 5, 6, 7&#125;; System.out.println("Given Array"); printArray(arr); MergeSort ob = new MergeSort(); ob.sort(arr, 0, arr.length-1); System.out.println("\nSorted array"); printArray(arr); &#125;&#125;时间复杂度：$O\left( n\log n\right)$链表的归并排序12345678910MergeSort(headRef)1) If head is NULL or there is only one element in the Linked List then return.2) Else divide the linked list into two halves. FrontBackSplit(head, &amp;a, &amp;b); /* a and b are two halves */3) Sort the two halves a and b. MergeSort(a); MergeSort(b);4) Merge the sorted a and b and update the head pointer using headRef. *headRef = SortedMerge(a, b);一下代码巧妙的使用两个指针移动来寻找中间节点，第一个指针每次移动一格，第二个指针每次移动两格，当第二个指针到达末尾时，第一个指针恰好到达中点。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136// Java program to illustrate merge sorted// of linkedList public class linkedList &#123; node head = null; // node a,b; static class node &#123; int val; node next; public node(int val) &#123; this.val = val; &#125; &#125; node sortedMerge(node a, node b) &#123; node result = null; /* Base cases */ if (a == null) return b; if (b == null) return a; /* Pick either a or b, and recur */ if (a.val &lt;= b.val) &#123; result = a; result.next = sortedMerge(a.next, b); &#125; else &#123; result = b; result.next = sortedMerge(a, b.next); &#125; return result; &#125; node mergeSort(node h) &#123; // Base case : if head is null if (h == null || h.next == null) &#123; return h; &#125; // get the middle of the list node middle = getMiddle(h); node nextofmiddle = middle.next; // set the next of middle node to null middle.next = null; // Apply mergeSort on left list node left = mergeSort(h); // Apply mergeSort on right list node right = mergeSort(nextofmiddle); // Merge the left and right lists node sortedlist = sortedMerge(left, right); return sortedlist; &#125; // Utility function to get the middle of the linked list node getMiddle(node h) &#123; //Base case if (h == null) return h; node fastptr = h.next; node slowptr = h; // Move fastptr by two and slow ptr by one // Finally slowptr will point to middle node while (fastptr != null) &#123; fastptr = fastptr.next; if(fastptr!=null) &#123; slowptr = slowptr.next; fastptr=fastptr.next; &#125; &#125; return slowptr; &#125; void push(int new_data) &#123; /* allocate node */ node new_node = new node(new_data); /* link the old list off the new node */ new_node.next = head; /* move the head to point to the new node */ head = new_node; &#125; // Utility function to print the linked list void printList(node headref) &#123; while (headref != null) &#123; System.out.print(headref.val + " "); headref = headref.next; &#125; &#125; public static void main(String[] args) &#123; linkedList li = new linkedList(); /* * Let us create a unsorted linked lists to test the functions Created * lists shall be a: 2-&gt;3-&gt;20-&gt;5-&gt;10-&gt;15 */ li.push(15); li.push(10); li.push(5); li.push(20); li.push(3); li.push(2); System.out.println("Linked List without sorting is :"); li.printList(li.head); // Apply merge Sort li.head = li.mergeSort(li.head); System.out.print("\n Sorted Linked List is: \n"); li.printList(li.head); &#125;&#125;堆排序（Heap Sort）堆排序是基于Binary Heap数据结构的基于比较的排序算法。它类似于我们首先找到最大元素然后和最后位置交换的选择排序。我们对剩下的元素重复相同的过程。什么是Binary HeapBinary Heap是一个完整二叉树，其中项以特殊顺序存储，使得父节点中的值比其两个子节点中的值更大（或更小）。前者称为最大堆，后者称为最小堆。堆可以用二叉树或数组表示。用数组表示Binary Heap，如果父节点存储在索引i处，则左边的孩子索引为2 * i + 1，右边的孩子索引为2 * i + 2（假设索引从0开始）。按升序排序的堆排序算法：根据输入数据构建一个最大堆。此时，最大的元素存储在堆的根。将它和堆的最后一项交换，然后将堆的大小减1。最后，heapify树的根。在堆大小大于1的情况下重复上述步骤。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// Java program for implementation of Heap Sortpublic class HeapSort&#123; public void sort(int arr[]) &#123; int n = arr.length; // Build heap (rearrange array) for (int i = n / 2 - 1; i &gt;= 0; i--) heapify(arr, n, i); // One by one extract an element from heap for (int i=n-1; i&gt;=0; i--) &#123; // Move current root to end int temp = arr[0]; arr[0] = arr[i]; arr[i] = temp; // call max heapify on the reduced heap heapify(arr, i, 0); &#125; &#125; // To heapify a subtree rooted with node i which is // an index in arr[]. n is size of heap void heapify(int arr[], int n, int i) &#123; int largest = i; // Initialize largest as root int l = 2*i + 1; // left = 2*i + 1 int r = 2*i + 2; // right = 2*i + 2 // If left child is larger than root if (l &lt; n &amp;&amp; arr[l] &gt; arr[largest]) largest = l; // If right child is larger than largest so far if (r &lt; n &amp;&amp; arr[r] &gt; arr[largest]) largest = r; // If largest is not root if (largest != i) &#123; int swap = arr[i]; arr[i] = arr[largest]; arr[largest] = swap; // Recursively heapify the affected sub-tree heapify(arr, n, largest); &#125; &#125; /* A utility function to print array of size n */ static void printArray(int arr[]) &#123; int n = arr.length; for (int i=0; i&lt;n; ++i) System.out.print(arr[i]+" "); System.out.println(); &#125; // Driver program public static void main(String args[]) &#123; int arr[] = &#123;12, 11, 13, 5, 6, 7&#125;; int n = arr.length; HeapSort ob = new HeapSort(); ob.sort(arr); System.out.println("Sorted array is"); printArray(arr); &#125;&#125;时间复杂度：$O\left( n\log n\right)$堆排序的应用对几乎排好序的（或K个排好序的）数组进行排序。求数组中的k个最大（或最小）元素。快速排序（QuickSort）——分治思想快排选择一个元素作为枢轴（pivot），并将给定的数组根据选取的枢轴分区。有许多选择枢轴不同的方式。始终选择第一个元素作为枢轴。总是选择最后一个元素作为枢轴。选择一个随机元素作为枢轴。选择中位数为枢轴。1234567891011121314151617181920212223public static void quickSort(int[] arr)&#123; qsort(arr, 0, arr.length-1);&#125;private static void qsort(int[] arr, int low, int high)&#123; if (low &lt; high)&#123; int pivot=partition(arr, low, high); //将数组分为两部分 qsort(arr, low, pivot-1); //递归排序左子数组 qsort(arr, pivot+1, high); //递归排序右子数组 &#125;&#125;private static int partition(int[] arr, int low, int high)&#123; int pivot = arr[low]; //枢轴记录 while (low&lt;high)&#123; while (low&lt;high &amp;&amp; arr[high]&gt;=pivot) --high; arr[low]=arr[high]; //交换比枢轴小的记录到左端 while (low&lt;high &amp;&amp; arr[low]&lt;=pivot) ++low; arr[high] = arr[low]; //交换比枢轴小的记录到右端 &#125; //扫描完成，枢轴到位 arr[low] = pivot; //返回的是枢轴的位置 return low;&#125;时间复杂度：$O\left( n\log n\right)$当最左元素或者最右元素被选为枢轴时，最坏情况发生在以下情形：数组已经是相同的顺序。数组已经是相反的顺序。所有元素都相等。所以尽量选择随机元素或者中间的元素或者中位数作为枢轴来避免最坏情况。Shell Sort（希尔排序）希尔排序基本思想为在直接插入排序的思想下设置一个最小增量dk,刚开始dk设置为n/2。进行插入排序，随后再让dk=dk/2,再进行插入排序，直到dk为1时完成最后一次插入排序，此时数组完成排序。1234567891011121314151617181920212223242526272829public static void shell_sort(int array[],int lenth)&#123; int temp = 0; int incre = lenth; while(true)&#123; incre = incre/2; for(int k = 0;k&lt;incre;k++)&#123; //根据增量分为若干子序列 for(int i=k+incre;i&lt;lenth;i+=incre)&#123; for(int j=i;j&gt;k;j-=incre)&#123; if(array[j]&lt;array[j-incre])&#123; temp = array[j-incre]; array[j-incre] = array[j]; array[j] = temp; &#125;else&#123; break; &#125; &#125; &#125; &#125; if(incre == 1)&#123; break; &#125; &#125;&#125;最坏时间复杂度为$O\left( n^{2}\right)$；最优时间复杂度为$O\left( n\right)$；平均时间复杂度为$O\left( n^{1.3}\right)$。辅助空间$O\left(1\right)$。稳定性：不稳定。希尔排序的时间复杂度与选取的增量有关，选取合适的增量可减少时间复杂度。]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符、字节与编码]]></title>
    <url>%2Fother%2F6d07e1bc%2F</url>
    <content type="text"><![CDATA[字符与编码的发展从计算机对多国语言的支持角度看，大致可以分为三个阶段：系统内码说明系统阶段一ASCII计算机刚开始只支持英语，其它语言不能够在计算机上存储和显示。英文 DOS阶段二ANSI编码(本地化)为使计算机支持更多语言，通常使用 0x80~0xFF 范围的 2 个字节来表示 1 个字符。比如：汉字 ‘中’ 在中文操作系统中，使用 [0xD6,0xD0] 这两个字节存储。不同的国家和地区制定了不同的标准，由此产生了 GB2312, BIG5, JIS 等各自的编码标准。这些使用 2 个字节来代表一个字符的各种汉字延伸编码方式，称为 ANSI 编码。在简体中文系统下，ANSI 编码代表 GB2312 编码，在日文操作系统下，ANSI 编码代表 JIS 编码。不同 ANSI 编码之间互不兼容，当信息在国际间交流时，无法将属于两种语言的文字，存储在同一段 ANSI 编码的文本中。中文 DOS，中文 Windows 95/98，日文 Windows 95/98阶段三UNICODE(国际化)为了使国际间信息交流更加方便，国际组织制定了 UNICODE 字符集，为各种语言中的每一个字符设定了统一并且唯一的数字编号，以满足跨语言、跨平台进行文本转换、处理的要求。Windows NT/2000/XP，Linux，Java字符串在内存中的存放方法：在 ASCII 阶段，单字节字符串使用一个字节存放一个字符（SBCS）。比如，”Bob123” 在内存中为：在使用 ANSI 编码支持多种语言阶段，每个字符使用一个字节或多个字节来表示（MBCS），因此，这种方式存放的字符也被称作多字节字符。比如，”中文123” 在中文 Windows 95 内存中为7个字节，每个汉字占2个字节，每个英文和数字字符占1个字节：在 UNICODE 被采用之后，计算机存放字符串时，改为存放每个字符在 UNICODE 字符集中的序号。目前计算机一般使用 2 个字节（16 位）来存放一个序号（DBCS），因此，这种方式存放的字符也被称作宽字节字符。比如，字符串 “中文123” 在 Windows 2000 下，内存中实际存放的是 5 个序号：一共占 10 个字节。字符，字节，字符串理解编码的关键，是要把字符的概念和字节的概念理解准确。这两个概念容易混淆，我们在此做一下区分：概念描述举例字符人们使用的记号，抽象意义上的一个符号。‘1’, ‘中’, ‘a’, ‘$’, ‘￥’, ……字节计算机中存储数据的单元，一个8位的二进制数，是一个很具体的存储空间。0x01, 0x45, 0xFA, ……ANSI字符串在内存中，如果“字符”是以 ANSI 编码形式存在的，一个字符可能使用一个字节或多个字节来表示，那么我们称这种字符串为 ANSI 字符串或者多字节字符串。“中文123”（占7字节）UNICODE字符串在内存中，如果“字符”是以在 UNICODE 中的序号存在的，那么我们称这种字符串为 UNICODE 字符串或者宽字节字符串。L”中文123”（占10字节）由于不同 ANSI 编码所规定的标准是不相同的，因此，对于一个给定的多字节字符串，我们必须知道它采用的是哪一种编码规则，才能够知道它包含了哪些“字符”。而对于 UNICODE 字符串来说，不管在什么环境下，它所代表的“字符”内容总是不变的。字符集与编码各个国家和地区所制定的不同 ANSI 编码标准中，都只规定了各自语言所需的“字符”。比如：汉字标准（GB2312）中没有规定韩国语字符怎样存储。这些 ANSI 编码标准所规定的内容包含两层含义：使用哪些字符。也就是说哪些汉字，字母和符号会被收入标准中。所包含“字符”的集合就叫做“字符集”。规定每个“字符”分别用一个字节还是多个字节存储，用哪些字节来存储，这个规定就叫做“编码”。各个国家和地区在制定编码标准的时候，“字符的集合”和“编码”一般都是同时制定的。因此，平常我们所说的“字符集”，比如：GB2312, GBK, JIS 等，除了有“字符的集合”这层含义外，同时也包含了“编码”的含义。“UNICODE 字符集” 包含了各种语言中使用到的所有“字符”。用来给 UNICODE 字符集编码的标准有很多种，比如：UTF-8, UTF-7, UTF-16, UnicodeLittle, UnicodeBig 等。常用的编码简介在这里，我们根据编码规则的特点，把所有的编码分成三类：分类编码标准说明单字节字符编码ISO-8859-1最简单的编码规则，每一个字节直接作为一个 UNICODE 字符。比如，[0xD6, 0xD0] 这两个字节，通过 iso-8859-1 转化为字符串时，将直接得到 [0x00D6, 0x00D0] 两个 UNICODE 字符，即 “ÖÐ”。反之，将 UNICODE 字符串通过 iso-8859-1 转化为字节串时，只能正常转化 0~255 范围的字符。ANSI编码GB2312,BIG5,Shift_JIS,ISO-8859-2……把 UNICODE 字符串通过 ANSI 编码转化为“字节串”时，根据各自编码的规定，一个 UNICODE 字符可能转化成一个字节或多个字节。反之，将字节串转化成字符串时，也可能多个字节转化成一个字符。比如，[0xD6, 0xD0] 这两个字节，通过 GB2312 转化为字符串时，将得到 [0x4E2D] 一个字符，即 ‘中’ 字。“ANSI 编码”的特点：1. 这些“ANSI 编码标准”都只能处理各自语言范围之内的 UNICODE 字符。2. “UNICODE 字符”与“转换出来的字节”之间的关系是人为规定的。UNICODE 编码UTF-8,UTF-16,UnicodeBig……与“ANSI 编码”类似的，把字符串通过 UNICODE 编码转化成“字节串”时，一个 UNICODE 字符可能转化成一个字节或多个字节。与“ANSI 编码”不同的是：1. 这些“UNICODE 编码”能够处理所有的 UNICODE 字符。2. “UNICODE 字符”与“转换出来的字节”之间是可以通过计算得到的。我们实际上没有必要去深究每一种编码具体把某一个字符编码成了哪几个字节，我们只需要知道“编码”的概念就是把“字符”转化成“字节” 就可以了。对于“UNICODE 编码”，由于它们是可以通过计算得到的，因此，在特殊的场合，我们可以去了解某一种“UNICODE 编码”是怎样的规则。Java中的字符与字节类型或操作Java字符char字节byteANSI字符串byte[]UNICODE字符串String字节串→字符串string = new String(bytes,&quot;encoding&quot;)字节串→字节串bytes = string.getBytes(&quot;encoding&quot;)以上需要注意: Java 中的 char 代表一个 “UNICODE 字符（宽字节字符）”]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker数据管理]]></title>
    <url>%2Fdocker%2Fc2e250ea%2F</url>
    <content type="text"><![CDATA[容器中管理数据主要有两种：数据卷：容器内数据直接映射到本地主机环境；数据卷容器：使用特定容器维护数据卷。数据卷数据卷是一个可供容器使用的特殊目录，它将主机操作系统目录直接映射进容器，类似于Linux中的mount操作。数据卷可以提供很多有用的特性，如下所示：数据卷可以在容器之间共享和重用，容器间传递数据将变得高效方便；对数据卷内数据的修改会立马生效，无论容器内操作还是本地操作；对数据卷的更新不会影响镜像，解耦了应用和数据；卷会一直存在，直到没有容器使用，可以安全地卸载它。在容器内创建一个数据卷在用docker run命令时，可以使用-v来创建一个数据卷。从此重复使用-v可以创建多个数据卷。使用training/webapp创建一个web容器，并创建一个数据卷挂载到容器的/webapp目录。1docker run -d -P --name web -v /webapp training/webapp python app.py挂载一个主机目录作为数据卷(推荐)使用-v标记也可以指定挂载本地的已有目录到容器中去作为数据卷。1docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py本地目录的路径必须是绝对路径，如果目录不存在，docker会自动创建。docker挂载数据卷的默认权限是读写(rw)，用户也可以通过ro指定为只读：1docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py数据卷容器如果用户需要在多个容器之间共享一些持续更新的数据，最简单的方式是使用数据卷容器。数据卷容器也是一个容器，但是它的目的是专门用来提供数据卷供其他容器挂载。创建一个数据卷容器，并在其中创建一个数据卷挂载到/dbdata:1docker run -it -v /dbdata --name dbdata ubuntu查看/dbdata目录：12$ lsbin boot dbdata dev src tec ...创建db1和db2两个容器，并从dbdata容器挂载数据卷：12docker run -it --volumes-from dbdata --name db1 ubuntudocker run -it --volumes-from dbdata --name db2 ubuntu此时，容器db1和db2都挂载同一个数据卷到相同的/dbdata目录。三个容器任何一方在该目录下的写入，其他容器都可以看见。可以多次使用--volomus-from参数来从多个容器加载多个数据卷。还可以从其他已经挂载了容器卷的容器来挂载数据卷。1docker run -d --name db3 --volumes-from db1 training/postgres注意： 使用--volumes-from参数所挂载的数据卷的容器自身并不需要保持在运行状态。如果删除了挂载的容器，数据卷并不会被自动删除。如果要删除一个数据卷，必须在删除最后一个还挂载着它的容器时显式使用docker rm -v命令来指定同时删除关联的数据卷。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搜索算法]]></title>
    <url>%2Falgorithms%2F401ea1e%2F</url>
    <content type="text"><![CDATA[Linear Search(线性搜索)问题： 给定一个有n个元素的数组，写一个函数在数组中搜索给定元素。Java实现1234567891011121314151617class LinearSearch&#123; // This function returns index of element x in arr[] static int search(int arr[], int n, int x) &#123; for (int i = 0; i &lt; n; i++) &#123; // Return the index of the element if the element // is found if (arr[i] == x) return i; &#125; // return -1 if the element is not found return -1; &#125;&#125;时间复杂度：$O\left( n\right)$Binary Search(二分查找)问题： 给定一个有n个元素的有序数组，写一个函数在数组中搜索给定元素。Java实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546// Java implementation of recursive Binary Searchclass BinarySearch&#123; // Returns index of x if it is present in arr[l.. // r], else return -1 int binarySearch(int arr[], int l, int r, int x) &#123; if (r&gt;=l) &#123; int mid = l + (r - l)/2; // If the element is present at the // middle itself if (arr[mid] == x) return mid; // If element is smaller than mid, then // it can only be present in left subarray if (arr[mid] &gt; x) return binarySearch(arr, l, mid-1, x); // Else the element can only be present // in right subarray return binarySearch(arr, mid+1, r, x); &#125; // We reach here when element is not present // in array return -1; &#125; // Driver method to test above public static void main(String args[]) &#123; BinarySearch ob = new BinarySearch(); int arr[] = &#123;2,3,4,10,40&#125;; int n = arr.length; int x = 10; int result = ob.binarySearch(arr,0,n-1,x); if (result == -1) System.out.println("Element not present"); else System.out.println("Element found at index " + result); &#125;&#125;时间复杂度：$O\left( \log n\right)$适用场景：有序Jump Search(跳跃搜索)Jump Search是用于有序数组的搜索算法。基本思想是通过以固定步长向前跳跃或跳过一些元素来代替搜索所有元素来检查更少的元素(而不是线性搜索)。例如，假设我们有一个大小为n的数组arr[]和大小为m的块（将被跳转）。然后我们搜索索引arr [0]，arr[m]，arr[2m] … ..arr[km]等等。一旦我们找到了间隔(arr[km] &lt; x &lt;arr [(k + 1)m])，我们就从索引km开始执行线性搜索操作来查找元素x。什么是最佳跳跃步长?在最坏的情况下，我们必须进行n/m跳转，并且如果最后一次选中的值大于要搜索的元素，我们将对线性搜索进行m-1比较。因此，最坏情况下的比较总数将是((n/m)+ m-1)。当m =√n时，函数的值((n/m)+m-1)最小。因此，最好的步长是m=√n。Java实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// Java program to implement Jump Search.public class JumpSearch&#123; public static int jumpSearch(int[] arr, int x) &#123; int n = arr.length; // Finding block size to be jumped int step = (int)Math.floor(Math.sqrt(n)); // Finding the block where element is // present (if it is present) int prev = 0; while (arr[Math.min(step, n)-1] &lt; x) &#123; prev = step; step += (int)Math.floor(Math.sqrt(n)); if (prev &gt;= n) return -1; &#125; // Doing a linear search for x in block // beginning with prev. while (arr[prev] &lt; x) &#123; prev++; // If we reached next block or end of // array, element is not present. if (prev == Math.min(step, n)) return -1; &#125; // If element is found if (arr[prev] == x) return prev; return -1; &#125; // Driver program to test function public static void main(String [ ] args) &#123; int arr[] = &#123; 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610&#125;; int x = 55; // Find the index of 'x' using Jump Search int index = jumpSearch(arr, x); // Print the index where 'x' is located System.out.println("\nNumber " + x + " is at index " + index); &#125;&#125;时间复杂度：$O\left( \sqrt {n}\right)$适用场景：有序Binary Search优于Jump Search，但Jump Search有一个优势，即我们只返回一次(Binary Search可能需要高达O(Log n)个跳转)。因此，在跳回成本高昂的系统中，我们使用Jump Search。Interpolation Search(插值搜索)给定一个有n个均匀分布值值的有序数组，编写一个函数来搜索数组中的特定元素。插值搜索是对二分搜索的改进，其中排序数组中的值均匀分布。二分查找总是对中间元素进行检查。插值搜索可能会根据正在搜索的值进入不同的位置。例如，如果搜索的值更接近最后一个元素，则插值搜索可能会从结尾开始搜索。要找到要搜索的位置，它使用以下公式。12345678公式的想法当要搜索的元素更接近arr[hi]，则返回较大的pos值，如果要搜索的元素更接近[lo]，则返回较小的pos值。pos = lo + [(x-arr[lo])*(hi-lo)/(arr[hi]-arr[Lo])]arr[] ==&gt; Array where elements need to be searchedx ==&gt; Element to be searchedlo ==&gt; Starting index in arr[]hi ==&gt; Ending index in arr[]Java实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// Java program to implement interpolation searchclass InterpolationSearch&#123; // Array of items on which search will // be conducted. static int arr[] = new int[]&#123;10, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 33, 35, 42, 47&#125;; // If x is present in arr[0..n-1], then returns // index of it, else returns -1. public static int interpolationSearch(int x) &#123; // Find indexes of two corners int lo = 0, hi = (arr.length - 1); // Since array is sorted, an element present // in array must be in range defined by corner while (lo &lt;= hi &amp;&amp; x &gt;= arr[lo] &amp;&amp; x &lt;= arr[hi]) &#123; // Probing the position with keeping // uniform distribution in mind. int pos = lo + (((hi-lo) / (arr[hi]-arr[lo]))*(x - arr[lo])); // Condition of target found if (arr[pos] == x) return pos; // If x is larger, x is in upper part if (arr[pos] &lt; x) lo = pos + 1; // If x is smaller, x is in lower part else hi = pos - 1; &#125; return -1; &#125; // Driver method public static void main(String[] args) &#123; int x = 18; // Element to be searched int index = interpolationSearch(x); // If element was found if (index != -1) System.out.println("Element found at index " + index); else System.out.println("Element not found."); &#125;&#125;时间复杂度：$O\left( \log \log n\right)$适用场景：有序、均匀分布Exponential Search(指数搜索)指数搜索涉及两个步骤：(1)查找元素存在的范围；(2)在上面找到的范围中进行二分查找。如何找到元素可能存在的范围？这个想法是从子数组大小1开始，比较它的最后一个元素和x，然后尝试大小2，然后是4，直到子数组的最后一个元素不会更大。 一旦我们找到了一个索引i（在重复了i次之后），我们知道该元素必须存在于i / 2和i之间（为什么是i / 2？因为我们在以前的迭代中找不到更大的值）Java实现123456789101112131415161718192021222324252627282930313233343536// Java program to find an element x in a// sorted array using Exponential search.import java.util.Arrays;class ExponentialSearch&#123; // Returns position of first ocurrence of // x in array public static int exponentialSearch(int arr[], int n, int x) &#123; // If x is present at firt location itself if (arr[0] == x) return 0; // Find range for binary search by // repeated doubling int i = 1; while (i &lt; n &amp;&amp; arr[i] &lt;= x) i = i*2; // Call binary search for the found range. return Arrays.binarySearch(arr, i/2, Math.min(i, n), x); &#125; // Driver method public static void main(String args[]) &#123; int arr[] = &#123;2, 3, 4, 10, 40&#125;; int x = 10; int result = exponentialSearch(arr, arr.length, x); System.out.println((result &lt; 0) ? "Element is not present in array" : "Element is present at index " + result); &#125;&#125;时间复杂度：$O\left( \log n\right)$适用场景：有序当目标元素更靠近开始位置时，Exponential Search优于Binary Search。]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker容器相关命令]]></title>
    <url>%2Fdocker%2Ffab65d8b%2F</url>
    <content type="text"><![CDATA[Docker容器的常用命令如下，详细信息也可以查看官方文档。新建并启动容器使用docker run命令可以新建并启动一个容器。命令格式：1docker run [OPTIONS] IMAGE [COMMAND] [ARG...]参数：参数默认值说明-d后台运行-P随机端口映射-p指定端口映射 (格式：-p hostPort:containerPort)--network指定网络模式示例：1docker run java /bin/echo 'Hello World'1docker run -d -p 91:80 nginx提醒：使用docker run命令创建容器时，会先检查本地是否存在指定镜像。如果本地不存在该名称的镜像，Docker就会自动从Docker Hub下载镜像并启动一个Docker容器。列出容器使用docker ps命令列出运行中的容器。命令格式：1docker ps [options]参数：参数默认值说明--all , -afalse列出所有容器(包括未运行的)--filter , -f根据条件过滤--last , -n-1显示最近创建的n个容器(无论状态)--no-truncfalse不截断输出--quite , -qfalse静默模式，只显示容器ID--size , -sfalse显示总文件大小示例：1docker ps -n 101docker ps -a -q停止容器使用docker stop命令可以停止容器。命令格式：1docker stop [options] CONTAINER [CONTAINER...]参数：参数默认值说明--time , -t10杀死容器前等待其停止的时间，单位是秒示例：12docker stop 784fd3b294d7docker stop nginx强行停止容器使用docker kill命令强行停止容器命令格式：1docker kill [options] CONTAINER [CONTAINER...]参数：参数默认值说明--siginal , -sKILL向容器发送信号示例：12docker kill 784fd3b294d7docker kill nginx启动已停止容器使用docker start命令可以启动已停止的容器。命令格式：1docker start [options] CONTAINER [CONTAINER...]示例：12docker start 784fd3b294d7docker start nginx重启容器使用docker restart命令可以重启容器。实际上是先执行了docker stop命令，然后再执行docker start命令。命令格式：1docker restart [options] CONTAINER [CONTAINER...]参数：参数默认值说明--time , -t10杀死容器前等待其停止的时间，单位是秒示例：12docker restart 784fd3b294d7docker restart nginx进入容器有多种方式进入容器，最简单的方式是使用docker exec命令。命令格式：1docker exec -it 容器ID /bin/bash示例：1docker exec -it 784fd3b294d7 /bin/bash删除容器使用docker rm命令可以删除容器。命令格式：1docker rm [options] CONTAINER [CONTAINER...]参数：参数默认值说明--force , -ffalse通过SIGKILL信号强制删除正在运行中的容器--link , -lfalse删除容器间的网络连接--volumes , -vfalse删除与容器关联的卷示例：12docker rm 784fd3b294d7docker rm -f nginx删除所有的容器:1docker rm -f $&#123;docker ps -a -q&#125;]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker镜像相关命令]]></title>
    <url>%2Fdocker%2F7dd9962d%2F</url>
    <content type="text"><![CDATA[Docker镜像的常用命令如下，详细信息也可以查看官方文档。搜索镜像使用docker search命令可以搜索远端仓库共享的镜像，默认是Docker Hub中的镜像。命令格式：1docker search [options] TERM参数：参数默认值说明--automatedfalse仅显示自动构建的镜像--filter , -f根据指定条件过滤--limit25搜索结果的最大条数--no-truncfalse输出信息不截断显示--stars , -s0仅显示star大于指定星级的镜像，0表示输出所有镜像示例：1docker search nginx1docker search -s 10 nginx下载镜像使用docker pull命令直接从Docker Hub下载镜像。命令格式：1docker pull [options] NAME[:TAG]其中，NAME是镜像仓库的名称，TAG是镜像的标签。通常情况下，描述一个镜像需要包括“名称+标签”信息。参数：参数默认值说明--all-tags , -afalse下载所有标签的镜像--disable-content-trustfalse忽略镜像内容校验示例：1docker pull nginx如果不指定TAG，默认下载镜像的最新版本。1docker pull myregistry.com/nginx:tag1列出镜像使用docker images命令可以列出本机上已有镜像的基本信息。命令格式：1docker images [options] [REPOSITORY[:TAG]]参数：参数默认值说明--all , -afalse列出所有镜像(包括隐藏中间层镜像)--digestsfalse显示摘要信息--filter , -f显示满足条件的镜像--format使用Go语言模板文件展示镜像--no-truncfalse输出信息不截断显示--quite , -qfalse只显示镜像ID示例：123456docker imagesdocker images nginxdocker images nginx:tag1docker images --digestsdocker images --filter "dangling=true"docker images --format "table &#123;&#123;.ID&#125;&#125;\t&#123;&#123;.Repository&#125;&#125;\t&#123;&#123;.Tag&#125;&#125;"添加标签使用docker tag命令为本地镜像添加新的标签命令格式：1docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]示例：123docker tag 0e5574283393 fedora/httpd:version1.0docker tag httpd fedora/httpd:version1.0docker tag httpd:test fedora/httpd:version1.0.test删除镜像使用docker rmi命令可以删除指定镜像。命令格式：1docker rmi [options] IMAGE [IMAGE...]参数：参数默认值说明--force, -ffalse强制删除--no-prunefalse不移除该镜像的过程镜像，默认移除示例：12docker rmi nginxdocker rmi $&#123;ID&#125;删除所有镜像:1docker rmi $(docker images)构建镜像通过Dockerfile构建镜像。命令格式：1docker build [options] path | url | -参数：参数默认值说明--file, -f指定Dockerfile的名称，默认是‘PATH/Dockerfile’--no-prunefalse不移除该镜像的过程镜像，默认移除]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 8新特性之Date/Time API]]></title>
    <url>%2Fjava%2F7dd3efa4%2F</url>
    <content type="text"><![CDATA[在Java 8以前，日期和时间处理一直被广大java程序员抱怨太难用，首先是java.util和java.sql中，都包含Date类，如果要处理由java.text.DateFormat类处理。同时java.util.Date中既包含了日期，又包含了时间，所以java 8新的日期和时间库，很好的解决了以前日期和时间类的很多弊端。并且也借鉴了第三方库joda很多的优点。对比旧的日期APIJava.timejava.util.Calendar以及Date流畅的API不流畅的API实例不可变实例可变线程安全非线程安全新API介绍1、主要的类:java.time包下的类：123456789Instant：时间戳 Duration：持续时间，时间差 LocalDate：只包含日期，比如：2016-10-20 LocalTime：只包含时间，比如：23:12:10 LocalDateTime：包含日期和时间，比如：2016-10-20 23:14:21 Period：时间段 ZoneOffset：时区偏移量，比如：+8:00 ZonedDateTime：带时区的时间 Clock：时钟，比如获取目前美国纽约的时间以及java.time.format包下的类：1DateTimeFormatter：时间格式化2、主要的类的值的格式:3、通过例子来看如何使用java8新的日期时间库(1) 获取今天的日期1234LocalDate todayDate = LocalDate.now();System.out.println("今天的日期："+todayDate);//结果今天的日期：2016-10-20(2) 指定日期，进行相应操作123456789101112131415161718192021222324252627//取2016年10月的第1天LocalDate firstDay = oneday.with(TemporalAdjusters.firstDayOfMonth());System.out.println(firstDay); //取2016年10月的第1天，另外一种写法LocalDate firstDay2 = oneday.withDayOfMonth(1);System.out.println(firstDay2); //取2016年10月的最后1天，不用考虑大月，小月，平年，闰年LocalDate lastDay = oneday.with(TemporalAdjusters.lastDayOfMonth());System.out.println(lastDay); //当前日期＋1天LocalDate tomorrow = oneday.plusDays(1);System.out.println(tomorrow);//判断是否为闰年boolean isLeapYear = tomorrow.isLeapYear();System.out.println(isLeapYear);//运行结果2016-10-202016-10-012016-10-012016-10-312016-10-21true(3) 生日检查或者账单日检查123456789101112开发过程中，经常需要为过生日的用户送上一些祝福，例如，用户的生日为1990-10-12，如果今天是2016-10-12，那么今天就是用户的生日(按公历/身份证日期来算)，那么通过java8新的日期库，我们该如何来进行判断？在java 8中，可以使用MonthDay，该类不包含年份信息，当然还有一个类是YearMonthLocalDate birthday = LocalDate.of(1990, 10, 12);MonthDay birthdayMd = MonthDay.of(birthday.getMonth(), birthday.getDayOfMonth());MonthDay today = MonthDay.from(LocalDate.of(2016, 10, 12)); System.out.println(today.equals(birthdayMd));//结果true(4) 获取当前的时间12345678910111213141516时间主要是使用LocalTime，该类不包含日期，只有时间信息//获取当前的时间LocalTime nowTime = LocalTime.now(); //结果14:29:40.558 //如果不想显示毫秒LocalTime nowTime2 = LocalTime.now().withNano(0); //14:43:14 //指定时间LocalTime time = LocalTime.of(14, 10, 21); //14:10:21LocalTime time2 = LocalTime.parse("12:00:01"); // 12:00:01 //当前时间增加2小时LocalTime nowTimePlus2Hour = nowTime.plusHours(2); //16:47:23.144//或者LocalTime nowTimePlus2Hour2 = nowTime.plus(2, ChronoUnit.HOURS);(5) 日期前后比较12345比较2个日期哪个在前，哪个在后，java8 LocalDate提供了2个方法，isAfter(),isBeforeLocalDate today = LocalDate.now();LocalDate specifyDate = LocalDate.of(2015, 10, 20);System.out.println(today.isAfter(specifyDate)); //true(6) 处理不同时区的时间12345678910111213141516java8中，将日期、时间，时区都很好的进行了分离。//查看当前的时区ZoneId defaultZone = ZoneId.systemDefault();System.out.println(defaultZone); //Asia/Shanghai //查看美国纽约当前的时间ZoneId america = ZoneId.of("America/New_York");LocalDateTime shanghaiTime = LocalDateTime.now();LocalDateTime americaDateTime = LocalDateTime.now(america);System.out.println(shanghaiTime); //2016-11-06T15:20:27.996System.out.println(americaDateTime); //2016-11-06T02:20:27.996 ，可以看到美国与北京时间差了13小时 //带有时区的时间ZonedDateTime americaZoneDateTime = ZonedDateTime.now(america);System.out.println(americaZoneDateTime); //2016-11-06T02:23:44.863-05:00[America/New_York](7) 比较两个日期之前时间差123456789101112131415161718在项目中，经常需要比较两个日期之间相差几天，或者相隔几个月，我们可以使用java8的Period来进行处理。LocalDate today = LocalDate.now();LocalDate specifyDate = LocalDate.of(2015, 10, 2);Period period = Period.between(specifyDate, today);System.out.println(period.getDays()); //4System.out.println(period.getMonths()); //1System.out.println(specifyDate.until(today, ChronoUnit.DAYS)); //401//输出结果41401我们可以看到，我们使用Period类比较天数，但它返回的值，并不是2个日期之间总共的天数差，而是一个相对天数差，比如5月1日和10月2日，他比较的是仅仅2个天之间的差，那1号和2号，相差1天，而实际上，因为中间相差了好几个月，所以真正的天数差肯定不是1天，所以我们可以使用until，并指明精度单位是days，就可以计算真正的天数差了。(8) 日期时间格式解析、格式化12345678910111213141516在java8之前，我们进行时间格式化主要是使用SimpleDateFormat，而在java8中，主要是使用DateTimeFormatter，java8中，预定义了一些标准的时间格式，我们可以直接将时间转换为标准的时间格式：String specifyDate = "20151011";DateTimeFormatter formatter = DateTimeFormatter.BASIC_ISO_DATE;LocalDate formatted = LocalDate.parse(specifyDate,formatter); System.out.println(formatted); //输出2015-10-11当然，很多时间标准的时间格式可能也不满足我们的要求，我们需要转为自定义的时间格式DateTimeFormatter formatter2 = DateTimeFormatter.ofPattern("YYYY MM dd");System.out.println(formatter2.format(LocalDate.now()));//结果2015 10 11(9) java8 时间类与Date类的相互转化1234567891011121314151617181920212223在转换中，我们需要注意，因为java8之前Date是包含日期和时间的，而LocalDate只包含日期，LocalTime只包含时间，所以与Date在互转中，势必会丢失日期或者时间，或者会使用起始时间。如果转LocalDateTime，那么就不存在信息误差。//Date与Instant的相互转化Instant instant = Instant.now();Date date = Date.from(instant);Instant instant2 = date.toInstant(); //Date转为LocalDateTimeDate date2 = new Date();LocalDateTime localDateTime2 = LocalDateTime.ofInstant(date2.toInstant(), ZoneId.systemDefault()); //LocalDateTime转DateLocalDateTime localDateTime3 = LocalDateTime.now();Instant instant3 = localDateTime3.atZone(ZoneId.systemDefault()).toInstant();Date date3 = Date.from(instant);//LocalDate转Date//因为LocalDate不包含时间，所以转Date时，会默认转为当天的起始时间，00:00:00LocalDate localDate4 = LocalDate.now();Instant instant4 = localDate4.atStartOfDay().atZone(ZoneId.systemDefault()).toInstant();Date date4 = Date.from(instant);]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java 8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 8新特性之函数式接口和Lambda表达式]]></title>
    <url>%2Fjava%2Fc8f73c32%2F</url>
    <content type="text"><![CDATA[面向对象并不坏，但它给程序带来了很多冗长的内容。例如，假设我们要创建一个Runnable的实例。通常我们使用下面的匿名类来完成它：123456Runnable r = new Runnable() &#123; @Override public void run() &#123; System.out.println("My Runnable"); &#125; &#125;;如果你看看上面的代码，实际使用的部分是 run() 方法中的代码。其余所有的代码是因为Java程序的结构化方式。Java 8函数式接口和Lambda表达式通过删除大量的样板代码，帮助我们编写更少、更简洁的代码。函数式接口具有一个抽象方法的接口称为函数式接口。添加了@FunctionalInterface注解，以便我们可以将接口标记为函数式接口。使用它不是强制性的，但最好的做法是将它与函数式接口一起使用，以避免意外添加额外的方法。如果接口使用@FunctionalInterface注解进行注释，并且我们尝试使用多个抽象方法，则会引发编译器错误。Java 8函数式接口的主要好处是我们可以使用lambda表达式来实例化它们，避免使用笨重的匿名类实现。Java 8 Collections API已被重写，并引入了新的Stream API，它使用了许多函数式接口。 Java 8在java.util.function包中定义了很多函数式接口。一些有用的java 8函数式接口如Consumer、Supplier、Function和Predicate。java.lang.Runnable是使用单一抽象方法 run() 的函数式接口的一个很好的例子。下面的代码片段为函数式接口提供了一些指导：1234567891011121314151617181920212223242526272829303132333435363738394041424344interface Foo &#123; boolean equals(Object obj); &#125;// Not functional because equals is already an implicit member (Object class)interface Comparator&lt;T&gt; &#123; boolean equals(Object obj); int compare(T o1, T o2);&#125;// Functional because Comparator has only one abstract non-Object methodinterface Foo &#123; int m(); Object clone();&#125;// Not functional because method Object.clone is not publicinterface X &#123; int m(Iterable&lt;String&gt; arg); &#125;interface Y &#123; int m(Iterable&lt;String&gt; arg); &#125;interface Z extends X, Y &#123;&#125;// Functional: two methods, but they have the same signatureinterface X &#123; Iterable m(Iterable&lt;String&gt; arg); &#125;interface Y &#123; Iterable&lt;String&gt; m(Iterable arg); &#125;interface Z extends X, Y &#123;&#125;// Functional: Y.m is a subsignature &amp; return-type-substitutableinterface X &#123; int m(Iterable&lt;String&gt; arg); &#125;interface Y &#123; int m(Iterable&lt;Integer&gt; arg); &#125;interface Z extends X, Y &#123;&#125;// Not functional: No method has a subsignature of all abstract methodsinterface X &#123; int m(Iterable&lt;String&gt; arg, Class c); &#125;interface Y &#123; int m(Iterable arg, Class&lt;?&gt; c); &#125;interface Z extends X, Y &#123;&#125;// Not functional: No method has a subsignature of all abstract methodsinterface X &#123; long m(); &#125;interface Y &#123; int m(); &#125;interface Z extends X, Y &#123;&#125;// Compiler error: no method is return type substitutableinterface Foo&lt;T&gt; &#123; void m(T arg); &#125;interface Bar&lt;T&gt; &#123; void m(T arg); &#125;interface FooBar&lt;X, Y&gt; extends Foo&lt;X&gt;, Bar&lt;Y&gt; &#123;&#125;// Compiler error: different signatures, same erasureLambda表达式由于在函数式接口中只有一个抽象函数，因此在将该lambda表达式应用于该方法时不会出现混淆。 Lambda表达式的语法是 (argument) -&gt; (body)。现在来看看如何使用lambda表达式写上面的匿名Runnable:1Runnable r1 = () -&gt; System.out.println("My Runnable");让我们试着了解上面的lambda表达式中发生了什么。Runnable是一个函数式接口，这就是为什么我们可以使用lambda表达式来创建它的实例。由于 run() 方法没有参数，我们的lambda表达式也没有参数。就像if-else块一样，我们可以避免大括号({})，因为我们在方法体中只有单个语句。对于多个语句，我们必须像使用其他方法一样使用花括号。为什么我们需要Lambda表达式1、减少代码行数使用lambda表达式的一个明显优势是代码量减少了，我们已经看到，我们可以轻松地使用lambda表达式而不是使用匿名类来创建函数接口的实例。2、顺序和并行执行支持使用lambda表达式的另一个好处是我们可以从Stream API顺序和并行操作支持中受益。为了解释这一点，我们举一个简单的例子，我们需要编写一个方法来测试一个数字是否是素数。12345678//Traditional approachprivate static boolean isPrime(int number) &#123; if(number &lt; 2) return false; for(int i=2; i&lt;number; i++)&#123; if(number % i == 0) return false; &#125; return true;&#125;上述代码的问题在于它本质上是顺序的，如果数字非常大，那么它将花费大量时间。代码的另一个问题是有太多的退出点使其可读性差。123456//Declarative approachprivate static boolean isPrime(int number) &#123; return number &gt; 1 &amp;&amp; IntStream.range(2, number).noneMatch( index -&gt; number % index == 0);&#125;为了提高可读性，我们也可以编写如下的方法。1234567private static boolean isPrime(int number) &#123; IntPredicate isDivisible = index -&gt; number % index == 0; return number &gt; 1 &amp;&amp; IntStream.range(2, number).noneMatch( isDivisible);&#125;3、将行为传递给方法我们来看看如何使用lambda表达式来传递一个方法的行为。假设我们必须编写一个方法来对列表中的数字求和，如果它们符合给定的条件。我们可以使用Predicate并编写如下的方法。123456public static int sumWithCondition(List&lt;Integer&gt; numbers, Predicate&lt;Integer&gt; predicate) &#123; return numbers.parallelStream() .filter(predicate) .mapToInt(i -&gt; i) .sum(); &#125;使用示例：123456//sum of all numberssumWithCondition(numbers, n -&gt; true)//sum of all even numberssumWithCondition(numbers, i -&gt; i%2==0)//sum of all numbers greater than 5sumWithCondition(numbers, i -&gt; i&gt;5)4、使用惰性求值效率更高使用lambda表达式的另一个优点是惰性求值(lazy evaluation)。假设我们需要编写一个方法来找出3到11范围内的最大奇数并返回它的平方。通常我们会为此方法编写如下代码：123456789private static int findSquareOfMaxOdd(List&lt;Integer&gt; numbers) &#123; int max = 0; for (int i : numbers) &#123; if (i % 2 != 0 &amp;&amp; i &gt; 3 &amp;&amp; i &lt; 11 &amp;&amp; i &gt; max) &#123; max = i; &#125; &#125; return max * max; &#125;上面的程序总是按顺序运行，但我们可以使用Stream API来实现这一点，并获得Laziness-seeking的好处。我们来看看如何使用Stream API和lambda表达式以函数式编程方式重写此代码。123456789101112131415161718192021public static int findSquareOfMaxOdd(List&lt;Integer&gt; numbers) &#123; return numbers.stream() .filter(NumberTest::isOdd) //Predicate is functional interface and .filter(NumberTest::isGreaterThan3) // we are using lambdas to initialize it .filter(NumberTest::isLessThan11) // rather than anonymous inner classes .max(Comparator.naturalOrder()) .map(i -&gt; i * i) .get(); &#125; public static boolean isOdd(int i) &#123; return i % 2 != 0; &#125; public static boolean isGreaterThan3(int i)&#123; return i &gt; 3; &#125; public static boolean isLessThan11(int i)&#123; return i &lt; 11; &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java 8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 8新特性之接口的默认方法和静态方法]]></title>
    <url>%2Fjava%2F6376aac3%2F</url>
    <content type="text"><![CDATA[Java 8接口新特性包括接口中的静态方法和默认方法。在Java 8之前，我们只能在接口中使用方法声明。但是从Java 8开始，我们可以在接口中使用默认方法和静态方法。默认方法为了在java接口中创建一个默认方法，我们需要在方法签名中使用“default”关键字。例如，12345678public interface Interface1 &#123; void method1(String str); default void log(String str)&#123; System.out.println("I1 logging::"+str); &#125;&#125;注意到 log(String str) 是Interface1中的默认方法。现在当一个类实现Interface1时，并不强制为接口的默认方法提供实现。这个特性将帮助我们扩展接口和其他方法，我们所需要的只是提供一个默认实现。另一个接口定义如下：123456789public interface Interface2 &#123; void method2(); default void log(String str)&#123; System.out.println("I2 logging::"+str); &#125;&#125;我们知道Java不允许我们继承多个类，因为它会导致“钻石问题”，因为编译器无法决定使用哪个超类方法。使用默认方法，”钻石问题”也会出现在接口上。因为如果一个类同时实现了Interface1和Interface2并且没有实现通用的默认方法，编译器无法决定选择哪一个。(备注：The diamond problem)实现多个接口是Java不可或缺的组成部分，可以在核心Java类以及大多数企业应用程序和框架中找到它。所以为了确保这个问题不会发生在接口中，必须为通用的接口默认方法提供实现。因此，如果一个类正在实现上述两个接口，它将不得不为 log() 方法提供实现，否则编译器将抛出编译时错误。一个同时实现Interface1和Interface2的简单类如下：12345678910111213141516public class MyClass implements Interface1, Interface2 &#123; @Override public void method2() &#123; &#125; @Override public void method1(String str) &#123; &#125; @Override public void log(String str)&#123; System.out.println("MyClass logging::"+str); Interface1.print("abc"); &#125;&#125;有关java接口默认方法的重点：Java 8接口的默认方法将帮助我们扩展接口，而不用担心会破坏实现类。Java 8接口默认方法弥合了接口和抽象类之间的差异。Java 8接口的默认方法将帮助我们避免utility类，比如所有的Collections类方法都可以在接口本身中提供。Java接口的默认方法将帮助我们去除基础实现类，我们可以提供默认的实现，实现类可以选择重写哪一个。在接口中引入默认方法的主要原因之一是增强Java 8中的Collections API以支持lambda表达式。如果层次结构中的任何类具有相同签名的方法，则默认方法变得不相关。默认方法不能从java.lang.Object中覆盖方法。推理非常简单，这是因为Object是所有java类的基类。所以即使我们把Object类的方法定义为接口中的默认方法，也是无用的，因为总是使用Object类的方法。这就是为什么要避免混淆，我们不能有覆盖Object类方法的默认方法。Java接口默认方法也被称为Defender方法或虚拟扩展方法。静态方法接口静态方法和默认方法类似，除了我们不能在实现类中override它们。这个特性有助于我们避免在实现类中由于不好的实现导致的不当结果。12345678910111213public interface MyData &#123; default void print(String str) &#123; if (!isNull(str)) System.out.println("MyData Print::" + str); &#125; static boolean isNull(String str) &#123; System.out.println("Interface Null Check"); return str == null ? true : "".equals(str) ? true : false; &#125;&#125;现在来看一个实现类，该类具有 isNull() 方法，但实现效果较差。1234567891011121314public class MyDataImpl implements MyData &#123; public boolean isNull(String str) &#123; System.out.println("Impl Null Check"); return str == null ? true : false; &#125; public static void main(String args[])&#123; MyDataImpl obj = new MyDataImpl(); obj.print(""); obj.isNull("abc"); &#125;&#125;注意 isNull(String str) 是一种简单的类方法，它不会覆盖接口方法。例如，如果我们将@Override注释添加到 isNull() 方法，则会导致编译器错误。现在，当我们运行应用程序时，我们得到以下输出:12Interface Null CheckImpl Null Check如果我们将接口方法从静态变为默认，我们将得到以下输出:123Impl Null CheckMyData Print::Impl Null CheckJava接口静态方法仅对接口方法可见，如果我们从 MyDataImpl 类中移除 isNull() 方法，我们将无法将其用于 MyDataImpl 对象。像其他静态方法一样，我们可以使用类名调用接口静态方法。例如：1boolean result = MyData.isNull("abc");有关java接口静态方法的重点：Java接口的静态方法是接口的一部分，我们不能用它来实现类对象。Java接口静态方法适用于提供utility方法，例如空检查，集合排序等。Java接口静态方法通过不允许实现类override它们来帮助我们提供安全性。我们不能为Object类方法定义接口静态方法，因为“这个静态方法不能从Object隐藏实例方法”，我们会得到编译器错误。这是因为它在java中是不允许的，因为Object是所有类的基类，我们不能有一个类级静态方法和另一个具有相同签名的实例方法。我们可以使用java接口的静态方法来移除Collections等utility类，并将它的所有静态方法移到相应的接口中，这很容易找到和使用。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java 8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊JVM的年轻代]]></title>
    <url>%2Fjava%2F24b8c8d9%2F</url>
    <content type="text"><![CDATA[本文章来源于并发编程网堆内存模型大致如下：1. 为什么会有年轻代我们先来屡屡，为什么需要把堆分代？不分代不能完成他所做的事情么？其实不分代完全可以，分代的唯一理由就是优化GC性能。你先想想，如果没有分代，那我们所有的对象都在一块，GC的时候我们要找到哪些对象没用，这样就会对堆的所有区域进行扫描。而我们的很多对象都是朝生夕死的，如果分代的话，我们把新创建的对象放到某一地方，当GC的时候先把这块存“朝生夕死”对象的区域进行回收，这样就会腾出很大的空间出来。2. 年轻代中的GCHotSpot JVM把年轻代分为了三部分：1个Eden区和2个Survivor区（分别叫from和to）。默认比例为 8:1:1 ( 设置较大的Eden空间和较小的Survivor空间是合理的，大大提高了内存的使用率，缓解了复制算法的缺点 )。一般情况下，新创建的对象都会被分配到Eden区(一些大对象特殊处理,直接分配到老年代),这些对象经过第一次Minor GC后，如果仍然存活，将会被移到Survivor区。对象在Survivor区中每熬过一次Minor GC，年龄就会增加1岁，当它的年龄增加到一定程度时，就会被移动到年老代中。因为年轻代中的对象基本都是朝生夕死的(80%以上)，所以在年轻代的垃圾回收算法使用的是复制算法，复制算法的基本思想就是将内存分为两块，每次只用其中一块，当这一块内存用完，就将还活着的对象复制到另外一块上面。复制算法不会产生内存碎片。在GC开始的时候，对象只会存在于Eden区和名为“From”的Survivor区，Survivor区“To”是空的。紧接着进行GC，Eden区中所有存活的对象都会被复制到“To”，而在“From”区中，仍存活的对象会根据他们的年龄值来决定去向。年龄达到一定值(年龄阈值，可以通过-XX:MaxTenuringThreshold来设置)的对象会被移动到年老代中，没有达到阈值的对象会被复制到“To”区域。经过这次GC后，Eden区和From区已经被清空。这个时候，“From”和“To”会交换他们的角色，也就是新的“To”就是上次GC前的“From”，新的“From”就是上次GC前的“To”。不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，“To”区被填满之后，会将所有对象移动到年老代中。3. 一个对象的这一辈子我是一个普通的java对象，我出生在Eden区，在Eden区我还看到和我长的很像的小兄弟，我们在Eden区中玩了挺长时间。有一天Eden区中的人实在是太多了，我就被迫去了Survivor区的“From”区，自从去了Survivor区，我就开始漂了，有时候在Survivor的“From”区，有时候在Survivor的“To”区，居无定所。直到我18岁的时候，爸爸说我成人了，该去社会上闯闯了。于是我就去了年老代那边，年老代里，人很多，并且年龄都挺大的，我在这里也认识了很多人。在年老代里，我生活了20年(每次GC加一岁)，然后被回收。4. 有关年轻代的JVM参数-XX:NewSize和-XX:MaxNewSize用于设置年轻代的大小，建议设为整个堆大小的1/3或者1/4,两个值设为一样大。-XX:SurvivorRatio用于设置Eden和其中一个Survivor的比值，这个值也比较重要。-XX:+PrintTenuringDistribution这个参数用于显示每次Minor GC时Survivor区中各个年龄段的对象的大小。-XX:InitialTenuringThreshol和-XX:MaxTenuringThreshold用于设置晋升到老年代的对象年龄的最小值和最大值，每个对象在坚持过一次Minor GC之后，年龄就加1。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型]]></title>
    <url>%2Fjava%2F91e798bc%2F</url>
    <content type="text"><![CDATA[Java虚拟机规范中试图定义一种Java内存模型(Java Memory Model, JMM)来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。主内存与工作内存Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。这里的变量与Java编程中所说的变量有所区别，它包括了实例字段、静态字段和构成数组对象的元素，但不包括局部变量与方法参数，因为后者是线程私有的，不会被共享，自然就不会存在竞争问题。Java内存模型规定了所有的变量都存储在主内存(Main Memory)中。每条线程还有自己的工作内存(Working Memory)，线程的工作内存中保存了该被线程使用到的变量的主内存副本拷贝，线程对变量的所有操作(读取、赋值等)都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成，线程、主内存、工作内存三者的交互关系如下：这里所讲的主内存、工作内存与Java内存区域中的Java堆、栈、方法区并不是同一个层次的内存划分，这两者基本上是没有关系的，如果两者一定要勉强对应起来，那从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分，而工作内存则对应于虚拟机栈中的部分数据。从更低层次上说，主内存就直接对应于物理硬件的内存，而为了获取更好的运行速度，虚拟机可能会让工作内存优先存储于寄存器和高速缓存中，因为程序运行时主要访问读写的是工作内存。内存间的交互操作关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，Java内存模型中定义了以下8种操作来完成，虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的(对于double和long类型的变量来说，load、store、read和write操作在某些平台上允许有例外)。lock(锁定)：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。unlock(解锁)：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。read(读取)：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。load(载入)：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。use(使用)：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。assign(赋值)：作用于工作内存的变量，它把一个从执行引擎收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。store(存储)：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。write(写入)：作用于工作内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。对于volatile型变量的特殊规则关键字volatile可以说是Java虚拟机提供的最轻量级的同步机制。当一个变量定义为volatile之后，它将具备两个特性，第一是保证此变量对所有线程的可见性，这里的可见性是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。虽然volatile变量在各个线程中是一致的，但是Java里面的运算并非原子操作，所以volatile变量的运算在并发下不能保证安全性。由于volatile变量只能保证可见性，在不符合以下两条规则的运算场景中，我们仍然要通过加锁(使用synchronized或java.util.concurrent中的原子类)来保证原子性。运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。变量不需要与其他的状态变量共同参与不变约束。使用volatile变量的第二个语义是禁止指令重排序优化。选用volatile的意义大多数场景下volatile的总开销要比锁低，我们在volatile与锁之中选择的唯一依据仅仅是volatile的语义能否满足使用场景的需求。对long和double型变量的特殊规则Java内存模型要求lock、unlock、read、load、assign、use、store、write这8个操作都具有原子性，但是对于64位的数据结构(long和double)，在模型中特别定义了一条相对宽松的规定：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即允许虚拟机实现选择可以不保证64位数据结构的load、store、read和write这4个操作的原子性，这点就是所谓的long和double的非原子协定。原子性、可见性与有序性原子性：可见性：有序性：先行发生原则程序次序规则：管程锁定规则：volatile变量规则：线程启动规则：线程终止规则：线程中断规则：对象终极规则：传递性：]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[垃圾收集算法]]></title>
    <url>%2Fjava%2Fba66848b%2F</url>
    <content type="text"><![CDATA[在Java运行时区域中，程序计数器、虚拟机栈、本地方法栈3个区域随线程的而生，随线程而灭，因此这几个区域的内存分配和回收都具有确定性，在这几个区域内就不需要多考虑回收的问题，因此方法结束或者线程结束时，内存自然就跟随着回收了。而Java堆和方法区则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间才能知道会创建哪些对象，这部分内存的分配都是动态的，垃圾收集器所关注的是这部分内存。1、判断对象是否“存活”1.1 引用计数法给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值减1；任何时刻计数器为0的对象就是不可能再被使用的。引用计数法的实现简单，判定效率也高，但是主流的Java虚拟机里面没有选用其来管理内存，最主要原因是它很难解决对象之间相互循环引用的问题。1.2 可达性分析算法这个算法的基本思想就是通过一系列的“GC Roots”对象作为起始点，从这些节点开始向下搜索。搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Roots没有任何引用链相连时(从图论来说，从GC Roots到这个对象不可达)，则证明此对象是不可用的。在Java语言中，可作为GC Roots的对象包括下面几种：虚拟机栈(栈帧中的本地变量表)中引用的对象。方法区中类静态属性引用的对象。方法区中常量引用的对象。本地方法栈中JNI(Native方法)引用的对象。1.3 四种引用类型引入分为强引用、软引用、弱引用、虚引用4种。强引用(Strong Reference)StringBuilder builder = new StringBuilder();强引用是默认引用类型，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。弱引用(Weak Reference)WeakReference&lt;StringBuilder&gt; weakBuilder = new WeakReference&lt;StringBuilder&gt;(builder);弱引用不是默认引用类型，如果需要使用弱引用，则要明确使用WeakReference类。弱引用用来描述非必需的对象。当内存中的对象只被弱引用时，它将可以被垃圾回收。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。软引用(Soft Reference)SoftReference&lt;StringBuilder&gt; softBuilder = new SoftReference&lt;StringBuilder&gt;(builder);软引用不是默认引用类型，如果需要使用软引用，则要明确使用SoftReference类。软引用用来描述一些还有用但是非必需的对象。对于软引用关联的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。虚引用(Phantom Reference)PhantomReference&lt;StringBuilder&gt; phantomBuilder = new PhantomReference&lt;StringBuilder&gt;(builder);虚引用不是默认引用类型，如果需要使用虚引用，则要明确使用PhantomReference类。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用的唯一目的就是能在这个对象呗收集器回收时收到一个系统通知。1.4 两次标记过程如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那么它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。 当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会放置在一个叫做F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。 这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，这样做的原因是，如果一个对象在finalize()方法中执行缓慢，或者发生了死循环，将很可能会导致F-Queue队列中其他对象永久处于等待，甚至导致整个内存回收系统崩溃。finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模标记，如果对象重新与引用链上任何一个对象建立关联，那么第二次标记时它将被移除出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的被回收了。注意： 任何一个对象的finalize()方法都只会被系统自动调用一次，如果对象面临下一次回收，它的finalize()方法不会被再次执行。1.5 回收方法区方法区的垃圾收集主要回收两部分内容：废弃常量和无用的类。 例如常量池中的字面值常量没有任何对象引用它，并且也没有其他地方引用了这个字面量，则这个变量就是废弃变量。类需要满足3个条件才能算是无用的类：(1)该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例；(2)加载该类的ClassLoader已经被回收；(3)该类对应的java.lang.Class对象没有在任何其他地方被引用，无法在任何地方通过反射访问该类的方法。虚拟机可以对废弃常量和无用的类进行回收，但并不是一定会回收，是否回收，由虚拟机提供的相关参数进行控制。2、垃圾收集算法2.1 标记-清除算法算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它的主要不足有两个：一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片。2.2 复制算法它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可。实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半。现在的商业虚拟机都采用这种收集算法来回收新生代。2.3 标记-整理算法复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低，所以一般不能用于老年代。根据老年代的特点，提出了“标记-整理”算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清除掉端边界以外的内存。2.4 分代收集算法当前商业虚拟机的垃圾收集都采用“分代收集”算法，根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清除”或者“标记-整理”算法来进行回收。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HotSpot虚拟机对象探秘]]></title>
    <url>%2Fjava%2F41b66951%2F</url>
    <content type="text"><![CDATA[以常用的虚拟机HotSpot和常用的内存区域Java堆为例，深入探讨HotSpot虚拟机在Java堆中对象分配、布局和访问全过程。1. 对象的创建（1）虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。（2）在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需内存的大小在类加载完成后便可完全确定，为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。假设Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”(Bump the Pointer)。如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间分配给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”(Free List)。选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。因此，在使用Serial、ParNew等带Compact过程的收集器时，系统采用的分配算法是指针碰撞，而使用CMS这种基于Mark-Sweep算法的收集器是，通常采用空闲列表。（3）除如何划分可用空间外，还有另一个需要考虑的问题是对象创建在虚拟机中是非常频繁的行为，即使是仅仅修改一个指针所指向的位置，在并发情况下也并不是线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。解决这个问题有两种方案，一种是对分配空间的动作进行同步处理——实际上虚拟机采用CAS配上失败重试的方式保证更新操作的原子性；另一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲(Thread Local Allocation Buffer，TLAB)。哪个线程要分配内存，就在哪个线程的TLAB上分配，只有TLAB用完并重新分配新的TLAB时，才需要同步锁定。虚拟机是否使用TLAB，可以通过-XX:+/-UseTLAB参数来设定。（4）内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值(不包括对象头)，如果使用TLAB，这一工作过程也可以提前至TLAB分配时进行。这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。（5）接下来，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例，如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息存放在对象的对象头(Object Header)之中。根据虚拟机当前的运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。（6）在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从Java程序的视角来看，对象创建才刚刚开始——\&lt;init>方法还没有执行，所有的字段都还为零。所以，一般来说，执行new指令之后会接着执行\&lt;init>方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。2. 对象的内存布局在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头(Header)、实例数据(Instance Data)和对齐填充(Padding)。HotSpot虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据，如哈希码(HashCode)、GC分待年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。对象头的另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说，查找对象的元数据信息并不一定要经过对象本身。另外，如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中缺无法确定数据的大小。接下来的实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。这部分的存储顺序会受到虚拟机分配策略参数和字段在Java源码中定义顺序的影响。第三部分对齐填充并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。由于HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说，就是对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的整数倍，因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。3. 对象的访问定位Java程序需要通过栈上的reference数据来操作堆上的具体对象。由于reference类型在Java虚拟机规范中只规定了一个指向对象的引用，并没有定义这个引用应该通过何种方式去定位、访问堆中的对象的具体位置，所以对象访问方式也是取决于虚拟机实现而定的。目前主流的访问方式有使用句柄和直接指针两种。（1）如果使用句柄访问的话，那么Java堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与数据类型各自的具体地址信息。（2）如果使用直接指针访问，那么Java堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而reference中存储的直接就是对象地址。这两种对象访问方式各有优势，使用句柄来访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而reference本身不需要修改。使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。Sun HotSpot虚拟机是使用直接指针访问方式进行对象访问的。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运行时数据区域]]></title>
    <url>%2Fjava%2F20fd51d6%2F</url>
    <content type="text"><![CDATA[Java虚拟机定义了程序执行期间使用的各种运行时数据区域。有的区域随着虚拟机的启动而存在并随着虚拟机的退出而销毁。有的数据区域是每个线程所独有的，随着线程的创建而创建并随着线程的退出而销毁。1.1 程序计数器（program counter register）程序计数器是一块较小的内存区域，它可以看作是当前线程所执行的字节码的行号指示器。为了线程切换后能恢复到正确的执行位置，每个线程都需要有一个独立的程序计数器。位于线程私有内存。如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Native方法，这个计数器值则为Undefined。此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。1.2 Java虚拟机栈(JVM Stack)每一个Java虚拟机线程都有一个私有的Java虚拟机栈，与线程同时创建。Java虚拟机栈用于存储帧(frame)。每个方法在执行的同时都会创建一个栈帧(Stack Frame)用于存储局部变量表、操作数栈、动态链接、方法出口等信息。当方法执行完成的时候，帧就被销毁了，无论方法是正常返回还是抛出未捕获的异常而中断。每一个方法从调用直至执行完成的过程，就对应一个栈帧在虚拟机栈中入栈到出栈的过程。Java虚拟机栈的内存不需要是连续的经常所说的栈内存(Stack)指的就是虚拟机栈，或者说是虚拟机栈中的局部变量表部分。局部变量表存放了编译期可知的各种基本数据类型(boolean、byte、char、short、int、float、long、double)、对象引用(reference类型，它不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置)和returnAddress类型(指向了一条字节码指令的地址)。其中64位长度的long和double类型的数据会占用2个局部变量空间(Slot)，其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。Java虚拟机栈存在以下两种异常状况：如果线程计算请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常。如果虚拟机栈可以动态扩展(当前大部分的Java虚拟机都可动态扩展)，并且尝试扩展时无法申请到足够的内存或者没有足够的内存可用于为新线程创建初始Java虚拟机栈时，将抛出OutOfMemoryError异常。1.3 本地方法栈(Native Method Stack)本地方法栈与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行Java方法(也就是字节码)服务，而本地方法栈则为虚拟机使用到的native方法服务。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。1.4 堆(Heap)对于大多数应用来说，Java堆是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程所共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。Java堆是垃圾收集器管理的主要区域，因此也被称为“GC堆”。Java堆可以位于物理上不连续的内存空间中，只要逻辑上是连续的即可。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的(通过-Xmx和-Xms控制)。如果在堆中没有足够内存完成实例分配，并且堆也无法扩展时，将会抛出OutOfMemoryError异常。1.5 方法区(Method Area)方法区是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息，例如运行时常量池、属性和方法的数据、方法和构造器的代码，以及类和接口初始化和实例初始化中使用的特殊方法。方法区不需要连续的内存，可以选择固定大小或者可扩展，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载。如果方法区的内存无法满足分配需求时，将抛出OutOfMemoryError异常。1.6 运行时常量池(Run-Time Constant Pool)Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。每一个运行时常量池都从JVM方法区分配内存，类或接口的运行时常量池是在Java虚拟机创建类或接口时构建的。运行时常量池相对于Class文件常量池的一个重要特征是具备动态性，Java语言并不要求常量一定只有编译期才能产生，也就是并非预置入Class文件中的常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的变量放入池中，这种特性被开发人员利用得比较多的便是String类的intern()方法。当创建类或接口时，如果无法从JVM方法区申请足够的内存来构造运行时常量池时，将抛出OutOfMemoryError异常。重要总结：1. 永久代的变更到废除变更(字符串常量池移到了堆)：在JDK6以及其前期的JDK版本中，永久代用于存储类信息和字符串常量池。在JDK7中，永久代只用于存储类信息，字符串常量池在堆中存储。废弃(被Metaspace取代)：在JDK7以及其前期的JDK版本中，堆内存通常被分为两块区域，新生代(younggeneration)和老年代(old generation)：显示如下图：永久代(Permanent Generation forVM Matedata)和代码缓存区(code cache area)属于非堆内存。在JDK8中把存放元数据的永久代废弃，类信息存储到了在本地内存(native memory)中叫Metaspace的区域，JDK8中JVM堆内存结构就变成了如下：2. 方法区位置变化在JDK7以及之前的版本，方法区是永久代的一部分，在JDK8中方法区是Metaspace的一部分。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hash冲突解决方案]]></title>
    <url>%2Fother%2Feebb0c54%2F</url>
    <content type="text"><![CDATA[开放地址法(open addressing)]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>hash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java String Constant Pool (Java字符串常量池)]]></title>
    <url>%2Fjava%2Fe52216a2%2F</url>
    <content type="text"><![CDATA[当你在Java中声明一个新的字符串时，在这个场景下有一些有趣的事情发生。这是一个基本的字符串声明，我们创建了一个新的字符串变量employee并给它赋值。1String employee = "Edgar Allen Poe";Java不仅会创建变量employee，而且还会为内存中的字面值“Edgar Allen Poe”分配空间。内存中的这个区域被称为字符串常量池。它就像程序的其他部分可用的字符串值池。重用字符串常量池中的值现在，如果你创建了另一个变量，比如employee2，并且还给了它一个“Edgar Allen Poe”的值，那么Java只是重用了已经在池中的值。1String employee2 = "Edgar Allen Poe";你会注意到字符串常量池位于内存的堆部分。创建一个新的字符串实例如果你创建String类的新实例，则常量池的工作方式不同。让我们创建另一个变量employee3，并给它相同的字面值。但是，这次我们将创建一个String类的新实例：1String employee3 = new String("Edgar Allen Poe");当这个代码被处理时，Java将会有所不同。而不是再次使用相同的字面值，它会在内存中创建一个新的值。在这种情况下，它不会在字符串常量池中创建它，而是在内存堆中创建它。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java -jar启动命令]]></title>
    <url>%2Fjava%2F309440ba%2F</url>
    <content type="text"><![CDATA[以下是java启动命令的语法说明:（官方文档说明）以下是[options]的说明以及一些常用的:1、Standard Options 所有运行环境都支持-D 用于设置系统变量，由于spring boot会从系统属性读取属性，所以使用@Value(&quot;myDir&quot;)即可获取。-jar 用于指定启动的jar文件，jar文件的manifest必须知道Main-Class2、Nonstandard Options 由Java HotSpot VMs默认提供-Xmn 设置新生代的大小-Xms 设置内存分配池的最小值，即初始值-Xmx 设置内存分配池的最大值对于服务器部署，-Xms和-Xmx通常设置为相同的值。以下是[arguments]说明：语法为 –{name}={value}例如：java -jar app.jar --name=&quot;Spring&quot; 。由于spring boot会从command line argument读取属性，所以使用@Value(&quot;name&quot;)即可获取。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Executor,ExecutorService和Executors间的不同]]></title>
    <url>%2Fjava%2F8542269d%2F</url>
    <content type="text"><![CDATA[文章摘录自博客java.util.concurrent.Executor, java.util.concurrent.ExecutorService, java.util.concurrent.Executors这三者均是 Java Executor 框架的一部分，用来提供线程池的功能。因为创建和管理线程非常心累，并且操作系统通常对线程数有限制，所以建议使用线程池来并发执行任务，而不是每次请求进来时创建一个线程。使用线程池不仅可以提高应用的响应时间，还可以避免&quot;java.lang.OutOfMemoryError: unable to create new native thread&quot;之类的错误。在 Java 1.5 时，开发者需要关心线程池的创建和管理，但在 Java 1.5 之后 Executor 框架提供了多种内置的线程池,例如：FixedThreadPool(包含固定数目的线程)，CachedThreadPool(可根据需要创建新的线程)等等。ExecutorExecutor，ExecutorService，和 Executors 最主要的区别是 Executor 是一个抽象层面的核心接口(大致代码如下)。123public interface Executor &#123; void execute(Runnable command);&#125;不同于java.lang.Thread类将任务和执行耦合在一起， Executor 将任务本身和执行任务分离，可以阅读 difference between Thread and Executor 来了解 Thread 和 Executor 间更多的不同。ExecutorServiceExecutorService 接口 对 Executor 接口进行了扩展，提供了返回 Future 对象，终止，关闭线程池等方法。当调用shutDown方法时，线程池会停止接受新的任务，但会完成正在 pending 中的任务。Future 对象提供了异步执行，这意味着无需等待任务执行的完成，只要提交需要执行的任务，然后在需要时检查 Future 是否已经有了结果，如果任务已经执行完成，就可以通过 Future.get( ) 方法获得执行结果。需要注意的是，Future.get( ) 方法是一个阻塞式的方法，如果调用时任务还没有完成，会等待直到任务执行结束。通过 ExecutorService.submit( ) 方法返回的 Future 对象，还可以取消任务的执行。Future 提供了 cancel()方法用来取消执行 pending 中的任务。ExecutorService 部分代码如下：123456public interface ExecutorService extends Executor &#123; void shutdown(); &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException;&#125;ExecutorsExecutors 是一个工具类，类似于 Collections。提供工厂方法来创建不同类型的线程池，比如 FixedThreadPool 或 CachedThreadPool。Executors 部分代码：123456789public class Executors &#123; public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125;&#125;Executor vs ExecutorService vs Executors正如上面所说，这三者均是 Executor 框架中的一部分。Java 开发者很有必要学习和理解他们，以便更高效的使用 Java 提供的不同类型的线程池。总结一下这三者间的区别，以便大家更好的理解：Executor 和 ExecutorService 这两个接口主要的区别是：ExecutorService 接口继承了 Executor 接口，是 Executor 的子接口Executor 和 ExecutorService 第二个区别是：Executor 接口定义了 execute()方法用来接收一个Runnable接口的对象，而 ExecutorService 接口中的 submit()方法可以接受Runnable和Callable接口的对象。Executor 和 ExecutorService 接口第三个区别是 Executor 中的 execute()方法不返回任何结果，而 ExecutorService 中的 submit()方法可以通过一个 Future 对象返回运算结果。Executor 和 ExecutorService 接口第四个区别是除了允许客户端提交一个任务，ExecutorService 还提供用来控制线程池的方法。比如：调用 shutDown()方法终止线程池。可以通过 《Java Concurrency in Practice》 一书了解更多关于关闭线程池和如何处理 pending 的任务的知识。Executors 类提供工厂方法用来创建不同类型的线程池。比如: newSingleThreadExecutor()创建一个只有一个线程的线程池，newFixedThreadPool(int numOfThreads)来创建固定线程数的线程池，newCachedThreadPool()可以根据需要创建新的线程，但如果已有线程是空闲的会重用已有线程。总结下表列出了 Executor 和 ExecutorService 的区别：ExecutorExecutorServiceExecutor 是 Java 线程池的核心接口，用来并发执行提交的任务ExecutorService 是 Executor 接口的扩展，提供了异步执行和关闭线程池的方法提供execute()方法用来提交任务提供submit()方法用来提交任务execute()方法无返回值submit()方法返回Future对象，可用来获取任务执行结果不能取消任务可以通过Future.cancel()取消pending中的任务没有提供和关闭线程池有关的方法提供了关闭线程池的方法译者注个人觉得，利用 Executors 类提供的工厂方法来创建一个线程池是很方便，但对于需要根据实际情况自定义线程池某些参数的场景，就不太适用了。举个例子：当线程池中的线程均处于工作状态，并且线程数已达线程池允许的最大线程数时，就会采取指定的饱和策略来处理新提交的任务。总共有四种策略：AbortPolicy: 直接抛异常CallerRunsPolicy: 用调用者的线程来运行任务DiscardOldestPolicy: 丢弃线程队列里最近的一个任务，执行新提交的任务DiscardPolicy 直接将新任务丢弃如果使用 Executors 的工厂方法创建的线程池，那么饱和策略都是采用默认的 AbortPolicy，所以如果我们想当线程池已满的情况，使用调用者的线程来运行任务，就要自己创建线程池，指定想要的饱和策略，而不是使用 Executors 了。所以我们可以根据需要创建 ThreadPoolExecutor(ExecutorService接口的实现类) 对象，自定义一些参数，而不是调用 Executors 的工厂方法创建。当然，在使用 Spring 框架的项目中，也可以使用 Spring 提供的 ThreadPoolTaskExecutor 类来创建线程池。ThreadPoolTaskExecutor 与 ThreadPoolExecutor 类似，也提供了许多参数用来自定义线程池，比如：核心线程池大小，线程池最大数量，饱和策略，线程活动保持时间等等。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[equals()和hashCode()]]></title>
    <url>%2Fjava%2F554520e5%2F</url>
    <content type="text"><![CDATA[原文链接默认情况下，Java超类java.lang.Object提供了两种比较对象的重要方法：equals()和hashCode()。在大型项目中实现多个类之间的交互时，这些方法变得非常有用。在本文中，我们将讨论这些方法之间的关系，它们的默认实现以及强制开发人员为每个方法提供自定义实现的情况。方法定义和默认实现123456789public class Object &#123; ... public boolean equals(Object obj) &#123; return (this == obj); &#125; ... public native int hashCode(); ...&#125;equal()方法：JDK提供的默认实现是基于内存位置的 - 当且仅当它们存储在同一个内存地址中时，两个对象是相等的。hashCode()方法：默认实现是个本地方法。需要满足三个约定：(1) 无论什么时间，在同一个应用内执行多次应该返回相同的值。(2) 如果两个对象的equals()方法返回true，那么它们的hashCode()必须相同。(3) 如果两个对象的equals()方法返回false，那么它们的hashCode()可以相同，也可以不同。重写equals()实例：12345678910111213141516171819202122package com.programmer.gate.beans;public class Student &#123; private int id; private String name; public Student(int id, String name) &#123; this.name = name; this.id = id; &#125; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125;123456789@Overridepublic boolean equals(Object obj) &#123; if (obj == null) return false; if (!(obj instanceof Student)) return false; if (obj == this) return true; return this.getId() == ((Student) obj).getId();&#125;equals() With ArrayList123456789public class HashcodeEquals &#123; public static void main(String[] args) &#123; Student alex = new Student(1, "Alex"); List &lt; Student &gt; studentsLst = new ArrayList &lt; Student &gt; (); studentsLst.add(alex); System.out.println("Arraylist size = " + studentsLst.size()); System.out.println("Arraylist contains Alex = " + studentsLst.contains(new Student(1, "Alex"))); &#125;&#125;以上代码输出为：12Arraylist size = 1Arraylist contains Alex = true原因是ArrayList的contains()方法内部是调用的对象的equals()方法。重写hashCode()1234@Overridepublic int hashCode() &#123; return id;&#125;equals() With HashSet1234567891011public class HashcodeEquals &#123; public static void main(String[] args) &#123; Student alex1 = new Student(1, "Alex"); Student alex2 = new Student(1, "Alex"); HashSet &lt; Student &gt; students = new HashSet &lt; Student &gt; (); students.add(alex1); students.add(alex2); System.out.println("HashSet size = " + students.size()); System.out.println("HashSet contains Alex = " + students.contains(new Student(1, "Alex"))); &#125;&#125;以上代码输出为：12HashSet size = 1HashSet contains Alex = trueHashSet将其元素存储在内存桶中。每个桶都链接到一个特定的哈希码。当调用students.add(alex1)时，Java在存储桶中存储alex1并将其链接到alex1.hashCode()的值。现在任何时候，一个具有相同散列码的元素被插入到集合中，它将会替换掉alex1。但是，由于alex2具有不同的散列码，它将被存储在一个单独的存储桶中，并被视为完全不同的对象。现在，当HashSet在其中搜索一个元素时，它首先生成元素的哈希码并查找与这个哈希码对应的一个桶。这同样适用于HashMap，HashTable或任何使用散列机制来存储元素的数据结构。hashCode()用于散列到桶，equals()用于判断对象是否相同。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Understanding Eureka Peer to Peer Communication]]></title>
    <url>%2Fspring%2F7b50bf88%2F</url>
    <content type="text"><![CDATA[原文链接Eureka client尝试去和相同zone的Eureka Server通信。如果相同zone的server不存在或者通信有问题，client就会转到其他zone的server。一旦服务器开始接收流量，在服务器上执行的所有操作都将被复制到服务器所知道的所有对等节点。如果某个操作由于某种原因而失败，那么该信息将在服务器之间下一次心跳时核对后复制。当Eureka server恢复，它尝试从邻居节点获取所有实例的注册信息。如果从一个节点获取信息存在问题，在它放弃之前，它将尝试所有的对等节点。如果Eureka server能够成功获取所有实例信息，则会根据该信息设置应该接收的“续约”阈值。如果任何时候，“续约”低于设置的该阈值百分比(在15分钟内低于85%),Eureka server停止过期实例来保护当前实例的注册信息。在Neflix,上面的保护称为“自我保护”模式，主要用在一组client和Eureka server之间存在网络分区的情况下的保护。在这种场景下，Eureka server尝试去保护已经拥有的信息。如果发生大规模的故障，在这种情况下，可能会导致client获得已经不存在的实例。client必须确保它们对于返回不存在或不响应的实例的Eureka server具有弹性。在这些情况下，最好的保护是快速超时并尝试其他服务器。在这种情况下，如果Eureka server无法从邻居节点获取注册表信息，则会等待几分钟（5分钟），以便客户端可以注册其信息。server尽量不提供部分信息给client，而是通过将流量倾斜到仅一组实例并会导致容量问题。如此处所述，Eureka server使用在Eureka client和server之间使用的相同机制相互通信。What happens during network outages between Peers?在peers之间失去网络通信的情况下，下列事情将发生peers之间的心跳复制可能会失败，并且Eureka server检测到这种情况然后进入自我保护模式来保护当前状态。注册可能发生在孤立的Eureka server上，有些client可能会反映新的注册信息，而其他client可能不会。(备注：由于孤立的Eureka server无法与其他server共享注册信息)在网络连接恢复到稳定状态后，情况会自动更正。当peers能够正常通信时，注册信息会自动被传输到没有这些信息的Eureka server上。(备注：即网络恢复后，Eureka server之间会自动同步共享注册信息)最重要的是，在网络中断期间，Eureka server尝试尽可能地具有弹性，但在此期间，client可能会有不同的server视图。(备注：Eureka server存在网络分区时，多个server之间无法同步注册信息，导致每个server上的信息可能不同，所以client可能会看到不同的server视图)]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Circuit Breaker--Hystrix]]></title>
    <url>%2Fspring%2Fda1cb016%2F</url>
    <content type="text"><![CDATA[1. Hystrix Clients原文链接Netflix创建了一个实现了circuit breaker模式的叫做Hystrix的库。在一个微服务架构中通常有多层的服务调用，如下图。Microservice Graph一个底层的服务失败可以导致级联的直到用户的失败。在一个由 metrics.rollingStats.timeInMilliseconds(默认10秒)定义的默认窗口内，当请求一个指定的服务次数大于circuitBreaker.requestVolumeThreshold(默认20)并且失败率大于circuitBreaker.errorThresholdPercentage(默认50%)时，断路打开，请求不会发出。在发生错误或者短路时，开发者可以提供fallback。Hystrix fallback prevents cascading failures断路阻止了级联失败，并且允许高负载或者失败的服务有时间去恢复。fallback可以是另一个Hystrix保护的调用，静态数据或者空值。fallback可能是链式的，导致第一个fallback做的一些业务调用又回退到静态数据。1.1 如何引入Hystrix1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt;12345678910111213141516171819202122@SpringBootApplication@EnableCircuitBreakerpublic class Application &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(Application.class).web(true).run(args); &#125;&#125;@Componentpublic class StoreIntegration &#123; @HystrixCommand(fallbackMethod = &quot;defaultStores&quot;) public Object getStores(Map&lt;String, Object&gt; parameters) &#123; //do stuff that might fail &#125; public Object defaultStores(Map&lt;String, Object&gt; parameters) &#123; return /* something useful */; &#125;&#125;@HystrixCommand由一个名为“javanica”的Netflix contrib库提供。Spring Cloud自动将包含该注释的Spring bean包装在连接到Hystrix断路器的代理中。断路器计算何时打开和关闭电路，以及在发生故障时该怎么办。要配置@HystrixCommand，您可以使用带有@HystrixProperty注释列表的commandProperties属性。这里查看细节。Hystrix properties。1.2 传播安全上下文或者使用Spring Scopes如果你想传播一些线程本地上下文到@HystrixCommand中，用默认声明是不起作用的，因为它在一个线程池中执行命令。当调用者使用一些配置或者直接在注解中让它去使用一个不同的隔离策略，你可以切换Hystrix去使用同一个线程。例如：123456@HystrixCommand(fallbackMethod = &quot;stubMyService&quot;, commandProperties = &#123; @HystrixProperty(name=&quot;execution.isolation.strategy&quot;, value=&quot;SEMAPHORE&quot;) &#125;)...如果使用@SessionScope或@RequestScope，则同样适用。你将知道何时需要执行此操作，因为一个运行时异常表示无法找到该scope内的上下文。你也可以设置hystrix.shareSecurityContext属性为true。这样会自动配置一个Hystrix并发策略插件，它将会把SecurityContext从你的主线程传递到Hystrix命令使用的线程。Hystrix不支持注册多个hystrix并发策略，所以可以通过声明你自己的HystrixConcurrencyStrategy bean来扩展。Spring cloud将在你的spring上下文中查找并把它封装进它自己的插件。1.3 健康指标连接断路器的状态也暴露在应用程序的/health端点中。123456789&#123; &quot;hystrix&quot;: &#123; &quot;openCircuitBreakers&quot;: [ &quot;StoreIntegration::getStoresByLocationLink&quot; ], &quot;status&quot;: &quot;CIRCUIT_OPEN&quot; &#125;, &quot;status&quot;: &quot;UP&quot;&#125;1.4 Hystrix指标流添加spring-boot-starter-actuator依赖来启用Hystrix指标流。这将暴露管理端点/hystrix.stream。1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;2. Hystrix Dashboard原文链接Hystrix的主要优点之一就是它收集的关于每个HystrixCommand的指标集合。Hystrix仪表板以高效的方式显示每个断路器的运行状况。Hystrix Dashboard3. Hystrix超时和Ribbon Client原文链接当使用Hystrix命令包装Ribbon client，你需要确保配置的Hystrix超时时间大于配置的Ribbon超时时间，包括任何潜在的重试。例如，如果你的ribbon连接超时是1秒，ribbon client可能重试3次，然后Hystrix超时应该略大于3秒。3.1 如何引入Hystrix Dashboard1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-netflix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt;运行Hystrix Dashboard使用@EnableHystrixDashboard注释Spring Boot主类。然后访问/hystrix并将仪表板指向Hystrix客户端应用程序中的单个实例的/hystrix.stream端点。提示： 连接到使用HTTPS的/hystrix.stream端点时，服务器使用的证书必须由JVM信任。如果证书不可信，你必须将证书导入到JVM中，以便Hystrix仪表板能成功连接到流终端。3.2 Turbine从单个实例来看，Hystrix数据在整个系统的健康状况方面并不是很有用。Turbine是一个应用程序，它将所有相关的/hystrix.stream端点汇总到一个用于Hystrix仪表板的组合/turbine.stream中。单个实例通过Eureka找到。运行Turbine与使用@EnableTurbine注释注释主类一样简单(例如，在classpath引入spring-cloud-starter-netflix-turbine)。来自Turbine 1 wiki)的文档配置属性都适用。唯一的区别是turbine.instanceUrlSuffix不需要预先添加端口，因为这是自动处理的，除非turbine.instanceInsertPort=false。提示： 默认情况下，Turbine在注册实例上查找/hystrix.stream端点是通过在Eureka中查找其homePageUrl条目，然后将/hystrix.stream附加到上面。这意味着如果spring-boot-actuator在自己的端口上运行（这是默认的），对/hystrix.stream的调用将失败。要使Turbine在正确的端口找到Hystrix流，你需要将management.port添加到实例的metadata：1234eureka: instance: metadata-map: management.port: $&#123;management.port:8081&#125;配置turbine.appConfig是Turbine用于查找实例的Eureka中注册的serviceId的列表。Turbine stream然后在Hystrix仪表板中使用一个类似如下的url：http://my.turbine.sever:8080/turbine.stream?cluster=&lt;CLUSTERNAME&gt;(cluster参数可以被省略，如果名称是“default”)。cluster参数必须与turbine.aggregator.clusterConfig中的条目匹配。从Eureka返回的值是大写，因此，如果有一个名为“customers”的应用程序在Eureka注册，我们预计这个例子将起作用：1234turbine: aggregator: clusterConfig: CUSTOMERS appConfig: customersclusterName可以通过turb.clusterNameExpression中的SPEL表达式来定制，指定InstanceInfo的一个实例。默认值是appName，这意味着Eureka serviceId最终作为集群key(即customers的InstanceInfo具有“CUSTOMERS”的appName)。另一个示例是turb.clusterNameExpression=aSGName，它将从AWS ASG名称获取集群名称。另一个例子：12345turbine: aggregator: clusterConfig: SYSTEM,USER appConfig: customers,stores,ui,admin clusterNameExpression: metadata[&apos;cluster&apos;]在这种情况下，来自4个服务的集群名称将从其metadata映射中提取出来，预期包含“SYSTEM”和“USER”的值。要为所有应用程序使用“default”集群，你需要一个字符串文字表达式(使用单引号，如果使用YAML，则使用双引号进行转义):123turbine: appConfig: customers,stores clusterNameExpression: &quot;&apos;default&apos;&quot;Spring Cloud提供了一个spring-cloud-starter-netflix-turbine，它拥有运行Turbine服务器所需的所有依赖。只需创建一个Spring Boot应用程序并使用@EnableTurbine对其进行注释。提示： 默认情况下，Spring Cloud允许Turbine使用主机和端口来允许每个主机，每个集群使用多个进程。如果你希望Turbine中内置的本机Netflix行为不允许每个主机，每个集群（实例id的key是主机名）都有多个进程，那么请设置属性turbine.combineHostPort=false。3.3 Turbine Stream在某些环境下（例如在PaaS设置中），从所有分布式Hystrix命令中提取指标的传统Turbine模型不起作用。在这种情况下，你可能希望让你的Hystrix命令将度量标准推送到Turbine，Spring Cloud通过消息传递来实现。你需要在客户端上执行的操作是添加依赖关系到你选择的spring-cloud-netflix-hystrix-stream和spring-cloud-starter-stream-*(有关broker和如何配置客户端凭据的详细信息，请参阅Spring Cloud Stream文档，但它应该为本地broker开箱即用)。在server端只需创建一个Spring Boot应用程序并使用@EnableTurbineStream对其进行注释，默认情况下它将在8989端口(将Hystrix仪表板指向该端口，任何路径)运行。你可以使用server.port或turbine.stream.port来自定义端口。如果在classpath中也有spring-boot-starter-web和spring-boot-starter-actuator，那么你可以通过提供一个不同的management.port，在单独的端口(默认情况下使用Tomcat)打开Actuator端点。然后你可以将Hystrix仪表板指向Turbine Stream Server，而不是单独的Hystrix流。如果Turbine Stream在myhost上的8989端口上运行，则将http:// myhost:8989放在Hystrix仪表板的流输入字段中。电路将以它们各自的serviceId为前缀，接着是一个点，然后是电路名称。Spring Cloud提供了一个spring-cloud-starter-netflix-turbine-stream，它拥有运行Turbine Stream server所需的所有依赖关系，只需添加你选择的Stream绑定程序，例如：spring-cloud-starter-stream-rabbit。你需要Java 8来运行应用程序，因为它是基于Netty的。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Understanding eureka client server communication]]></title>
    <url>%2Fspring%2F55dcd732%2F</url>
    <content type="text"><![CDATA[原文链接About Instance Statuses默认的，Eureka client开始状态是 STARTING，这为了在实例能够提供服务之前，给它做应用初始化的时间。之后应用可以加入到可提供服务中通过将状态变更为 UP。ApplicationInfoManager.getInstance().setInstanceStatus(InstanceStatus.UP)应用也可以注册健康检查的callback，这可以选择性地将实例状态变为 DOWN。在Neflix中，还有一个 OUT_ OF_ SERVICE 状态,表明该实例不可提供服务中。Eureka Client OperationsEureka client首先尝试去和相同zone的Eureka Server连接，如果它不能发现服务端，它将转向其他zone。Eureka client通过以下方式和服务端交互RegisterEurek Client向Eureka server注册运行实例的信息。注册发生在第一次心跳(在30秒之后)。RenewEureka client需要通过每30秒发送心跳来“续约”。“续约”信号告诉Eureka server该实例仍然是可用的。如果server在90秒没有收到“续约”，他将从注册列表移除该实例。不去改变“续约”周期是明智的，因为server使用这个信息去判断在client和server之间的通信是否有普遍的问题。(备注：例如网络分区问题)Fetch RegistryEureka client从server获取注册信息并缓存在本地。之后，client使用这个信息去发现其他的服务。注册信息被周期性的更新(每30秒)，通过获取上一个读取周期和当前读取周期之间的增量更新。增量信息在server中保持较长时间（约3分钟），因此增量提取可能会再次返回相同的实例。Eureka client会自动处理重复的信息。获取增量之后，Eureka client和server通过比较server返回的实例数量来比对信息，如果由于某些原因信息不匹配，整个注册信息将重新提取。Eureka server缓存压缩的增量payload、整个注册表，以及每个应用程序相同的未压缩信息。payload支持JSON和XML格式。Eureka client通过jersey apache client获取压缩的JSON格式的信息。CancelEureka client在shutdown时给Eureka server发送一个cancel请求。Eureka server将从服务的实例注册信息中移除该实例，这有效得将实例从负载中移除。(备注：通过linux命令 kill -15应用程序将收到shutdown通知，kill -9则收不到通知)当Eureka client shutdown时，应用应该保证去调用以下方法。1DiscoveryManager.getInstance().shutdownComponent()Time LagEureka client的所有操作会花费一定时间反映到Eureka server和其他的clients。这是因为Eureka server上有payload的缓存，它定期刷新以获取新的信息。Eureka client也会定期刷新增量信息。因此，这可能花费长达2分钟的时间去把变更传播到所有的Eureka client。Communication mechanism默认的，Eureka client使用Jersey,XStream技术和JSON 格式的payload去和Eureka Server交流。你也可以使用你选择的机制来覆盖默认的。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Declarative REST Client--Feign]]></title>
    <url>%2Fspring%2F2db5c206%2F</url>
    <content type="text"><![CDATA[原文链接Feign是一个声明式的web服务client。它让编写web服务客户端更简单。使用Feign需要创建一个接口并在上面加注解。它有可插拔的注解支持，包括Feign的注解和JAX-RS的注解。Feign也支持可插拔式的编码器(encoder)和解码器(decoder)。Spring Cloud增加了对Spring MVC注解的支持，并且使用了Spring Web中默认使用的HttpMessageConverters。Spring Cloud整合Ribbon和Eureka，在使用Feign时提供负载均衡的http client。1.1 如何引入Feignpom.xml1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&lt;/dependency&gt;Application.java12345678910@SpringBootApplication@EnableEurekaClient@EnableFeignClientspublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125;StoreClient.java12345678@FeignClient(&quot;stores&quot;)public interface StoreClient &#123; @RequestMapping(method = RequestMethod.GET, value = &quot;/stores&quot;) List&lt;Store&gt; getStores(); @RequestMapping(method = RequestMethod.POST, value = &quot;/stores/&#123;storeId&#125;&quot;, consumes = &quot;application/json&quot;) Store update(@PathVariable(&quot;storeId&quot;) Long storeId, Store store);&#125;在@FeignClient注解中的值“stores”是一个任意client name,被用来创建一个Ribbon负载均衡器。你也可以使用url属性来指定一个URL。在application context中的bean名称是这个接口的全限定名。你可以使用@FeignClient注解的qualifier属性来指定你自己的别名。上面的Ribbon client会去获取“stores”服务的物理地址。如果你的应用是一个Eureka client，它将解析在Eureka server注册的服务。如果你不想使用Eureka, 你可以在你的配置文件中额外配置一个服务列表。1.2 覆盖Feign默认配置Spring Cloud Feign支持的一个重要概念是named client。每个Feign client都是集合的一部分，它们一起工作来连接远程服务.作为应用开发者，你使用@FeignClient注解来给这个集合一个名字。Spring Cloud使用FeignClientsConfiguration创建一个新的集合，作为每个指定客户端的ApplicationContext。这包括feign.Decoder,feign.Encoder,feign.Contract等。通过使用@FeignClient声明额外的配置（在FeignClientsConfiguration之上），Spring Cloud可让你完全控制Ribbon client。例如：1234@FeignClient(name = &quot;stores&quot;, configuration = FooConfiguration.class)public interface StoreClient &#123; //..&#125;在这种情况下，ribbon client由已经在FeignClientsConfiguration中的组件和FooConfiguration中的任何组件（后者将覆盖前者）组成。提示： FooConfiguration不需要@Configuraion注解。(备注：这一点和ribbon client完全相反，@RibbonClient的configuration必须被@Configuration注解。)它不能在应用上下文被@ComponentScan扫描到，否则它将被所有@FeignClient所共享。(备注：在这个特性上，和RibbonClient一样)name和url属性支持占位符,例如：1234@FeignClient(name = &quot;$&#123;feign.name&#125;&quot;, url = &quot;$&#123;feign.url&#125;&quot;)public interface StoreClient &#123; //..&#125;Spring Cloud Netflix默认提供以下bean (BeanType beanName：ClassName):Decoder feignDecoder: ResponseEntityDecoder(封装的SpringDecoder)Encoder feignEncoder: SpringEncoderLogger feignLogger: Slf4jLoggerContract feignContract: SpringMvcContractFeign.Builder feignBuilder: HystrixFeign.BuilderClient feignClient: 如果ribbon开启是LoadBalancerFeignClient, 否则是默认的feign client。通过设置feign.okhttp.enabled或feign.httpclient.enabled为true，可以使用OkHttpClient和ApacheHttpClient的feign client，并将它们放到classpath。Spring Cloud Netflix默认情况下不提供以下bean，但仍从应用程序上下文中查找这些类型的bean以创建feign client：Logger.LevelRetryerErrorDecoderRequest.OptionsCollection&lt;RequestInterceptor&gt;SetterFactory创建这些类型的bean并将其放入@FeignClient配置（例如上面的FooConfiguration）就能够覆盖所描述的每个bean。例如：123456789101112@Configurationpublic class FooConfiguration &#123; @Bean public Contract feignContract() &#123; return new feign.Contract.Default(); &#125; @Bean public BasicAuthRequestInterceptor basicAuthRequestInterceptor() &#123; return new BasicAuthRequestInterceptor(&quot;user&quot;, &quot;password&quot;); &#125;&#125;这用feign.Contract.Default代替了SpringMvcContract，并且将一个RequestInterceptor添加到RequestInterceptor的集合中。@FeignClient也可以使用配置属性进行配置。application.yml12345678910111213feign: client: config: feignName: connectTimeout: 5000 readTimeout: 5000 loggerLevel: full errorDecoder: com.example.SimpleErrorDecoder retryer: com.example.SimpleRetryer requestInterceptors: - com.example.FooRequestInterceptor - com.example.BarRequestInterceptor decode404: false默认配置可以在@EnableFeignClients属性defaultConfiguration中以与上述类似的方式指定。不同的是，这个配置将适用于所有的feign client。如果你更喜欢使用配置属性来配置所有@FeignClient，则可以使用default这个feign名称来创建配置属性。application.yml1234567feign: client: config: default: connectTimeout: 5000 readTimeout: 5000 loggerLevel: basic如果我们同时创建@Configuration bean和配置属性，配置属性将会胜出。它将覆盖@Configuration的值。但是如果你想改变@Configuration的优先级，你可以把feign.client.default-to-properties设为false。提示： 如果你需要在你的RequestInterceptor中使用ThreadLocal域变量，你要么把Hystrix的thread isolation strategy设为SEMAPHORE，要么在Feign中禁用Hystrix。application.yml123456789101112# To disable Hystrix in Feignfeign: hystrix: enabled: false# To set thread isolation to SEMAPHOREhystrix: command: default: execution: isolation: strategy: SEMAPHORE1.3 手动创建Feign Client在某些情况下，可能需要在不方便使用以上方法的时自定义你的Feign Client。在这种情况下，你可以使用Feign Builder API创建client。下面是一个例子，它创建两个具有相同接口的Feign client，但用每个客户端配置了一个单独的请求拦截器。12345678910111213141516171819202122@Import(FeignClientsConfiguration.class)class FooController &#123; private FooClient fooClient; private FooClient adminClient; @Autowired public FooController( Decoder decoder, Encoder encoder, Client client) &#123; this.fooClient = Feign.builder().client(client) .encoder(encoder) .decoder(decoder) .requestInterceptor(new BasicAuthRequestInterceptor(&quot;user&quot;, &quot;user&quot;)) .target(FooClient.class, &quot;http://PROD-SVC&quot;); this.adminClient = Feign.builder().client(client) .encoder(encoder) .decoder(decoder) .requestInterceptor(new BasicAuthRequestInterceptor(&quot;admin&quot;, &quot;admin&quot;)) .target(FooClient.class, &quot;http://PROD-SVC&quot;); &#125;&#125;提示： 在上面的例子中，FeignClientsConfiguration.class是由Spring Cloud Netflix提供的默认配置。PROD-SVC是client要请求的服务的名称。1.4 Feign的Hystrix支持如果Hystrix在classpath上并且feign.hystrix.enabled=true,那么Feign将用一个断路器来包装所有的方法。返回一个com.netflix.hystrix.HystrixCommand也是可以的。这将让你使用响应式模式(调用.toObservable()或.observe()或异步使用（调用.queue())要基于每个client禁用Hystrix支持，需要创建一个具有“prototype”范围的Feign.Builder，例如：12345678@Configurationpublic class FooConfiguration &#123; @Bean @Scope(&quot;prototype&quot;) public Feign.Builder feignBuilder() &#123; return Feign.builder(); &#125;&#125;警告： 在Spring Cloud Dalston发布之前，如果Hystrix在classpath上(备注：pom.xml中有spring-cloud-starter-hystrix依赖)，Feign默认情况下会将所有方法封装在断路器中。 Spring Cloud Dalston改变了这种默认行为，赞成采用选择加入的方式。(备注：Dalston前的版本中 feign.hystrix.enabled 默认值为true，Dalston及其之后的版本中 feign.hystrix.enabled 默认值为false)1.5 Feign Hystrix FallbacksHystrix支持fallback的概念：一个默认的代码路径，在断路或出现错误时执行。为给定的@FeignClient启用fallback功能，将fallback属性设置为实现fallback的类名称。你还需要将你的实现声明为Spring bean。123456789101112@FeignClient(name = &quot;hello&quot;, fallback = HystrixClientFallback.class)protected interface HystrixClient &#123; @RequestMapping(method = RequestMethod.GET, value = &quot;/hello&quot;) Hello iFailSometimes();&#125;static class HystrixClientFallback implements HystrixClient &#123; @Override public Hello iFailSometimes() &#123; return new Hello(&quot;fallback&quot;); &#125;&#125;如果需要访问fallback触发的原因，则可以使用@FeignClient中的fallbackFactory属性。123456789101112131415161718@FeignClient(name = &quot;hello&quot;, fallbackFactory = HystrixClientFallbackFactory.class)protected interface HystrixClient &#123; @RequestMapping(method = RequestMethod.GET, value = &quot;/hello&quot;) Hello iFailSometimes();&#125;@Componentstatic class HystrixClientFallbackFactory implements FallbackFactory&lt;HystrixClient&gt; &#123; @Override public HystrixClient create(Throwable cause) &#123; return new HystrixClientWithFallBackFactory() &#123; @Override public Hello iFailSometimes() &#123; return new Hello(&quot;fallback; reason was: &quot; + cause.getMessage()); &#125; &#125;; &#125;&#125;警告： Feign的fallback和Hystrix的fallback工作有一个限制。fallback当前不支持返回类型为com.netflix.hystrix.HystrixCommand和rx.Observable的方法。1.6 Feign和@Primary当使用Feign的Hystrix fallback时，ApplicationContext中有多个同一类型的Bean。这将会导致@Autowired不工作，因为没有一个确切的bean或者一个标记为primary的。要解决这个问题，Spring Cloud Netflix让所有的Feign实例为@Primary，所以Spring Framework将知道注入哪个bean。在一些情况下，这可能是不可取的。要关闭这个特性，设置@FeignClient的primary属性为false。1234@FeignClient(name = &quot;hello&quot;, primary = false)public interface HelloClient &#123; // methods here&#125;1.7 Feign的继承支持Feign通过单继承接口支持样板apis。这允许将通用操作分组为方便的基础接口。UserService.java12345public interface UserService &#123; @RequestMapping(method = RequestMethod.GET, value =&quot;/users/&#123;id&#125;&quot;) User getUser(@PathVariable(&quot;id&quot;) long id);&#125;UserResource.java1234@RestControllerpublic class UserResource implements UserService &#123;&#125;UserClient.java123456package project.user;@FeignClient(&quot;users&quot;)public interface UserClient extends UserService &#123;&#125;提示： 一般不建议在server和client之间共享一个接口。它引入了紧密的耦合，而且实际上以当前的形式用于Spring MVC并不起作用（方法参数映射不被继承）。1.8 Feign请求响应的压缩你可以考虑为你的Feign请求开启请求或响应的GZIP压缩。你可以通过开启以下属性来完成此操作：12eign.compression.request.enabled=truefeign.compression.response.enabled=trueFeign请求压缩为你提供了类似于设置Web服务器的设置：123feign.compression.request.enabled=truefeign.compression.request.mime-types=text/xml,application/xml,application/jsonfeign.compression.request.min-request-size=2048这些属性允许你选择压缩的media type和最小请求阈值长度。1.9 Feign日志为每一个Feign client创建一个logger，logger默认的名字是用来创建Feign client的接口的全限定类名。Feign的日志只响应DEBUG级别。application.ymllogging.level.project.user.UserClient: DEBUG你可以为每一个client配置一个Logger.Level对象，告诉Feign去记录什么。有以下选择：NONE, 不记录 (默认).BASIC, 只记录请求方法、URL、响应状态码和执行时间。HEADERS, 记录请求头和响应头的基本信息。FULL, 记录请求和响应的headers、body和metadata。例如：以下将设置Logger.Level设为FULL:1234567@Configurationpublic class FooConfiguration &#123; @Bean Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125;&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[客户端侧的负载均衡--Ribbon]]></title>
    <url>%2Fspring%2Fd662598d%2F</url>
    <content type="text"><![CDATA[原文链接Ribbon是一个客户端负载均衡器，它可以让您对HTTP和TCP客户端的行为有很大的控制权。 Feign已经使用Ribbon，所以如果您使用的是@FeignClient，那么这个部分也适用。Ribbon中一个重要的概念是named client。Spring Cloud使用RibbonClientConfiguration根据需要为每个named client创建一个新的集合作为ApplicationContext，这包含（除其他外）ILoadBalancer，RestClient和ServerListFilter。1. 如何引入Ribbon1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&lt;/dependency&gt;2. 自定义Ribbon Client你可以使用&lt;client&gt;.ribbon.*属性来配置ribbon client。Spring Cloud还允许你通过使用@RibbonClient声明其他配置（在RibbonClientConfiguration上）来完全控制客户端。例：1234@Configuration@RibbonClient(name = &quot;foo&quot;, configuration = FooConfiguration.class)public class TestConfiguration &#123;&#125;在这种情况下，ribbon client由已经在RibbonClientConfiguration中的组件和FooConfiguration中的任何组件（后者通常会覆盖前者）组成。(备注：使用RibbonClientConfiguration中的Bean和自定义的FooConfiguration中的Bean来配置ribbon client, FooConfiguration中的Bean会覆盖RibbonClientConfiguration中的Bean)注意： 上面的FooConfiguration必须用@Configuration，但是注意它不能在应用上下文被@ComponentScan扫描到，否则它将被所有@RibbonClient所共享。如果你使用@ComponentScan或者@SpringBootApplication,你需要避免它被包括在内(例如：把它放在一个单独的，不重叠的包或者在@ComponentScan中明确指定要扫描的包)。(备注：我是在src/main/java下新建一个package,将自定义的RibbonConfiguration配置Bean放在这个包下)Spring Cloud Netflix默认给ribbon提供以下的bean(BeanType beanName: ClassName):IClientConfig ribbonClientConfig: DefaultClientConfigImplIRule ribbonRule: ZoneAvoidanceRuleIPing ribbonPing: NoOpPingServerList&lt;Server&gt; ribbonServerList: ConfigurationBasedServerListServerListFilter&lt;Server&gt; ribbonServerListFilter: ZonePreferenceServerListFilterILoadBalancer ribbonLoadBalancer: ZoneAwareLoadBalancerServerListUpdater ribbonServerListUpdater: PollingServerListUpdater创建这些类型的bean并将其放置在@RibbonClient配置Bean（例如上面的FooConfiguration）中，可以覆盖所描述的每个bean。例：1234567@Configurationpublic class FooConfiguration &#123; @Bean public IPing ribbonPing(IClientConfig config) &#123; return new PingUrl(); &#125;&#125;这将用PingUrl代替NoOpPing。3. 使用properties来自定义Ribbon ClientSpring Cloud Netflix现在支持使用properties来定制Ribbon client，以便与Ribbon文档兼容。这使你可以在不同的环境启动时更改行为。支持的属性如下所列，并应以&lt;clientName&gt;.ribbon为前缀：NFLoadBalancerClassName: should implement ILoadBalancerNFLoadBalancerRuleClassName: should implement IRuleNFLoadBalancerPingClassName: should implement IPingNIWSServerListClassName: should implement ServerListNIWSServerListFilterClassName: should implement ServerListFilter提示： 在这些属性中定义的类优先于使用@RibbonClient(configuration=MyRibbonConfig.class)定义的bean和Spring Cloud Netflix提供的默认类。要为一个名为users的服务设置IRule，可以如下设置：123users: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRule4. Ribbon和Eureka一起使用当Eureka和Ribbon一起使用(例如，二者都在classpath), ribbonServerList被DiscoveryEnabledNIWSServerList的一个扩展覆盖了，该扩展的server list来自于Eureka。同时用NIWSDiscoveryPing替代IPing,通过Eureka来判断服务状态是否为UP。默认安装的ServerList是一个DomainExtractingServerList，这样做的目的是在不使用AWS AMI metadata(这是Netflix所依赖的)的情况下为负载均衡器提供物理metadata。默认情况下，server list将使用实例metadata中提供的“zone”信息构建（所以在远程客户端上设置eureka.instance.metadataMap.zone）,如果没有设置zone，可以使用服务器hostname的域名作为zone的代理（如果设置了标志approximateZoneFromHostname）。一旦zone信息可用，就可以在ServerListFilter中使用。默认情况下，它将用于定位与client位于同一个zone的server，因为默认值是ZonePreferenceServerListFilter。默认地client的zone的确定方式与远程实例相同，即通过eureka.instance.metadataMap.zone。提示： 如果没有设置zone数据，则根据client配置（而不是实例配置）进行猜测。我们把eureka.client.availabilityZones(这是一个从region名称到zone列表的map)，并取出实例所在region的第一个zone（即eureka.client.region，默认为“us-east-1“，为了与本地Netflix的兼容性）。5. Ribbon不和Eureka一起使用Eureka是一个远程服务发现的一个简便实现，所以你不需要在client端硬编码url，但是如果你不喜欢使用eureka，Ribbon和Feign仍然很合适。假设你已经为“stores”声明了@RibbonClient, 并且没有使用eureka。Ribbon client默认使用一个配置的server list,你可以像这样提供配置：application.yml123stores: ribbon: listOfServers: example.com,google.com6. 在Ribbon中禁用Eureka设置属性ribbon.eureka.enabled = false将明确禁止在Ribbon中使用Eureka。application.yml123ribbon: eureka: enabled: false7. 直接使用Ribbon API你可以直接使用LoadBalancerClient，例如：12345678910public class MyClass &#123; @Autowired private LoadBalancerClient loadBalancer; public void doStuff() &#123; ServiceInstance instance = loadBalancer.choose(&quot;stores&quot;); URI storesUri = URI.create(String.format(&quot;http://%s:%s&quot;, instance.getHost(), instance.getPort())); // ... do something with the URI &#125;&#125;8. Ribbon的缓存配置每个named client的Ribbon都有一个Spring Cloud维护的对应子应用程序上下文,这个应用程序的上下文是当对named client第一次请求时懒加载的。可以将此延迟加载行为更改为在启动时立即加载这些子应用程序上下文，通过指定Ribbon client的名称来配置。application.yml1234ribbon: eager-load: enabled: true clients: client1, client2, client3]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[具有负载均衡功能的RestTemplate]]></title>
    <url>%2Fspring%2F96993ac3%2F</url>
    <content type="text"><![CDATA[原文链接通过@LoadBalanced和@Bean修饰可以生成一个具有负载均衡功能的RestTemplate。12345678@Configurationpublic class MyConfiguration &#123; @LoadBalanced @Bean RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125;提示： 从Spring Boot 1.4开始不再提供自动配置的RestTemplate Bean,你必须自己创建。Retrying Failed RequestsRestTemplatede的失败重试,默认是不可用的，如果需要开启，需要设置spring.cloud.loadbalancer.retry.enabled=true并且添加Spring Retry依赖。1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt;&lt;/dependency&gt;具有负载均衡功能的RestTemplate将遵循Ribbon关于重试的配置，如client.ribbon.MaxAutoRetries，client.ribbon.MaxAutoRetriesNextServer，client.ribbon.OkToRetryOnAllOperations。Ribbon具体的配置。Multiple RestTemplate objects原文链接如果需要同时使用具有负载均衡功能和普通的RestTemplate，可以如下配置：1234567891011121314151617181920212223242526272829303132@Configurationpublic class MyConfiguration &#123; @LoadBalanced @Bean RestTemplate loadBalanced() &#123; return new RestTemplate(); &#125; @Primary @Bean RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125;public class MyClass &#123; @Autowired private RestTemplate restTemplate; @Autowired @LoadBalanced private RestTemplate loadBalanced; public String doOtherStuff() &#123; return loadBalanced.getForObject(&quot;http://stores/stores&quot;, String.class); &#125; public String doStuff() &#123; return restTemplate.getForObject(&quot;http://example.com&quot;, String.class); &#125;&#125;RestTemplate bean上的@Primary注解表明当@Autowired时没有特殊修饰符时使用该实例。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot读取配置文件顺序]]></title>
    <url>%2Fspring%2F5886b3b2%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot内嵌tomcat访问日志常用配置]]></title>
    <url>%2Fspring%2F76c7f26f%2F</url>
    <content type="text"><![CDATA[tomcat access log 常用配置123456789# tomcat access log configserver: tomcat: accesslog: enabled: true #是否开启日志 directory: /tmp/accesslogs/mobile-site #日志存储目录 pattern: &apos;%t %a %A %m %U%q %s %D %I %B&apos; #日志格式 prefix: access #日志文件前缀 rename-on-rotate: true #是否启用日志轮转pattern的配置：%a - Remote IP address，远程ip地址，注意不一定是原始ip地址，中间可能经过nginx等的转发%A - Local IP address，本地ip%b - Bytes sent, excluding HTTP headers, or ‘-‘ if no bytes were sent%B - Bytes sent, excluding HTTP headers%h - Remote host name (or IP address if enableLookups for the connector is false)，远程主机名称(如果resolveHosts为false则展示IP)%H - Request protocol，请求协议%l - Remote logical username from identd (always returns ‘-‘)%m - Request method，请求方法（GET，POST）%p - Local port，接受请求的本地端口%q - Query string (prepended with a ‘?’ if it exists, otherwise an empty string%r - First line of the request，HTTP请求的第一行（包括请求方法，请求的URI）%s - HTTP status code of the response，HTTP的响应代码，如：200,404%S - User session ID%t - Date and time, in Common Log Format format，日期和时间，Common Log Format格式%u - Remote user that was authenticated%U - Requested URL path%v - Local server name%D - Time taken to process the request, in millis，处理请求的时间，单位毫秒%T - Time taken to process the request, in seconds，处理请求的时间，单位秒%I - current Request thread name (can compare later with stacktraces)，当前请求的线程名，可以和打印的log对比查找问题]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[\@ConfigurationProperties和@EnableConfigurationProperties]]></title>
    <url>%2Fspring%2F4b6e90e4%2F</url>
    <content type="text"><![CDATA[在Spring Boot中使用 @ConfigurationProperties 注解开始创建一个@ConfigurationProperties bean:1234567891011121314151617@ConfigurationProperties(locations = "classpath:mail.properties", ignoreUnknownFields = false, prefix = "mail")public class MailProperties &#123; public static class Smtp &#123; private boolean auth; private boolean starttlsEnable; // ... getters and setters &#125; @NotBlank private String host; private int port; private String from; private String username; private String password; @NotNull private Smtp smtp; // ... getters and setters&#125;…从如下属性中创建(mail.properties):1234567mail.host=localhostmail.port=25mail.smtp.auth=falsemail.smtp.starttls-enable=falsemail.from=me@localhostmail.username=mail.password=方案一1234567891011121314151617181920212223@Configuration@ConfigurationProperties(locations = "classpath:mail.properties", prefix = "mail")public class MailConfiguration &#123; public static class Smtp &#123; private boolean auth; private boolean starttlsEnable; // ... getters and setters &#125; @NotBlank private String host; private int port; private String from; private String username; private String password; @NotNull private Smtp smtp; // ... getters and setters @Bean public JavaMailSender javaMailSender() &#123; // omitted for readability &#125;&#125;方案二123456789@Configuration@EnableConfigurationProperties(MailProperties.class) public class MailConfiguration &#123; @Autowired private MailProperties mailProperties; @Bean public JavaMailSender javaMailSender() &#123; // omitted for readability &#125; &#125;注意: @EnableConfigurationProperties这个注解告诉Spring Boot能支持指定特定类型的@ConfigurationProperties。如果不指定会看到如下异常:1org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [demo.mail.MailProperties] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: &#123;@org.springframework.beans.factory.annotation.Autowired(required=true)&#125;方案一不使用@EnableConfigurationProperties注解，使用@Configuration或者@Component注解使其被component scan发现。方案二使用@EnableConfigurationProperties注解，使其指定的配置类被EnableConfigurationPropertiesImportSelector注册到应用上下文。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[\@Async注解的自定义Executor]]></title>
    <url>%2Fspring%2F555f9026%2F</url>
    <content type="text"><![CDATA[How To Do @Async in Spring默认情况下，Spring使用SimpleAsyncTaskExecutor来异步运行这些方法。默认值可以在两个级别重写 - 在应用程序级别或单个方法级别。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux wc命令]]></title>
    <url>%2Flinux%2F3bb57d1c%2F</url>
    <content type="text"><![CDATA[Linux wc命令用于计算字数。利用wc指令我们可以计算文件的Byte数、字数、或是行数，若不指定文件名称、或是所给予的文件名为“-”，则wc指令会从标准输入设备读取数据。语法wc [-clw][--help][--version][文件...]参数：-c或–bytes或–chars 只显示Bytes数。-l或–lines 只显示行数。-w或–words 只显示字数。–help 在线帮助。–version 显示版本信息。实例统计单个文件在默认的情况下，wc将计算指定文件的行数、字数，以及字节数。使用的命令为：wc testfile先查看testfile文件的内容，可以看到：123456789$ cat testfile Linux networks are becoming more and more common, but scurity is often an overlooked issue. Unfortunately, in today’s environment all networks are potential hacker targets, fro0m tp-secret military research networks to small home LANs. Linux Network Securty focuses on securing Linux in a networked environment, where the security of the entire network needs to be considered rather than just isolated machines. It uses a mix of theory and practicl techniques to teach administrators how to install and use security applications, as well as how the applcations work and why they are necesary.使用wc统计，结果如下：123$ wc testfile # testfile文件的统计信息3 92 598 testfile # testfile文件的行数为3、单词数92、字节数598其中，3 个数字分别表示testfile文件的行数、单词数，以及该文件的字节数。统计多个文件如果想同时统计多个文件的信息，例如同时统计testfile、testfile_1、testfile_2，可使用如下命令：wc testfile testfile_1 testfile_2 #统计三个文件的信息输出结果如下：123456$ wc testfile testfile_1 testfile_2 #统计三个文件的信息 3 92 598 testfile #第一个文件行数为3、单词数92、字节数598 9 18 78 testfile_1 #第二个文件的行数为9、单词数18、字节数78 3 6 32 testfile_2 #第三个文件的行数为3、单词数6、字节数32 15 116 708 总用量 #三个文件总共的行数为15、单词数116、字节数708统计管道输出12ls -l | wc -lps -ef | grep java | wc -l]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux top命令]]></title>
    <url>%2Flinux%2F4c6cbbb6%2F</url>
    <content type="text"><![CDATA[Linux top命令用于实时显示 process 的动态。使用权限：所有使用者。语法top [-] [d delay] [q] [c] [S] [s] [i] [n] [b]参数说明：d : 改变显示的更新速度，或是在交谈式指令列( interactive command)按 sq : 没有任何延迟的显示速度，如果使用者是有 superuser 的权限，则 top 将会以最高的优先序执行c : 切换显示模式，共有两种模式，一是只显示执行档的名称，另一种是显示完整的路径与名称S : 累积模式，会将己完成或消失的子行程 ( dead child process ) 的 CPU time 累积起来s : 安全模式，将交谈式指令取消, 避免潜在的危机i : 不显示任何闲置 (idle) 或无用 (zombie) 的行程n : 更新的次数，完成后将会退出 topb : 批次档模式，搭配 “n” 参数一起使用，可以用来将 top 的结果输出到档案内实例显示进程信息# top显示完整命令# top -c以批处理模式显示程序信息# top -b以累积模式显示程序信息# top -S设置信息更新次数123top -n 2//表示更新两次后终止更新显示设置信息更新时间123# top -d 3//表示更新周期为3秒显示指定的进程信息123# top -p 139//显示进程号为139的进程信息，CPU、内存占用率等显示更新十次后退出top -n 10使用者将不能利用交谈式指令来对行程下命令top -s将更新显示二次的结果输入到名称为 top.log 的档案里top -n 2 -b &lt; top.log提示：根据top命令显示的内容可以进一步根据pid查看具体是哪个进程，使用命令ps aux | grep {pid}]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux ps命令]]></title>
    <url>%2Flinux%2F56aee8cb%2F</url>
    <content type="text"><![CDATA[Linux ps命令用于显示当前进程(process)的状态语法ps [options] [--help]参数ps 的参数非常多, 在此仅列出几个常用的参数并大略介绍含义-A 列出所有的行程-u 显示指定用户的进程-e 等于“-A”-f 以格式化显示a 显示所有涉及终端的进程信息u 显示面向用户的输出x 显示没有终端的进程au(x) 输出格式 :USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND实例显示进程信息1234567891011121314# ps -A 显示进程信息PID TTY TIME CMD 1 ? 00:00:02 init 2 ? 00:00:00 kthreadd 3 ? 00:00:00 migration/0 4 ? 00:00:00 ksoftirqd/0 5 ? 00:00:00 watchdog/0……省略部分结果31160 ? 00:00:00 dhclient31211 ? 00:00:00 aptd31302 ? 00:00:00 sshd31374 pts/2 00:00:00 bash31396 pts/2 00:00:00 ps显示指定用户信息1234567891011121314# ps -u root 显示root进程用户信息 PID TTY TIME CMD 1 ? 00:00:02 init 2 ? 00:00:00 kthreadd 3 ? 00:00:00 migration/0 4 ? 00:00:00 ksoftirqd/0 5 ? 00:00:00 watchdog/0……省略部分结果 31160 ? 00:00:00 dhclient31211 ? 00:00:00 aptd31302 ? 00:00:00 sshd31374 pts/2 00:00:00 bash31397 pts/2 00:00:00 ps显示所有进程信息，连同命令行12345678910111213# ps -ef 显示所有命令，连带命令行UID PID PPID C STIME TTY TIME CMDroot 1 0 0 10:22 ? 00:00:02 /sbin/initroot 2 0 0 10:22 ? 00:00:00 [kthreadd]root 3 2 0 10:22 ? 00:00:00 [migration/0]root 4 2 0 10:22 ? 00:00:00 [ksoftirqd/0]root 5 2 0 10:22 ? 00:00:00 [watchdog/0]……省略部分结果root 31302 2095 0 17:42 ? 00:00:00 sshd: root@pts/2 root 31374 31302 0 17:42 pts/2 00:00:00 -bashroot 31400 1 0 17:46 ? 00:00:00 /usr/bin/python /usr/sbin/aptdroot 31407 31374 0 17:48 pts/2 00:00:00 ps -efps与grep常用组合用法，查找特定进程123456# ps -ef | grep sshUID PID PPID C STIME TTY TIME CMDroot 2720 1 0 Nov02 ? 00:00:00 /usr/sbin/sshdroot 17394 2720 0 14:58 ? 00:00:00 sshd: root@pts/0 root 17465 17398 0 15:57 pts/0 00:00:00 grep ssh列出目前所有的正在内存当中的程序123456789101112# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.0 10368 676 ? Ss Nov02 0:00 init [3] root 2 0.0 0.0 0 0 ? S&lt; Nov02 0:01 [migration/0]root 3 0.0 0.0 0 0 ? SN Nov02 0:00 [ksoftirqd/0]root 4 0.0 0.0 0 0 ? S&lt; Nov02 0:01 [migration/1]root 5 0.0 0.0 0 0 ? SN Nov02 0:00 [ksoftirqd/1]root 6 0.0 0.0 0 0 ? S&lt; Nov02 29:57 [events/0]root 7 0.0 0.0 0 0 ? S&lt; Nov02 0:00 [events/1]root 8 0.0 0.0 0 0 ? S&lt; Nov02 0:00 ……省略部分结果ps aux可以显示进程占用CPU和内存情况。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux grep命令]]></title>
    <url>%2Flinux%2Fb177a18e%2F</url>
    <content type="text"><![CDATA[Linux grep命令用于查找文件里符合条件的字符串。若不指定任何文件名称，或是所给予的文件名为“-”，则grep指令会从标准输入设备读取数据。语法grep [-abcEFGhHilLnqrsvVwxy][-A&lt;显示列数&gt;][-B&lt;显示列数&gt;][-C&lt;显示列数&gt;][-d&lt;进行动作&gt;][-e&lt;范本样式&gt;][-f&lt;范本文件&gt;][--help][范本样式][文件或目录...]参数-a或–text 不要忽略二进制的数据。-A&lt;显示列数&gt;或–after-context=&lt;显示列数&gt; 除了显示符合范本样式的那一列之外，并显示该列之后的内容。-b或–byte-offset 在显示符合范本样式的那一列之前，标示出该列第一个字符的位编号。-B&lt;显示列数&gt;或–before-context=&lt;显示列数&gt; 除了显示符合范本样式的那一列之外，并显示该列之前的内容。-c或–count 计算符合范本样式的列数。-C&lt;显示列数&gt;或–context=&lt;显示列数&gt;或-&lt;显示列数&gt; 除了显示符合范本样式的那一列之外，并显示该列之前后的内容。-d&lt;进行动作&gt;或–directories=&lt;进行动作&gt; 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。-e&lt;范本样式&gt;或–regexp=&lt;范本样式&gt; 指定字符串做为查找文件内容的范本样式。-E或–extended-regexp 将范本样式为延伸的普通表示法来使用。-f&lt;范本文件&gt;或–file=&lt;范本文件&gt; 指定范本文件，其内容含有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每列一个范本样式。-F或–fixed-regexp 将范本样式视为固定字符串的列表。-G或–basic-regexp 将范本样式视为普通的表示法来使用。-h或–no-filename 在显示符合范本样式的那一列之前，不标示该列所属的文件名称。-H或–with-filename 在显示符合范本样式的那一列之前，表示该列所属的文件名称。-i或–ignore-case 忽略字符大小写的差别。-l或–file-with-matches 列出文件内容符合指定的范本样式的文件名称。-L或–files-without-match 列出文件内容不符合指定的范本样式的文件名称。-n或–line-number 在显示符合范本样式的那一列之前，标示出该列的列数编号。-o 输出每一行中所有符合条件的内容-q或–quiet或–silent 不显示任何信息。-r或–recursive 此参数的效果和指定”-d recurse”参数相同。-s或–no-messages 不显示错误信息。-v或–revert-match 反转查找。-V或–version 显示版本信息。-w或–word-regexp 只显示全字符合的列。-x或–line-regexp 只显示全列符合的列。-y 此参数的效果和指定”-i”参数相同。–help 在线帮助。实例12345$ grep test test* #查找后缀有“test”的文件包含“test”字符串的文件 testfile1:This a Linux testfile! #列出testfile1 文件中包含test字符的行 testfile_2:This is a linux testfile! #列出testfile_2 文件中包含test字符的行 testfile_2:Linux test #列出testfile_2 文件中包含test字符的行1234567$ grep -r update /etc/acpi #以递归的方式查找“etc/acpi”下包含“update”的文件 /etc/acpi/ac.d/85-anacron.sh:# (Things like the slocate updatedb cause a lot of IO.) Rather than /etc/acpi/resume.d/85-anacron.sh:# (Things like the slocate updatedb cause a lot of IO.) Rather than /etc/acpi/events/thinkpad-cmos:action=/usr/sbin/thinkpad-keys--update12345678910$ grep -v test *test* #查找文件名中包含test 的文件中不包含test的行testfile1:helLinux! testfile1:Linis a free Unix-type operating system. testfile1:Lin testfile_1:HELLO LINUX! testfile_1:LINUX IS A FREE UNIX-TYPE OPTERATING SYSTEM. testfile_1:THIS IS A LINUX TESTFILE! testfile_2:HELLO LINUX! testfile_2:Linux is a free unix-type opterating system.]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux dig 命令]]></title>
    <url>%2Flinux%2F152528eb%2F</url>
    <content type="text"><![CDATA[dig是域信息检索器的简称(Domain Information Groper)，可以执行查询域名相关的任务。语法dig [选项参数] {domian}示例一：dig www.baidu.com示例二：+short 输出精简答复dig www.baidu.com +short示例三：+trace 追踪DNS解析过程dig www.baidu.com +trace]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux awk 命令]]></title>
    <url>%2Flinux%2Fc0a16f03%2F</url>
    <content type="text"><![CDATA[原文链接AWK是一种处理文本文件的语言，是一个强大的文本分析工具。之所以叫AWK是因为其取了三位创始人Alfred Aho，Peter Weinberger, 和 Brian Kernighan 的Family Name的首字符。语法123awk [选项参数] &apos;script&apos; var=value file(s)或awk [选项参数] -f scriptfile var=value file(s)常用选项参数说明-F fs指定输入文件的分隔符，fs是一个字符串或者是一个正则表达式，如-F:。-V var=value赋值一个用户定义变量-f scripfile从脚本文件中读取awk命令。基本用法log.txt文本内容如下：12342 this is a test3 Are you like awkThis&apos;s a test10 There are orange,apple,mongo用法一awk ‘{[pattern] action}’ {filenames} # 行匹配语句 awk ‘’ 只能用单引号实例：123456789101112131415# 每行按空格或TAB分割，输出文本中的1、4项 $ awk &apos;&#123;print $1,$4&#125;&apos; log.txt --------------------------------------------- 2 a 3 like This&apos;s 10 orange,apple,mongo # 格式化输出 $ awk &apos;&#123;printf &quot;%-8s %-10s\n&quot;,$1,$4&#125;&apos; log.txt --------------------------------------------- 2 a 3 like This&apos;s 10 orange,apple,mongo用法二awk -F #-F相当于内置变量FS, 指定分割字符实例：1234567891011121314151617181920212223# 使用&quot;,&quot;分割 $ awk -F, &apos;&#123;print $1,$2&#125;&apos; log.txt --------------------------------------------- 2 this is a test 3 Are you like awk This&apos;s a test 10 There are orange apple # 或者使用内建变量 $ awk &apos;BEGIN&#123;FS=&quot;,&quot;&#125; &#123;print $1,$2&#125;&apos; log.txt --------------------------------------------- 2 this is a test 3 Are you like awk This&apos;s a test 10 There are orange apple # 使用多个分隔符.先使用空格分割，然后对分割结果再使用&quot;,&quot;分割 $ awk -F &apos;[ ,]&apos; &apos;&#123;print $1,$2,$5&#125;&apos; log.txt --------------------------------------------- 2 this test 3 Are awk This&apos;s a 10 There apple用法三awk -v # 设置变量实例：12345678910111213$ awk -va=1 &apos;&#123;print $1,$1+a&#125;&apos; log.txt --------------------------------------------- 2 3 3 4 This&apos;s 1 10 11 $ awk -va=1 -vb=s &apos;&#123;print $1,$1+a,$1b&#125;&apos; log.txt --------------------------------------------- 2 3 2s 3 4 3s This&apos;s 1 This&apos;ss 10 11 10s用法四awk -f {awk脚本} {文件名}实例：$ awk -f cal.awk log.txt运算符运算符描述= += -= *= /= %= ^= **=赋值?:C条件表达式||逻辑或&amp;&amp;逻辑与~ ~!匹配正则表达式和不匹配正则表达式&lt; &lt;= &gt; &gt;= != ==关系运算符空格连接+ -加，减* / %乘，除与求余+ - !一元加，减和逻辑非^ ***求幂++ –增加或减少，作为前缀或后缀$字段引用in数组成员过滤第一列大于2的行12345$ awk &apos;$1&gt;2&apos; log.txt #命令#输出3 Are you like awkThis&apos;s a test10 There are orange,apple,mongo过滤第一列等于2的行123$ awk &apos;$1==2 &#123;print $1,$3&#125;&apos; log.txt #命令#输出2 is过滤第一列大于2并且第二列等于’Are’的行123$ awk &apos;$1&gt;2 &amp;&amp; $2==&quot;Are&quot; &#123;print $1,$2,$3&#125;&apos; log.txt #命令#输出3 Are you内置变量变量描述\$n当前记录的第n个字段，字段间由FS分隔\$0完整的输入记录ARGC命令行参数的数目ARGIND命令行中当前文件的位置(从0开始算)ARGV包含命令行参数的数组CONVFMT数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组ERRNO最后一个系统错误的描述FIELDWIDTHS字段宽度列表(用空格键分隔)FILENAME当前文件名FNR各文件分别计数的行号FS字段分隔符(默认是任何空格)IGNORECASE如果为真，则进行忽略大小写的匹配NF输入字段分割符NR已经读出的记录数，就是行号，从1开始OFMT数字的输出格式(默认值是%.6g)OFS输出记录分隔符（输出换行符），输出时用指定的符号代替换行符ORS输出记录分隔符(默认值是一个换行符)RLENGTH由match函数所匹配的字符串的长度RS记录分隔符(默认是一个换行符)RSTART由match函数所匹配的字符串的第一个位置SUBSEP数组下标分隔符(默认值是/034)使用正则，字符串匹配1234# 输出第二列包含 &quot;th&quot;，并打印第二列与第四列$ awk &apos;$2 ~ /th/ &#123;print $2,$4&#125;&apos; log.txt---------------------------------------------this a~ 表示模式开始。//中是模式12345# 输出包含&quot;re&quot; 的行$ awk &apos;/re/ &apos; log.txt---------------------------------------------3 Are you like awk10 There are orange,apple,mongo忽略大小写1234$ awk &apos;BEGIN&#123;IGNORECASE=1&#125; /this/&apos; log.txt---------------------------------------------2 this is a testThis&apos;s a test模式取反1234567891011$ awk &apos;$2 !~ /th/ &#123;print $2,$4&#125;&apos; log.txt---------------------------------------------Are likeaThere orange,apple,mongo$ awk &apos;!/th/ &#123;print $2,$4&#125;&apos; log.txt---------------------------------------------Are likeaThere orange,apple,mongoawk脚本关于awk脚本，我们需要注意两个关键词BEGIN和END。BEGIN{ 这里面放的是执行前的语句 }END {这里面放的是处理完所有的行后要执行的语句 }{这里面放的是处理每一行时要执行的语句}假设有这么一个文件（学生成绩表）：123456$ cat score.txtMarry 2143 78 84 77Jack 2321 66 78 45Tom 2122 48 77 71Mike 2537 87 97 95Bob 2415 40 57 62我们的awk脚本如下：123456789101112131415161718192021222324$ cat cal.awk#!/bin/awk -f#运行前BEGIN &#123; math = 0 english = 0 computer = 0 printf &quot;NAME NO. MATH ENGLISH COMPUTER TOTAL\n&quot; printf &quot;---------------------------------------------\n&quot;&#125;#运行中&#123; math+=$3 english+=$4 computer+=$5 printf &quot;%-6s %-6s %4d %8d %8d %8d\n&quot;, $1, $2, $3,$4,$5, $3+$4+$5&#125;#运行后END &#123; printf &quot;---------------------------------------------\n&quot; printf &quot; TOTAL:%10d %8d %8d \n&quot;, math, english, computer printf &quot;AVERAGE:%10.2f %8.2f %8.2f\n&quot;, math/NR, english/NR, computer/NR&#125;我们来看一下执行结果：1234567891011$ awk -f cal.awk score.txtNAME NO. MATH ENGLISH COMPUTER TOTAL---------------------------------------------Marry 2143 78 84 77 239Jack 2321 66 78 45 189Tom 2122 48 77 71 196Mike 2537 87 97 95 279Bob 2415 40 57 62 159--------------------------------------------- TOTAL: 319 393 350AVERAGE: 63.80 78.60 70.00]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
</search>
