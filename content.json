{"meta":{"title":"Mao's Blog","subtitle":null,"description":"A Java Programmer","author":"云逸云飞","url":"https://maoyunfei.github.io"},"pages":[{"title":"404","date":"2018-03-05T10:09:20.322Z","updated":"2018-03-05T10:09:20.320Z","comments":true,"path":"/404.html","permalink":"https://maoyunfei.github.io//404.html","excerpt":"","text":"404页面"},{"title":"","date":"2018-03-06T03:13:34.777Z","updated":"2018-03-06T03:12:54.763Z","comments":true,"path":"baidu_verify_TEGpfbeJP3.html","permalink":"https://maoyunfei.github.io/baidu_verify_TEGpfbeJP3.html","excerpt":"","text":"TEGpfbeJP3"},{"title":"所有分类","date":"2018-03-04T10:17:13.000Z","updated":"2018-03-04T14:03:24.859Z","comments":false,"path":"categories/index.html","permalink":"https://maoyunfei.github.io/categories/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2018-03-04T10:15:48.000Z","updated":"2018-03-04T14:03:24.862Z","comments":false,"path":"tags/index.html","permalink":"https://maoyunfei.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Java 8新特性之Date/Time API","slug":"java/Java 8新特性之Date:Time API","date":"2018-03-02T16:00:00.000Z","updated":"2018-03-04T09:38:51.314Z","comments":true,"path":"java/7dd3efa4/","link":"","permalink":"https://maoyunfei.github.io/java/7dd3efa4/","excerpt":"在Java 8以前，日期和时间处理一直被广大java程序员抱怨太难用，首先是java.util和java.sql中，都包含Date类，如果要处理由java.text.DateFormat类处理。同时java.util.Date中既包含了日期，又包含了时间，所以java 8新的日期和时间库，很好的解决了以前日期和时间类的很多弊端。并且也借鉴了第三方库joda很多的优点。对比旧的日期APIJava.timejava.util.Calendar以及Date流畅的API不流畅的API实例不可变实例可变线程安全非线程安全","text":"在Java 8以前，日期和时间处理一直被广大java程序员抱怨太难用，首先是java.util和java.sql中，都包含Date类，如果要处理由java.text.DateFormat类处理。同时java.util.Date中既包含了日期，又包含了时间，所以java 8新的日期和时间库，很好的解决了以前日期和时间类的很多弊端。并且也借鉴了第三方库joda很多的优点。对比旧的日期APIJava.timejava.util.Calendar以及Date流畅的API不流畅的API实例不可变实例可变线程安全非线程安全新API介绍1、主要的类:java.time包下的类：123456789Instant：时间戳 Duration：持续时间，时间差 LocalDate：只包含日期，比如：2016-10-20 LocalTime：只包含时间，比如：23:12:10 LocalDateTime：包含日期和时间，比如：2016-10-20 23:14:21 Period：时间段 ZoneOffset：时区偏移量，比如：+8:00 ZonedDateTime：带时区的时间 Clock：时钟，比如获取目前美国纽约的时间以及java.time.format包下的类：1DateTimeFormatter：时间格式化2、主要的类的值的格式:3、通过例子来看如何使用java8新的日期时间库(1) 获取今天的日期1234LocalDate todayDate = LocalDate.now();System.out.println(\"今天的日期：\"+todayDate);//结果今天的日期：2016-10-20(2) 指定日期，进行相应操作123456789101112131415161718192021222324252627//取2016年10月的第1天LocalDate firstDay = oneday.with(TemporalAdjusters.firstDayOfMonth());System.out.println(firstDay); //取2016年10月的第1天，另外一种写法LocalDate firstDay2 = oneday.withDayOfMonth(1);System.out.println(firstDay2); //取2016年10月的最后1天，不用考虑大月，小月，平年，闰年LocalDate lastDay = oneday.with(TemporalAdjusters.lastDayOfMonth());System.out.println(lastDay); //当前日期＋1天LocalDate tomorrow = oneday.plusDays(1);System.out.println(tomorrow);//判断是否为闰年boolean isLeapYear = tomorrow.isLeapYear();System.out.println(isLeapYear);//运行结果2016-10-202016-10-012016-10-012016-10-312016-10-21true(3) 生日检查或者账单日检查123456789101112开发过程中，经常需要为过生日的用户送上一些祝福，例如，用户的生日为1990-10-12，如果今天是2016-10-12，那么今天就是用户的生日(按公历/身份证日期来算)，那么通过java8新的日期库，我们该如何来进行判断？在java 8中，可以使用MonthDay，该类不包含年份信息，当然还有一个类是YearMonthLocalDate birthday = LocalDate.of(1990, 10, 12);MonthDay birthdayMd = MonthDay.of(birthday.getMonth(), birthday.getDayOfMonth());MonthDay today = MonthDay.from(LocalDate.of(2016, 10, 12)); System.out.println(today.equals(birthdayMd));//结果true(4) 获取当前的时间12345678910111213141516时间主要是使用LocalTime，该类不包含日期，只有时间信息//获取当前的时间LocalTime nowTime = LocalTime.now(); //结果14:29:40.558 //如果不想显示毫秒LocalTime nowTime2 = LocalTime.now().withNano(0); //14:43:14 //指定时间LocalTime time = LocalTime.of(14, 10, 21); //14:10:21LocalTime time2 = LocalTime.parse(\"12:00:01\"); // 12:00:01 //当前时间增加2小时LocalTime nowTimePlus2Hour = nowTime.plusHours(2); //16:47:23.144//或者LocalTime nowTimePlus2Hour2 = nowTime.plus(2, ChronoUnit.HOURS);(5) 日期前后比较12345比较2个日期哪个在前，哪个在后，java8 LocalDate提供了2个方法，isAfter(),isBeforeLocalDate today = LocalDate.now();LocalDate specifyDate = LocalDate.of(2015, 10, 20);System.out.println(today.isAfter(specifyDate)); //true(6) 处理不同时区的时间12345678910111213141516java8中，将日期、时间，时区都很好的进行了分离。//查看当前的时区ZoneId defaultZone = ZoneId.systemDefault();System.out.println(defaultZone); //Asia/Shanghai //查看美国纽约当前的时间ZoneId america = ZoneId.of(\"America/New_York\");LocalDateTime shanghaiTime = LocalDateTime.now();LocalDateTime americaDateTime = LocalDateTime.now(america);System.out.println(shanghaiTime); //2016-11-06T15:20:27.996System.out.println(americaDateTime); //2016-11-06T02:20:27.996 ，可以看到美国与北京时间差了13小时 //带有时区的时间ZonedDateTime americaZoneDateTime = ZonedDateTime.now(america);System.out.println(americaZoneDateTime); //2016-11-06T02:23:44.863-05:00[America/New_York](7) 比较两个日期之前时间差123456789101112131415161718在项目中，经常需要比较两个日期之间相差几天，或者相隔几个月，我们可以使用java8的Period来进行处理。LocalDate today = LocalDate.now();LocalDate specifyDate = LocalDate.of(2015, 10, 2);Period period = Period.between(specifyDate, today);System.out.println(period.getDays()); //4System.out.println(period.getMonths()); //1System.out.println(specifyDate.until(today, ChronoUnit.DAYS)); //401//输出结果41401我们可以看到，我们使用Period类比较天数，但它返回的值，并不是2个日期之间总共的天数差，而是一个相对天数差，比如5月1日和10月2日，他比较的是仅仅2个天之间的差，那1号和2号，相差1天，而实际上，因为中间相差了好几个月，所以真正的天数差肯定不是1天，所以我们可以使用until，并指明精度单位是days，就可以计算真正的天数差了。(8) 日期时间格式解析、格式化12345678910111213141516在java8之前，我们进行时间格式化主要是使用SimpleDateFormat，而在java8中，主要是使用DateTimeFormatter，java8中，预定义了一些标准的时间格式，我们可以直接将时间转换为标准的时间格式：String specifyDate = \"20151011\";DateTimeFormatter formatter = DateTimeFormatter.BASIC_ISO_DATE;LocalDate formatted = LocalDate.parse(specifyDate,formatter); System.out.println(formatted); //输出2015-10-11当然，很多时间标准的时间格式可能也不满足我们的要求，我们需要转为自定义的时间格式DateTimeFormatter formatter2 = DateTimeFormatter.ofPattern(\"YYYY MM dd\");System.out.println(formatter2.format(LocalDate.now()));//结果2015 10 11(9) java8 时间类与Date类的相互转化1234567891011121314151617181920212223在转换中，我们需要注意，因为java8之前Date是包含日期和时间的，而LocalDate只包含日期，LocalTime只包含时间，所以与Date在互转中，势必会丢失日期或者时间，或者会使用起始时间。如果转LocalDateTime，那么就不存在信息误差。//Date与Instant的相互转化Instant instant = Instant.now();Date date = Date.from(instant);Instant instant2 = date.toInstant(); //Date转为LocalDateTimeDate date2 = new Date();LocalDateTime localDateTime2 = LocalDateTime.ofInstant(date2.toInstant(), ZoneId.systemDefault()); //LocalDateTime转DateLocalDateTime localDateTime3 = LocalDateTime.now();Instant instant3 = localDateTime3.atZone(ZoneId.systemDefault()).toInstant();Date date3 = Date.from(instant);//LocalDate转Date//因为LocalDate不包含时间，所以转Date时，会默认转为当天的起始时间，00:00:00LocalDate localDate4 = LocalDate.now();Instant instant4 = localDate4.atStartOfDay().atZone(ZoneId.systemDefault()).toInstant();Date date4 = Date.from(instant);","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java 8","slug":"Java-8","permalink":"https://maoyunfei.github.io/tags/Java-8/"}]},{"title":"Java 8新特性之函数式接口和Lambda表达式","slug":"java/Java 8新特性之函数式接口和Lambda表达式","date":"2018-03-01T16:00:00.000Z","updated":"2018-03-04T09:38:51.334Z","comments":true,"path":"java/c8f73c32/","link":"","permalink":"https://maoyunfei.github.io/java/c8f73c32/","excerpt":"面向对象并不坏，但它给程序带来了很多冗长的内容。例如，假设我们要创建一个Runnable的实例。通常我们使用下面的匿名类来完成它：","text":"面向对象并不坏，但它给程序带来了很多冗长的内容。例如，假设我们要创建一个Runnable的实例。通常我们使用下面的匿名类来完成它：123456Runnable r = new Runnable() &#123; @Override public void run() &#123; System.out.println(\"My Runnable\"); &#125; &#125;;如果你看看上面的代码，实际使用的部分是 run() 方法中的代码。其余所有的代码是因为Java程序的结构化方式。Java 8函数式接口和Lambda表达式通过删除大量的样板代码，帮助我们编写更少、更简洁的代码。函数式接口具有一个抽象方法的接口称为函数式接口。添加了@FunctionalInterface注解，以便我们可以将接口标记为函数式接口。使用它不是强制性的，但最好的做法是将它与函数式接口一起使用，以避免意外添加额外的方法。如果接口使用@FunctionalInterface注解进行注释，并且我们尝试使用多个抽象方法，则会引发编译器错误。Java 8函数式接口的主要好处是我们可以使用lambda表达式来实例化它们，避免使用笨重的匿名类实现。Java 8 Collections API已被重写，并引入了新的Stream API，它使用了许多函数式接口。 Java 8在java.util.function包中定义了很多函数式接口。一些有用的java 8函数式接口如Consumer、Supplier、Function和Predicate。java.lang.Runnable是使用单一抽象方法 run() 的函数式接口的一个很好的例子。下面的代码片段为函数式接口提供了一些指导：1234567891011121314151617181920212223242526272829303132333435363738394041424344interface Foo &#123; boolean equals(Object obj); &#125;// Not functional because equals is already an implicit member (Object class)interface Comparator&lt;T&gt; &#123; boolean equals(Object obj); int compare(T o1, T o2);&#125;// Functional because Comparator has only one abstract non-Object methodinterface Foo &#123; int m(); Object clone();&#125;// Not functional because method Object.clone is not publicinterface X &#123; int m(Iterable&lt;String&gt; arg); &#125;interface Y &#123; int m(Iterable&lt;String&gt; arg); &#125;interface Z extends X, Y &#123;&#125;// Functional: two methods, but they have the same signatureinterface X &#123; Iterable m(Iterable&lt;String&gt; arg); &#125;interface Y &#123; Iterable&lt;String&gt; m(Iterable arg); &#125;interface Z extends X, Y &#123;&#125;// Functional: Y.m is a subsignature &amp; return-type-substitutableinterface X &#123; int m(Iterable&lt;String&gt; arg); &#125;interface Y &#123; int m(Iterable&lt;Integer&gt; arg); &#125;interface Z extends X, Y &#123;&#125;// Not functional: No method has a subsignature of all abstract methodsinterface X &#123; int m(Iterable&lt;String&gt; arg, Class c); &#125;interface Y &#123; int m(Iterable arg, Class&lt;?&gt; c); &#125;interface Z extends X, Y &#123;&#125;// Not functional: No method has a subsignature of all abstract methodsinterface X &#123; long m(); &#125;interface Y &#123; int m(); &#125;interface Z extends X, Y &#123;&#125;// Compiler error: no method is return type substitutableinterface Foo&lt;T&gt; &#123; void m(T arg); &#125;interface Bar&lt;T&gt; &#123; void m(T arg); &#125;interface FooBar&lt;X, Y&gt; extends Foo&lt;X&gt;, Bar&lt;Y&gt; &#123;&#125;// Compiler error: different signatures, same erasureLambda表达式由于在函数式接口中只有一个抽象函数，因此在将该lambda表达式应用于该方法时不会出现混淆。 Lambda表达式的语法是 (argument) -&gt; (body)。现在来看看如何使用lambda表达式写上面的匿名Runnable:1Runnable r1 = () -&gt; System.out.println(\"My Runnable\");让我们试着了解上面的lambda表达式中发生了什么。Runnable是一个函数式接口，这就是为什么我们可以使用lambda表达式来创建它的实例。由于 run() 方法没有参数，我们的lambda表达式也没有参数。就像if-else块一样，我们可以避免大括号({})，因为我们在方法体中只有单个语句。对于多个语句，我们必须像使用其他方法一样使用花括号。为什么我们需要Lambda表达式1、减少代码行数使用lambda表达式的一个明显优势是代码量减少了，我们已经看到，我们可以轻松地使用lambda表达式而不是使用匿名类来创建函数接口的实例。2、顺序和并行执行支持使用lambda表达式的另一个好处是我们可以从Stream API顺序和并行操作支持中受益。为了解释这一点，我们举一个简单的例子，我们需要编写一个方法来测试一个数字是否是素数。12345678//Traditional approachprivate static boolean isPrime(int number) &#123; if(number &lt; 2) return false; for(int i=2; i&lt;number; i++)&#123; if(number % i == 0) return false; &#125; return true;&#125;上述代码的问题在于它本质上是顺序的，如果数字非常大，那么它将花费大量时间。代码的另一个问题是有太多的退出点使其可读性差。123456//Declarative approachprivate static boolean isPrime(int number) &#123; return number &gt; 1 &amp;&amp; IntStream.range(2, number).noneMatch( index -&gt; number % index == 0);&#125;为了提高可读性，我们也可以编写如下的方法。1234567private static boolean isPrime(int number) &#123; IntPredicate isDivisible = index -&gt; number % index == 0; return number &gt; 1 &amp;&amp; IntStream.range(2, number).noneMatch( isDivisible);&#125;3、将行为传递给方法我们来看看如何使用lambda表达式来传递一个方法的行为。假设我们必须编写一个方法来对列表中的数字求和，如果它们符合给定的条件。我们可以使用Predicate并编写如下的方法。123456public static int sumWithCondition(List&lt;Integer&gt; numbers, Predicate&lt;Integer&gt; predicate) &#123; return numbers.parallelStream() .filter(predicate) .mapToInt(i -&gt; i) .sum(); &#125;使用示例：123456//sum of all numberssumWithCondition(numbers, n -&gt; true)//sum of all even numberssumWithCondition(numbers, i -&gt; i%2==0)//sum of all numbers greater than 5sumWithCondition(numbers, i -&gt; i&gt;5)4、使用惰性求值效率更高使用lambda表达式的另一个优点是惰性求值(lazy evaluation)。假设我们需要编写一个方法来找出3到11范围内的最大奇数并返回它的平方。通常我们会为此方法编写如下代码：123456789private static int findSquareOfMaxOdd(List&lt;Integer&gt; numbers) &#123; int max = 0; for (int i : numbers) &#123; if (i % 2 != 0 &amp;&amp; i &gt; 3 &amp;&amp; i &lt; 11 &amp;&amp; i &gt; max) &#123; max = i; &#125; &#125; return max * max; &#125;上面的程序总是按顺序运行，但我们可以使用Stream API来实现这一点，并获得Laziness-seeking的好处。我们来看看如何使用Stream API和lambda表达式以函数式编程方式重写此代码。123456789101112131415161718192021public static int findSquareOfMaxOdd(List&lt;Integer&gt; numbers) &#123; return numbers.stream() .filter(NumberTest::isOdd) //Predicate is functional interface and .filter(NumberTest::isGreaterThan3) // we are using lambdas to initialize it .filter(NumberTest::isLessThan11) // rather than anonymous inner classes .max(Comparator.naturalOrder()) .map(i -&gt; i * i) .get(); &#125; public static boolean isOdd(int i) &#123; return i % 2 != 0; &#125; public static boolean isGreaterThan3(int i)&#123; return i &gt; 3; &#125; public static boolean isLessThan11(int i)&#123; return i &lt; 11; &#125;","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java 8","slug":"Java-8","permalink":"https://maoyunfei.github.io/tags/Java-8/"}]},{"title":"Java 8新特性之接口的默认方法和静态方法","slug":"java/Java 8新特性之接口的默认方法和静态方法","date":"2018-02-28T16:00:00.000Z","updated":"2018-03-04T09:38:51.330Z","comments":true,"path":"java/6376aac3/","link":"","permalink":"https://maoyunfei.github.io/java/6376aac3/","excerpt":"Java 8接口新特性包括接口中的静态方法和默认方法。在Java 8之前，我们只能在接口中使用方法声明。但是从Java 8开始，我们可以在接口中使用默认方法和静态方法。","text":"Java 8接口新特性包括接口中的静态方法和默认方法。在Java 8之前，我们只能在接口中使用方法声明。但是从Java 8开始，我们可以在接口中使用默认方法和静态方法。默认方法为了在java接口中创建一个默认方法，我们需要在方法签名中使用“default”关键字。例如，12345678public interface Interface1 &#123; void method1(String str); default void log(String str)&#123; System.out.println(\"I1 logging::\"+str); &#125;&#125;注意到 log(String str) 是Interface1中的默认方法。现在当一个类实现Interface1时，并不强制为接口的默认方法提供实现。这个特性将帮助我们扩展接口和其他方法，我们所需要的只是提供一个默认实现。另一个接口定义如下：123456789public interface Interface2 &#123; void method2(); default void log(String str)&#123; System.out.println(\"I2 logging::\"+str); &#125;&#125;我们知道Java不允许我们继承多个类，因为它会导致“钻石问题”，因为编译器无法决定使用哪个超类方法。使用默认方法，”钻石问题”也会出现在接口上。因为如果一个类同时实现了Interface1和Interface2并且没有实现通用的默认方法，编译器无法决定选择哪一个。(备注：The diamond problem)实现多个接口是Java不可或缺的组成部分，可以在核心Java类以及大多数企业应用程序和框架中找到它。所以为了确保这个问题不会发生在接口中，必须为通用的接口默认方法提供实现。因此，如果一个类正在实现上述两个接口，它将不得不为 log() 方法提供实现，否则编译器将抛出编译时错误。一个同时实现Interface1和Interface2的简单类如下：12345678910111213141516public class MyClass implements Interface1, Interface2 &#123; @Override public void method2() &#123; &#125; @Override public void method1(String str) &#123; &#125; @Override public void log(String str)&#123; System.out.println(\"MyClass logging::\"+str); Interface1.print(\"abc\"); &#125;&#125;有关java接口默认方法的重点：Java 8接口的默认方法将帮助我们扩展接口，而不用担心会破坏实现类。Java 8接口默认方法弥合了接口和抽象类之间的差异。Java 8接口的默认方法将帮助我们避免utility类，比如所有的Collections类方法都可以在接口本身中提供。Java接口的默认方法将帮助我们去除基础实现类，我们可以提供默认的实现，实现类可以选择重写哪一个。在接口中引入默认方法的主要原因之一是增强Java 8中的Collections API以支持lambda表达式。如果层次结构中的任何类具有相同签名的方法，则默认方法变得不相关。默认方法不能从java.lang.Object中覆盖方法。推理非常简单，这是因为Object是所有java类的基类。所以即使我们把Object类的方法定义为接口中的默认方法，也是无用的，因为总是使用Object类的方法。这就是为什么要避免混淆，我们不能有覆盖Object类方法的默认方法。Java接口默认方法也被称为Defender方法或虚拟扩展方法。静态方法接口静态方法和默认方法类似，除了我们不能在实现类中override它们。这个特性有助于我们避免在实现类中由于不好的实现导致的不当结果。12345678910111213public interface MyData &#123; default void print(String str) &#123; if (!isNull(str)) System.out.println(\"MyData Print::\" + str); &#125; static boolean isNull(String str) &#123; System.out.println(\"Interface Null Check\"); return str == null ? true : \"\".equals(str) ? true : false; &#125;&#125;现在来看一个实现类，该类具有 isNull() 方法，但实现效果较差。1234567891011121314public class MyDataImpl implements MyData &#123; public boolean isNull(String str) &#123; System.out.println(\"Impl Null Check\"); return str == null ? true : false; &#125; public static void main(String args[])&#123; MyDataImpl obj = new MyDataImpl(); obj.print(\"\"); obj.isNull(\"abc\"); &#125;&#125;注意 isNull(String str) 是一种简单的类方法，它不会覆盖接口方法。例如，如果我们将@Override注释添加到 isNull() 方法，则会导致编译器错误。现在，当我们运行应用程序时，我们得到以下输出:12Interface Null CheckImpl Null Check如果我们将接口方法从静态变为默认，我们将得到以下输出:123Impl Null CheckMyData Print::Impl Null CheckJava接口静态方法仅对接口方法可见，如果我们从 MyDataImpl 类中移除 isNull() 方法，我们将无法将其用于 MyDataImpl 对象。像其他静态方法一样，我们可以使用类名调用接口静态方法。例如：1boolean result = MyData.isNull(\"abc\");有关java接口静态方法的重点：Java接口的静态方法是接口的一部分，我们不能用它来实现类对象。Java接口静态方法适用于提供utility方法，例如空检查，集合排序等。Java接口静态方法通过不允许实现类override它们来帮助我们提供安全性。我们不能为Object类方法定义接口静态方法，因为“这个静态方法不能从Object隐藏实例方法”，我们会得到编译器错误。这是因为它在java中是不允许的，因为Object是所有类的基类，我们不能有一个类级静态方法和另一个具有相同签名的实例方法。我们可以使用java接口的静态方法来移除Collections等utility类，并将它的所有静态方法移到相应的接口中，这很容易找到和使用。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java 8","slug":"Java-8","permalink":"https://maoyunfei.github.io/tags/Java-8/"}]},{"title":"聊聊JVM的年轻代","slug":"java/jvm/【收录】聊聊JVM的年轻代","date":"2018-02-09T16:00:00.000Z","updated":"2018-03-04T09:38:51.288Z","comments":true,"path":"java/24b8c8d9/","link":"","permalink":"https://maoyunfei.github.io/java/24b8c8d9/","excerpt":"本文章来源于并发编程网堆内存模型大致如下：","text":"本文章来源于并发编程网堆内存模型大致如下：1. 为什么会有年轻代我们先来屡屡，为什么需要把堆分代？不分代不能完成他所做的事情么？其实不分代完全可以，分代的唯一理由就是优化GC性能。你先想想，如果没有分代，那我们所有的对象都在一块，GC的时候我们要找到哪些对象没用，这样就会对堆的所有区域进行扫描。而我们的很多对象都是朝生夕死的，如果分代的话，我们把新创建的对象放到某一地方，当GC的时候先把这块存“朝生夕死”对象的区域进行回收，这样就会腾出很大的空间出来。2. 年轻代中的GCHotSpot JVM把年轻代分为了三部分：1个Eden区和2个Survivor区（分别叫from和to）。默认比例为 8:1:1 ( 设置较大的Eden空间和较小的Survivor空间是合理的，大大提高了内存的使用率，缓解了复制算法的缺点 )。一般情况下，新创建的对象都会被分配到Eden区(一些大对象特殊处理,直接分配到老年代),这些对象经过第一次Minor GC后，如果仍然存活，将会被移到Survivor区。对象在Survivor区中每熬过一次Minor GC，年龄就会增加1岁，当它的年龄增加到一定程度时，就会被移动到年老代中。因为年轻代中的对象基本都是朝生夕死的(80%以上)，所以在年轻代的垃圾回收算法使用的是复制算法，复制算法的基本思想就是将内存分为两块，每次只用其中一块，当这一块内存用完，就将还活着的对象复制到另外一块上面。复制算法不会产生内存碎片。在GC开始的时候，对象只会存在于Eden区和名为“From”的Survivor区，Survivor区“To”是空的。紧接着进行GC，Eden区中所有存活的对象都会被复制到“To”，而在“From”区中，仍存活的对象会根据他们的年龄值来决定去向。年龄达到一定值(年龄阈值，可以通过-XX:MaxTenuringThreshold来设置)的对象会被移动到年老代中，没有达到阈值的对象会被复制到“To”区域。经过这次GC后，Eden区和From区已经被清空。这个时候，“From”和“To”会交换他们的角色，也就是新的“To”就是上次GC前的“From”，新的“From”就是上次GC前的“To”。不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，“To”区被填满之后，会将所有对象移动到年老代中。3. 一个对象的这一辈子我是一个普通的java对象，我出生在Eden区，在Eden区我还看到和我长的很像的小兄弟，我们在Eden区中玩了挺长时间。有一天Eden区中的人实在是太多了，我就被迫去了Survivor区的“From”区，自从去了Survivor区，我就开始漂了，有时候在Survivor的“From”区，有时候在Survivor的“To”区，居无定所。直到我18岁的时候，爸爸说我成人了，该去社会上闯闯了。于是我就去了年老代那边，年老代里，人很多，并且年龄都挺大的，我在这里也认识了很多人。在年老代里，我生活了20年(每次GC加一岁)，然后被回收。4. 有关年轻代的JVM参数-XX:NewSize和-XX:MaxNewSize用于设置年轻代的大小，建议设为整个堆大小的1/3或者1/4,两个值设为一样大。-XX:SurvivorRatio用于设置Eden和其中一个Survivor的比值，这个值也比较重要。-XX:+PrintTenuringDistribution这个参数用于显示每次Minor GC时Survivor区中各个年龄段的对象的大小。-XX:InitialTenuringThreshol和-XX:MaxTenuringThreshold用于设置晋升到老年代的对象年龄的最小值和最大值，每个对象在坚持过一次Minor GC之后，年龄就加1。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://maoyunfei.github.io/tags/JVM/"}]},{"title":"Java内存模型","slug":"java/jvm/4、Java内存模型","date":"2018-02-08T16:00:00.000Z","updated":"2018-03-04T09:38:51.297Z","comments":true,"path":"java/91e798bc/","link":"","permalink":"https://maoyunfei.github.io/java/91e798bc/","excerpt":"Java虚拟机规范中试图定义一种Java内存模型(Java Memory Model, JMM)来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。","text":"Java虚拟机规范中试图定义一种Java内存模型(Java Memory Model, JMM)来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。主内存与工作内存Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。这里的变量与Java编程中所说的变量有所区别，它包括了实例字段、静态字段和构成数组对象的元素，但不包括局部变量与方法参数，因为后者是线程私有的，不会被共享，自然就不会存在竞争问题。Java内存模型规定了所有的变量都存储在主内存(Main Memory)中。每条线程还有自己的工作内存(Working Memory)，线程的工作内存中保存了该被线程使用到的变量的主内存副本拷贝，线程对变量的所有操作(读取、赋值等)都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成，线程、主内存、工作内存三者的交互关系如下：这里所讲的主内存、工作内存与Java内存区域中的Java堆、栈、方法区并不是同一个层次的内存划分，这两者基本上是没有关系的，如果两者一定要勉强对应起来，那从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分，而工作内存则对应于虚拟机栈中的部分数据。从更低层次上说，主内存就直接对应于物理硬件的内存，而为了获取更好的运行速度，虚拟机可能会让工作内存优先存储于寄存器和高速缓存中，因为程序运行时主要访问读写的是工作内存。内存间的交互操作关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，Java内存模型中定义了以下8种操作来完成，虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的(对于double和long类型的变量来说，load、store、read和write操作在某些平台上允许有例外)。lock(锁定)：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。unlock(解锁)：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。read(读取)：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。load(载入)：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。use(使用)：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。assign(赋值)：作用于工作内存的变量，它把一个从执行引擎收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。store(存储)：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。write(写入)：作用于工作内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。对于volatile型变量的特殊规则关键字volatile可以说是Java虚拟机提供的最轻量级的同步机制。当一个变量定义为volatile之后，它将具备两个特性，第一是保证此变量对所有线程的可见性，这里的可见性是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。虽然volatile变量在各个线程中是一致的，但是Java里面的运算并非原子操作，所以volatile变量的运算在并发下不能保证安全性。由于volatile变量只能保证可见性，在不符合以下两条规则的运算场景中，我们仍然要通过加锁(使用synchronized或java.util.concurrent中的原子类)来保证原子性。运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。变量不需要与其他的状态变量共同参与不变约束。使用volatile变量的第二个语义是禁止指令重排序优化。选用volatile的意义大多数场景下volatile的总开销要比锁低，我们在volatile与锁之中选择的唯一依据仅仅是volatile的语义能否满足使用场景的需求。对long和double型变量的特殊规则Java内存模型要求lock、unlock、read、load、assign、use、store、write这8个操作都具有原子性，但是对于64位的数据结构(long和double)，在模型中特别定义了一条相对宽松的规定：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即允许虚拟机实现选择可以不保证64位数据结构的load、store、read和write这4个操作的原子性，这点就是所谓的long和double的非原子协定。原子性、可见性与有序性原子性：可见性：有序性：先行发生原则程序次序规则：管程锁定规则：volatile变量规则：线程启动规则：线程终止规则：线程中断规则：对象终极规则：传递性：","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://maoyunfei.github.io/tags/JVM/"}]},{"title":"垃圾收集算法","slug":"java/jvm/3、垃圾收集算法","date":"2018-02-07T16:00:00.000Z","updated":"2018-03-04T09:38:51.278Z","comments":true,"path":"java/ba66848b/","link":"","permalink":"https://maoyunfei.github.io/java/ba66848b/","excerpt":"在Java运行时区域中，程序计数器、虚拟机栈、本地方法栈3个区域随线程的而生，随线程而灭，因此这几个区域的内存分配和回收都具有确定性，在这几个区域内就不需要多考虑回收的问题，因此方法结束或者线程结束时，内存自然就跟随着回收了。而Java堆和方法区则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间才能知道会创建哪些对象，这部分内存的分配都是动态的，垃圾收集器所关注的是这部分内存。","text":"在Java运行时区域中，程序计数器、虚拟机栈、本地方法栈3个区域随线程的而生，随线程而灭，因此这几个区域的内存分配和回收都具有确定性，在这几个区域内就不需要多考虑回收的问题，因此方法结束或者线程结束时，内存自然就跟随着回收了。而Java堆和方法区则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间才能知道会创建哪些对象，这部分内存的分配都是动态的，垃圾收集器所关注的是这部分内存。1、判断对象是否“存活”1.1 引用计数法给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值减1；任何时刻计数器为0的对象就是不可能再被使用的。引用计数法的实现简单，判定效率也高，但是主流的Java虚拟机里面没有选用其来管理内存，最主要原因是它很难解决对象之间相互循环引用的问题。1.2 可达性分析算法这个算法的基本思想就是通过一系列的“GC Roots”对象作为起始点，从这些节点开始向下搜索。搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Roots没有任何引用链相连时(从图论来说，从GC Roots到这个对象不可达)，则证明此对象是不可用的。在Java语言中，可作为GC Roots的对象包括下面几种：虚拟机栈(栈帧中的本地变量表)中引用的对象。方法区中类静态属性引用的对象。方法区中常量引用的对象。本地方法栈中JNI(Native方法)引用的对象。1.3 四种引用类型引入分为强引用、软引用、弱引用、虚引用4种。强引用(Strong Reference)StringBuilder builder = new StringBuilder();强引用是默认引用类型，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。弱引用(Weak Reference)WeakReference&lt;StringBuilder&gt; weakBuilder = new WeakReference&lt;StringBuilder&gt;(builder);弱引用不是默认引用类型，如果需要使用弱引用，则要明确使用WeakReference类。弱引用用来描述非必需的对象。当内存中的对象只被弱引用时，它将可以被垃圾回收。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。软引用(Soft Reference)SoftReference&lt;StringBuilder&gt; softBuilder = new SoftReference&lt;StringBuilder&gt;(builder);软引用不是默认引用类型，如果需要使用软引用，则要明确使用SoftReference类。软引用用来描述一些还有用但是非必需的对象。对于软引用关联的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。虚引用(Phantom Reference)PhantomReference&lt;StringBuilder&gt; phantomBuilder = new PhantomReference&lt;StringBuilder&gt;(builder);虚引用不是默认引用类型，如果需要使用虚引用，则要明确使用PhantomReference类。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用的唯一目的就是能在这个对象呗收集器回收时收到一个系统通知。1.4 两次标记过程如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那么它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。 当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会放置在一个叫做F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。 这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，这样做的原因是，如果一个对象在finalize()方法中执行缓慢，或者发生了死循环，将很可能会导致F-Queue队列中其他对象永久处于等待，甚至导致整个内存回收系统崩溃。finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模标记，如果对象重新与引用链上任何一个对象建立关联，那么第二次标记时它将被移除出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的被回收了。注意： 任何一个对象的finalize()方法都只会被系统自动调用一次，如果对象面临下一次回收，它的finalize()方法不会被再次执行。1.5 回收方法区方法区的垃圾收集主要回收两部分内容：废弃常量和无用的类。 例如常量池中的字面值常量没有任何对象引用它，并且也没有其他地方引用了这个字面量，则这个变量就是废弃变量。类需要满足3个条件才能算是无用的类：(1)该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例；(2)加载该类的ClassLoader已经被回收；(3)该类对应的java.lang.Class对象没有在任何其他地方被引用，无法在任何地方通过反射访问该类的方法。虚拟机可以对废弃常量和无用的类进行回收，但并不是一定会回收，是否回收，由虚拟机提供的相关参数进行控制。2、垃圾收集算法2.1 标记-清除算法算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它的主要不足有两个：一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片。2.2 复制算法它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可。实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半。现在的商业虚拟机都采用这种收集算法来回收新生代。2.3 标记-整理算法复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低，所以一般不能用于老年代。根据老年代的特点，提出了“标记-整理”算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清除掉端边界以外的内存。2.4 分代收集算法当前商业虚拟机的垃圾收集都采用“分代收集”算法，根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清除”或者“标记-整理”算法来进行回收。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://maoyunfei.github.io/tags/JVM/"}]},{"title":"HotSpot虚拟机对象探秘","slug":"java/jvm/2、HotSpot虚拟机对象(创建、内存布局、定位)探秘","date":"2018-02-06T16:00:00.000Z","updated":"2018-03-04T09:38:51.293Z","comments":true,"path":"java/41b66951/","link":"","permalink":"https://maoyunfei.github.io/java/41b66951/","excerpt":"以常用的虚拟机HotSpot和常用的内存区域Java堆为例，深入探讨HotSpot虚拟机在Java堆中对象分配、布局和访问全过程。","text":"以常用的虚拟机HotSpot和常用的内存区域Java堆为例，深入探讨HotSpot虚拟机在Java堆中对象分配、布局和访问全过程。1. 对象的创建（1）虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。（2）在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需内存的大小在类加载完成后便可完全确定，为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。假设Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”(Bump the Pointer)。如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间分配给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”(Free List)。选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。因此，在使用Serial、ParNew等带Compact过程的收集器时，系统采用的分配算法是指针碰撞，而使用CMS这种基于Mark-Sweep算法的收集器是，通常采用空闲列表。（3）除如何划分可用空间外，还有另一个需要考虑的问题是对象创建在虚拟机中是非常频繁的行为，即使是仅仅修改一个指针所指向的位置，在并发情况下也并不是线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。解决这个问题有两种方案，一种是对分配空间的动作进行同步处理——实际上虚拟机采用CAS配上失败重试的方式保证更新操作的原子性；另一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲(Thread Local Allocation Buffer，TLAB)。哪个线程要分配内存，就在哪个线程的TLAB上分配，只有TLAB用完并重新分配新的TLAB时，才需要同步锁定。虚拟机是否使用TLAB，可以通过-XX:+/-UseTLAB参数来设定。（4）内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值(不包括对象头)，如果使用TLAB，这一工作过程也可以提前至TLAB分配时进行。这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。（5）接下来，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例，如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息存放在对象的对象头(Object Header)之中。根据虚拟机当前的运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。（6）在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从Java程序的视角来看，对象创建才刚刚开始——\\&lt;init>方法还没有执行，所有的字段都还为零。所以，一般来说，执行new指令之后会接着执行\\&lt;init>方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。2. 对象的内存布局在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头(Header)、实例数据(Instance Data)和对齐填充(Padding)。HotSpot虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据，如哈希码(HashCode)、GC分待年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。对象头的另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说，查找对象的元数据信息并不一定要经过对象本身。另外，如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中缺无法确定数据的大小。接下来的实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。这部分的存储顺序会受到虚拟机分配策略参数和字段在Java源码中定义顺序的影响。第三部分对齐填充并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。由于HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说，就是对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的整数倍，因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。3. 对象的访问定位Java程序需要通过栈上的reference数据来操作堆上的具体对象。由于reference类型在Java虚拟机规范中只规定了一个指向对象的引用，并没有定义这个引用应该通过何种方式去定位、访问堆中的对象的具体位置，所以对象访问方式也是取决于虚拟机实现而定的。目前主流的访问方式有使用句柄和直接指针两种。（1）如果使用句柄访问的话，那么Java堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与数据类型各自的具体地址信息。（2）如果使用直接指针访问，那么Java堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而reference中存储的直接就是对象地址。这两种对象访问方式各有优势，使用句柄来访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而reference本身不需要修改。使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。Sun HotSpot虚拟机是使用直接指针访问方式进行对象访问的。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://maoyunfei.github.io/tags/JVM/"}]},{"title":"运行时数据区域","slug":"java/jvm/1、运行时数据区域","date":"2018-02-05T16:00:00.000Z","updated":"2018-03-04T09:38:51.327Z","comments":true,"path":"java/20fd51d6/","link":"","permalink":"https://maoyunfei.github.io/java/20fd51d6/","excerpt":"Java虚拟机定义了程序执行期间使用的各种运行时数据区域。有的区域随着虚拟机的启动而存在并随着虚拟机的退出而销毁。有的数据区域是每个线程所独有的，随着线程的创建而创建并随着线程的退出而销毁。","text":"Java虚拟机定义了程序执行期间使用的各种运行时数据区域。有的区域随着虚拟机的启动而存在并随着虚拟机的退出而销毁。有的数据区域是每个线程所独有的，随着线程的创建而创建并随着线程的退出而销毁。1.1 程序计数器（program counter register）程序计数器是一块较小的内存区域，它可以看作是当前线程所执行的字节码的行号指示器。为了线程切换后能恢复到正确的执行位置，每个线程都需要有一个独立的程序计数器。位于线程私有内存。如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Native方法，这个计数器值则为Undefined。此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。1.2 Java虚拟机栈(JVM Stack)每一个Java虚拟机线程都有一个私有的Java虚拟机栈，与线程同时创建。Java虚拟机栈用于存储帧(frame)。每个方法在执行的同时都会创建一个栈帧(Stack Frame)用于存储局部变量表、操作数栈、动态链接、方法出口等信息。当方法执行完成的时候，帧就被销毁了，无论方法是正常返回还是抛出未捕获的异常而中断。每一个方法从调用直至执行完成的过程，就对应一个栈帧在虚拟机栈中入栈到出栈的过程。Java虚拟机栈的内存不需要是连续的经常所说的栈内存(Stack)指的就是虚拟机栈，或者说是虚拟机栈中的局部变量表部分。局部变量表存放了编译期可知的各种基本数据类型(boolean、byte、char、short、int、float、long、double)、对象引用(reference类型，它不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置)和returnAddress类型(指向了一条字节码指令的地址)。其中64位长度的long和double类型的数据会占用2个局部变量空间(Slot)，其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。Java虚拟机栈存在以下两种异常状况：如果线程计算请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常。如果虚拟机栈可以动态扩展(当前大部分的Java虚拟机都可动态扩展)，并且尝试扩展时无法申请到足够的内存或者没有足够的内存可用于为新线程创建初始Java虚拟机栈时，将抛出OutOfMemoryError异常。1.3 本地方法栈(Native Method Stack)本地方法栈与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行Java方法(也就是字节码)服务，而本地方法栈则为虚拟机使用到的native方法服务。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。1.4 堆(Heap)对于大多数应用来说，Java堆是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程所共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。Java堆是垃圾收集器管理的主要区域，因此也被称为“GC堆”。Java堆可以位于物理上不连续的内存空间中，只要逻辑上是连续的即可。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的(通过-Xmx和-Xms控制)。如果在堆中没有足够内存完成实例分配，并且堆也无法扩展时，将会抛出OutOfMemoryError异常。1.5 方法区(Method Area)方法区是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息，例如运行时常量池、属性和方法的数据、方法和构造器的代码，以及类和接口初始化和实例初始化中使用的特殊方法。方法区不需要连续的内存，可以选择固定大小或者可扩展，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载。如果方法区的内存无法满足分配需求时，将抛出OutOfMemoryError异常。1.6 运行时常量池(Run-Time Constant Pool)Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。每一个运行时常量池都从JVM方法区分配内存，类或接口的运行时常量池是在Java虚拟机创建类或接口时构建的。运行时常量池相对于Class文件常量池的一个重要特征是具备动态性，Java语言并不要求常量一定只有编译期才能产生，也就是并非预置入Class文件中的常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的变量放入池中，这种特性被开发人员利用得比较多的便是String类的intern()方法。当创建类或接口时，如果无法从JVM方法区申请足够的内存来构造运行时常量池时，将抛出OutOfMemoryError异常。重要总结：1. 永久代的变更到废除变更(字符串常量池移到了堆)：在JDK6以及其前期的JDK版本中，永久代用于存储类信息和字符串常量池。在JDK7中，永久代只用于存储类信息，字符串常量池在堆中存储。废弃(被Metaspace取代)：在JDK7以及其前期的JDK版本中，堆内存通常被分为两块区域，新生代(younggeneration)和老年代(old generation)：显示如下图：永久代(Permanent Generation forVM Matedata)和代码缓存区(code cache area)属于非堆内存。在JDK8中把存放元数据的永久代废弃，类信息存储到了在本地内存(native memory)中叫Metaspace的区域，JDK8中JVM堆内存结构就变成了如下：2. 方法区位置变化在JDK7以及之前的版本，方法区是永久代的一部分，在JDK8中方法区是Metaspace的一部分。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://maoyunfei.github.io/tags/JVM/"}]},{"title":"Hash冲突解决方案","slug":"other/Hash冲突解决方案","date":"2018-02-04T16:00:00.000Z","updated":"2018-03-04T09:40:15.520Z","comments":true,"path":"other/eebb0c54/","link":"","permalink":"https://maoyunfei.github.io/other/eebb0c54/","excerpt":"开放地址法(open addressing)","text":"开放地址法(open addressing)","categories":[{"name":"其他","slug":"other","permalink":"https://maoyunfei.github.io/categories/other/"}],"tags":[{"name":"hash","slug":"hash","permalink":"https://maoyunfei.github.io/tags/hash/"}]},{"title":"Java String Constant Pool (Java字符串常量池)","slug":"java/Java字符串常量池的概念和机制","date":"2018-02-03T16:00:00.000Z","updated":"2018-03-04T09:38:51.282Z","comments":true,"path":"java/e52216a2/","link":"","permalink":"https://maoyunfei.github.io/java/e52216a2/","excerpt":"当你在Java中声明一个新的字符串时，在这个场景下有一些有趣的事情发生。这是一个基本的字符串声明，我们创建了一个新的字符串变量employee并给它赋值。1String employee = \"Edgar Allen Poe\";","text":"当你在Java中声明一个新的字符串时，在这个场景下有一些有趣的事情发生。这是一个基本的字符串声明，我们创建了一个新的字符串变量employee并给它赋值。1String employee = \"Edgar Allen Poe\";Java不仅会创建变量employee，而且还会为内存中的字面值“Edgar Allen Poe”分配空间。内存中的这个区域被称为字符串常量池。它就像程序的其他部分可用的字符串值池。重用字符串常量池中的值现在，如果你创建了另一个变量，比如employee2，并且还给了它一个“Edgar Allen Poe”的值，那么Java只是重用了已经在池中的值。1String employee2 = \"Edgar Allen Poe\";你会注意到字符串常量池位于内存的堆部分。创建一个新的字符串实例如果你创建String类的新实例，则常量池的工作方式不同。让我们创建另一个变量employee3，并给它相同的字面值。但是，这次我们将创建一个String类的新实例：1String employee3 = new String(\"Edgar Allen Poe\");当这个代码被处理时，Java将会有所不同。而不是再次使用相同的字面值，它会在内存中创建一个新的值。在这种情况下，它不会在字符串常量池中创建它，而是在内存堆中创建它。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://maoyunfei.github.io/tags/Java基础/"}]},{"title":"java -jar启动命令","slug":"java/java -jar启动命令","date":"2018-02-02T16:00:00.000Z","updated":"2018-03-04T09:38:51.310Z","comments":true,"path":"java/309440ba/","link":"","permalink":"https://maoyunfei.github.io/java/309440ba/","excerpt":"以下是java启动命令的语法说明:（官方文档说明）","text":"以下是java启动命令的语法说明:（官方文档说明）以下是[options]的说明以及一些常用的:1、Standard Options 所有运行环境都支持-D 用于设置系统变量，由于spring boot会从系统属性读取属性，所以使用@Value(&quot;myDir&quot;)即可获取。-jar 用于指定启动的jar文件，jar文件的manifest必须知道Main-Class2、Nonstandard Options 由Java HotSpot VMs默认提供-Xmn 设置新生代的大小-Xms 设置内存分配池的最小值，即初始值-Xmx 设置内存分配池的最大值对于服务器部署，-Xms和-Xmx通常设置为相同的值。以下是[arguments]说明：语法为 –{name}={value}例如：java -jar app.jar --name=&quot;Spring&quot; 。由于spring boot会从command line argument读取属性，所以使用@Value(&quot;name&quot;)即可获取。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://maoyunfei.github.io/tags/Java基础/"}]},{"title":"Executor,ExecutorService和Executors间的不同","slug":"java/Executor，ExecutorService 和 Executors","date":"2018-02-01T16:00:00.000Z","updated":"2018-03-04T09:38:51.341Z","comments":true,"path":"java/8542269d/","link":"","permalink":"https://maoyunfei.github.io/java/8542269d/","excerpt":"文章摘录自博客java.util.concurrent.Executor, java.util.concurrent.ExecutorService, java.util.concurrent.Executors这三者均是 Java Executor 框架的一部分，用来提供线程池的功能。因为创建和管理线程非常心累，并且操作系统通常对线程数有限制，所以建议使用线程池来并发执行任务，而不是每次请求进来时创建一个线程。使用线程池不仅可以提高应用的响应时间，还可以避免&quot;java.lang.OutOfMemoryError: unable to create new native thread&quot;之类的错误。在 Java 1.5 时，开发者需要关心线程池的创建和管理，但在 Java 1.5 之后 Executor 框架提供了多种内置的线程池,例如：FixedThreadPool(包含固定数目的线程)，CachedThreadPool(可根据需要创建新的线程)等等。","text":"文章摘录自博客java.util.concurrent.Executor, java.util.concurrent.ExecutorService, java.util.concurrent.Executors这三者均是 Java Executor 框架的一部分，用来提供线程池的功能。因为创建和管理线程非常心累，并且操作系统通常对线程数有限制，所以建议使用线程池来并发执行任务，而不是每次请求进来时创建一个线程。使用线程池不仅可以提高应用的响应时间，还可以避免&quot;java.lang.OutOfMemoryError: unable to create new native thread&quot;之类的错误。在 Java 1.5 时，开发者需要关心线程池的创建和管理，但在 Java 1.5 之后 Executor 框架提供了多种内置的线程池,例如：FixedThreadPool(包含固定数目的线程)，CachedThreadPool(可根据需要创建新的线程)等等。ExecutorExecutor，ExecutorService，和 Executors 最主要的区别是 Executor 是一个抽象层面的核心接口(大致代码如下)。123public interface Executor &#123; void execute(Runnable command);&#125;不同于java.lang.Thread类将任务和执行耦合在一起， Executor 将任务本身和执行任务分离，可以阅读 difference between Thread and Executor 来了解 Thread 和 Executor 间更多的不同。ExecutorServiceExecutorService 接口 对 Executor 接口进行了扩展，提供了返回 Future 对象，终止，关闭线程池等方法。当调用shutDown方法时，线程池会停止接受新的任务，但会完成正在 pending 中的任务。Future 对象提供了异步执行，这意味着无需等待任务执行的完成，只要提交需要执行的任务，然后在需要时检查 Future 是否已经有了结果，如果任务已经执行完成，就可以通过 Future.get( ) 方法获得执行结果。需要注意的是，Future.get( ) 方法是一个阻塞式的方法，如果调用时任务还没有完成，会等待直到任务执行结束。通过 ExecutorService.submit( ) 方法返回的 Future 对象，还可以取消任务的执行。Future 提供了 cancel()方法用来取消执行 pending 中的任务。ExecutorService 部分代码如下：123456public interface ExecutorService extends Executor &#123; void shutdown(); &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException;&#125;ExecutorsExecutors 是一个工具类，类似于 Collections。提供工厂方法来创建不同类型的线程池，比如 FixedThreadPool 或 CachedThreadPool。Executors 部分代码：123456789public class Executors &#123; public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125;&#125;Executor vs ExecutorService vs Executors正如上面所说，这三者均是 Executor 框架中的一部分。Java 开发者很有必要学习和理解他们，以便更高效的使用 Java 提供的不同类型的线程池。总结一下这三者间的区别，以便大家更好的理解：Executor 和 ExecutorService 这两个接口主要的区别是：ExecutorService 接口继承了 Executor 接口，是 Executor 的子接口Executor 和 ExecutorService 第二个区别是：Executor 接口定义了 execute()方法用来接收一个Runnable接口的对象，而 ExecutorService 接口中的 submit()方法可以接受Runnable和Callable接口的对象。Executor 和 ExecutorService 接口第三个区别是 Executor 中的 execute()方法不返回任何结果，而 ExecutorService 中的 submit()方法可以通过一个 Future 对象返回运算结果。Executor 和 ExecutorService 接口第四个区别是除了允许客户端提交一个任务，ExecutorService 还提供用来控制线程池的方法。比如：调用 shutDown()方法终止线程池。可以通过 《Java Concurrency in Practice》 一书了解更多关于关闭线程池和如何处理 pending 的任务的知识。Executors 类提供工厂方法用来创建不同类型的线程池。比如: newSingleThreadExecutor()创建一个只有一个线程的线程池，newFixedThreadPool(int numOfThreads)来创建固定线程数的线程池，newCachedThreadPool()可以根据需要创建新的线程，但如果已有线程是空闲的会重用已有线程。总结下表列出了 Executor 和 ExecutorService 的区别：ExecutorExecutorServiceExecutor 是 Java 线程池的核心接口，用来并发执行提交的任务ExecutorService 是 Executor 接口的扩展，提供了异步执行和关闭线程池的方法提供execute()方法用来提交任务提供submit()方法用来提交任务execute()方法无返回值submit()方法返回Future对象，可用来获取任务执行结果不能取消任务可以通过Future.cancel()取消pending中的任务没有提供和关闭线程池有关的方法提供了关闭线程池的方法译者注个人觉得，利用 Executors 类提供的工厂方法来创建一个线程池是很方便，但对于需要根据实际情况自定义线程池某些参数的场景，就不太适用了。举个例子：当线程池中的线程均处于工作状态，并且线程数已达线程池允许的最大线程数时，就会采取指定的饱和策略来处理新提交的任务。总共有四种策略：AbortPolicy: 直接抛异常CallerRunsPolicy: 用调用者的线程来运行任务DiscardOldestPolicy: 丢弃线程队列里最近的一个任务，执行新提交的任务DiscardPolicy 直接将新任务丢弃如果使用 Executors 的工厂方法创建的线程池，那么饱和策略都是采用默认的 AbortPolicy，所以如果我们想当线程池已满的情况，使用调用者的线程来运行任务，就要自己创建线程池，指定想要的饱和策略，而不是使用 Executors 了。所以我们可以根据需要创建 ThreadPoolExecutor(ExecutorService接口的实现类) 对象，自定义一些参数，而不是调用 Executors 的工厂方法创建。当然，在使用 Spring 框架的项目中，也可以使用 Spring 提供的 ThreadPoolTaskExecutor 类来创建线程池。ThreadPoolTaskExecutor 与 ThreadPoolExecutor 类似，也提供了许多参数用来自定义线程池，比如：核心线程池大小，线程池最大数量，饱和策略，线程活动保持时间等等。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://maoyunfei.github.io/tags/Java基础/"}]},{"title":"equals()和hashCode()","slug":"java/equals()和hashCode()","date":"2018-01-31T16:00:00.000Z","updated":"2018-03-04T09:38:51.305Z","comments":true,"path":"java/554520e5/","link":"","permalink":"https://maoyunfei.github.io/java/554520e5/","excerpt":"原文链接默认情况下，Java超类java.lang.Object提供了两种比较对象的重要方法：equals()和hashCode()。在大型项目中实现多个类之间的交互时，这些方法变得非常有用。在本文中，我们将讨论这些方法之间的关系，它们的默认实现以及强制开发人员为每个方法提供自定义实现的情况。","text":"原文链接默认情况下，Java超类java.lang.Object提供了两种比较对象的重要方法：equals()和hashCode()。在大型项目中实现多个类之间的交互时，这些方法变得非常有用。在本文中，我们将讨论这些方法之间的关系，它们的默认实现以及强制开发人员为每个方法提供自定义实现的情况。方法定义和默认实现123456789public class Object &#123; ... public boolean equals(Object obj) &#123; return (this == obj); &#125; ... public native int hashCode(); ...&#125;equal()方法：JDK提供的默认实现是基于内存位置的 - 当且仅当它们存储在同一个内存地址中时，两个对象是相等的。hashCode()方法：默认实现是个本地方法。需要满足三个约定：(1) 无论什么时间，在同一个应用内执行多次应该返回相同的值。(2) 如果两个对象的equals()方法返回true，那么它们的hashCode()必须相同。(3) 如果两个对象的equals()方法返回false，那么它们的hashCode()可以相同，也可以不同。重写equals()实例：12345678910111213141516171819202122package com.programmer.gate.beans;public class Student &#123; private int id; private String name; public Student(int id, String name) &#123; this.name = name; this.id = id; &#125; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125;123456789@Overridepublic boolean equals(Object obj) &#123; if (obj == null) return false; if (!(obj instanceof Student)) return false; if (obj == this) return true; return this.getId() == ((Student) obj).getId();&#125;equals() With ArrayList123456789public class HashcodeEquals &#123; public static void main(String[] args) &#123; Student alex = new Student(1, \"Alex\"); List &lt; Student &gt; studentsLst = new ArrayList &lt; Student &gt; (); studentsLst.add(alex); System.out.println(\"Arraylist size = \" + studentsLst.size()); System.out.println(\"Arraylist contains Alex = \" + studentsLst.contains(new Student(1, \"Alex\"))); &#125;&#125;以上代码输出为：12Arraylist size = 1Arraylist contains Alex = true原因是ArrayList的contains()方法内部是调用的对象的equals()方法。重写hashCode()1234@Overridepublic int hashCode() &#123; return id;&#125;equals() With HashSet1234567891011public class HashcodeEquals &#123; public static void main(String[] args) &#123; Student alex1 = new Student(1, \"Alex\"); Student alex2 = new Student(1, \"Alex\"); HashSet &lt; Student &gt; students = new HashSet &lt; Student &gt; (); students.add(alex1); students.add(alex2); System.out.println(\"HashSet size = \" + students.size()); System.out.println(\"HashSet contains Alex = \" + students.contains(new Student(1, \"Alex\"))); &#125;&#125;以上代码输出为：12HashSet size = 1HashSet contains Alex = trueHashSet将其元素存储在内存桶中。每个桶都链接到一个特定的哈希码。当调用students.add(alex1)时，Java在存储桶中存储alex1并将其链接到alex1.hashCode()的值。现在任何时候，一个具有相同散列码的元素被插入到集合中，它将会替换掉alex1。但是，由于alex2具有不同的散列码，它将被存储在一个单独的存储桶中，并被视为完全不同的对象。现在，当HashSet在其中搜索一个元素时，它首先生成元素的哈希码并查找与这个哈希码对应的一个桶。这同样适用于HashMap，HashTable或任何使用散列机制来存储元素的数据结构。hashCode()用于散列到桶，equals()用于判断对象是否相同。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://maoyunfei.github.io/tags/Java基础/"}]},{"title":"Understanding Eureka Peer to Peer Communication","slug":"spring/spring cloud/Understanding Eureka Peer to Peer Communication","date":"2018-01-14T16:00:00.000Z","updated":"2018-03-04T11:51:48.765Z","comments":true,"path":"spring/7b50bf88/","link":"","permalink":"https://maoyunfei.github.io/spring/7b50bf88/","excerpt":"原文链接Eureka client尝试去和相同zone的Eureka Server通信。如果相同zone的server不存在或者通信有问题，client就会转到其他zone的server。一旦服务器开始接收流量，在服务器上执行的所有操作都将被复制到服务器所知道的所有对等节点。如果某个操作由于某种原因而失败，那么该信息将在服务器之间下一次心跳时核对后复制。当Eureka server恢复，它尝试从邻居节点获取所有实例的注册信息。如果从一个节点获取信息存在问题，在它放弃之前，它将尝试所有的对等节点。如果Eureka server能够成功获取所有实例信息，则会根据该信息设置应该接收的“续约”阈值。如果任何时候，“续约”低于设置的该阈值百分比(在15分钟内低于85%),Eureka server停止过期实例来保护当前实例的注册信息。在Neflix,上面的保护称为“自我保护”模式，主要用在一组client和Eureka server之间存在网络分区的情况下的保护。在这种场景下，Eureka server尝试去保护已经拥有的信息。如果发生大规模的故障，在这种情况下，可能会导致client获得已经不存在的实例。client必须确保它们对于返回不存在或不响应的实例的Eureka server具有弹性。在这些情况下，最好的保护是快速超时并尝试其他服务器。在这种情况下，如果Eureka server无法从邻居节点获取注册表信息，则会等待几分钟（5分钟），以便客户端可以注册其信息。server尽量不提供部分信息给client，而是通过将流量倾斜到仅一组实例并会导致容量问题。如此处所述，Eureka server使用在Eureka client和server之间使用的相同机制相互通信。","text":"原文链接Eureka client尝试去和相同zone的Eureka Server通信。如果相同zone的server不存在或者通信有问题，client就会转到其他zone的server。一旦服务器开始接收流量，在服务器上执行的所有操作都将被复制到服务器所知道的所有对等节点。如果某个操作由于某种原因而失败，那么该信息将在服务器之间下一次心跳时核对后复制。当Eureka server恢复，它尝试从邻居节点获取所有实例的注册信息。如果从一个节点获取信息存在问题，在它放弃之前，它将尝试所有的对等节点。如果Eureka server能够成功获取所有实例信息，则会根据该信息设置应该接收的“续约”阈值。如果任何时候，“续约”低于设置的该阈值百分比(在15分钟内低于85%),Eureka server停止过期实例来保护当前实例的注册信息。在Neflix,上面的保护称为“自我保护”模式，主要用在一组client和Eureka server之间存在网络分区的情况下的保护。在这种场景下，Eureka server尝试去保护已经拥有的信息。如果发生大规模的故障，在这种情况下，可能会导致client获得已经不存在的实例。client必须确保它们对于返回不存在或不响应的实例的Eureka server具有弹性。在这些情况下，最好的保护是快速超时并尝试其他服务器。在这种情况下，如果Eureka server无法从邻居节点获取注册表信息，则会等待几分钟（5分钟），以便客户端可以注册其信息。server尽量不提供部分信息给client，而是通过将流量倾斜到仅一组实例并会导致容量问题。如此处所述，Eureka server使用在Eureka client和server之间使用的相同机制相互通信。What happens during network outages between Peers?在peers之间失去网络通信的情况下，下列事情将发生peers之间的心跳复制可能会失败，并且Eureka server检测到这种情况然后进入自我保护模式来保护当前状态。注册可能发生在孤立的Eureka server上，有些client可能会反映新的注册信息，而其他client可能不会。(备注：由于孤立的Eureka server无法与其他server共享注册信息)在网络连接恢复到稳定状态后，情况会自动更正。当peers能够正常通信时，注册信息会自动被传输到没有这些信息的Eureka server上。(备注：即网络恢复后，Eureka server之间会自动同步共享注册信息)最重要的是，在网络中断期间，Eureka server尝试尽可能地具有弹性，但在此期间，client可能会有不同的server视图。(备注：Eureka server存在网络分区时，多个server之间无法同步注册信息，导致每个server上的信息可能不同，所以client可能会看到不同的server视图)","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://maoyunfei.github.io/tags/Spring-Cloud/"}]},{"title":"Understanding eureka client server communication","slug":"spring/spring cloud/Understanding eureka client server communication","date":"2018-01-13T16:00:00.000Z","updated":"2018-03-04T11:51:48.764Z","comments":true,"path":"spring/55dcd732/","link":"","permalink":"https://maoyunfei.github.io/spring/55dcd732/","excerpt":"原文链接About Instance Statuses默认的，Eureka client开始状态是 STARTING，这为了在实例能够提供服务之前，给它做应用初始化的时间。之后应用可以加入到可提供服务中通过将状态变更为 UP。ApplicationInfoManager.getInstance().setInstanceStatus(InstanceStatus.UP)应用也可以注册健康检查的callback，这可以选择性地将实例状态变为 DOWN。在Neflix中，还有一个 OUT_ OF_ SERVICE 状态,表明该实例不可提供服务中。","text":"原文链接About Instance Statuses默认的，Eureka client开始状态是 STARTING，这为了在实例能够提供服务之前，给它做应用初始化的时间。之后应用可以加入到可提供服务中通过将状态变更为 UP。ApplicationInfoManager.getInstance().setInstanceStatus(InstanceStatus.UP)应用也可以注册健康检查的callback，这可以选择性地将实例状态变为 DOWN。在Neflix中，还有一个 OUT_ OF_ SERVICE 状态,表明该实例不可提供服务中。Eureka Client OperationsEureka client首先尝试去和相同zone的Eureka Server连接，如果它不能发现服务端，它将转向其他zone。Eureka client通过以下方式和服务端交互RegisterEurek Client向Eureka server注册运行实例的信息。注册发生在第一次心跳(在30秒之后)。RenewEureka client需要通过每30秒发送心跳来“续约”。“续约”信号告诉Eureka server该实例仍然是可用的。如果server在90秒没有收到“续约”，他将从注册列表移除该实例。不去改变“续约”周期是明智的，因为server使用这个信息去判断在client和server之间的通信是否有普遍的问题。(备注：例如网络分区问题)Fetch RegistryEureka client从server获取注册信息并缓存在本地。之后，client使用这个信息去发现其他的服务。注册信息被周期性的更新(每30秒)，通过获取上一个读取周期和当前读取周期之间的增量更新。增量信息在server中保持较长时间（约3分钟），因此增量提取可能会再次返回相同的实例。Eureka client会自动处理重复的信息。获取增量之后，Eureka client和server通过比较server返回的实例数量来比对信息，如果由于某些原因信息不匹配，整个注册信息将重新提取。Eureka server缓存压缩的增量payload、整个注册表，以及每个应用程序相同的未压缩信息。payload支持JSON和XML格式。Eureka client通过jersey apache client获取压缩的JSON格式的信息。CancelEureka client在shutdown时给Eureka server发送一个cancel请求。Eureka server将从服务的实例注册信息中移除该实例，这有效得将实例从负载中移除。(备注：通过linux命令 kill -15应用程序将收到shutdown通知，kill -9则收不到通知)当Eureka client shutdown时，应用应该保证去调用以下方法。1DiscoveryManager.getInstance().shutdownComponent()Time LagEureka client的所有操作会花费一定时间反映到Eureka server和其他的clients。这是因为Eureka server上有payload的缓存，它定期刷新以获取新的信息。Eureka client也会定期刷新增量信息。因此，这可能花费长达2分钟的时间去把变更传播到所有的Eureka client。Communication mechanism默认的，Eureka client使用Jersey,XStream技术和JSON 格式的payload去和Eureka Server交流。你也可以使用你选择的机制来覆盖默认的。","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://maoyunfei.github.io/tags/Spring-Cloud/"}]},{"title":"Circuit Breaker--Hystrix","slug":"spring/spring cloud/Circuit Breaker--Hystrix","date":"2018-01-13T16:00:00.000Z","updated":"2018-03-04T11:51:48.763Z","comments":true,"path":"spring/da1cb016/","link":"","permalink":"https://maoyunfei.github.io/spring/da1cb016/","excerpt":"1. Hystrix Clients原文链接Netflix创建了一个实现了circuit breaker模式的叫做Hystrix的库。在一个微服务架构中通常有多层的服务调用，如下图。","text":"1. Hystrix Clients原文链接Netflix创建了一个实现了circuit breaker模式的叫做Hystrix的库。在一个微服务架构中通常有多层的服务调用，如下图。Microservice Graph一个底层的服务失败可以导致级联的直到用户的失败。在一个由 metrics.rollingStats.timeInMilliseconds(默认10秒)定义的默认窗口内，当请求一个指定的服务次数大于circuitBreaker.requestVolumeThreshold(默认20)并且失败率大于circuitBreaker.errorThresholdPercentage(默认50%)时，断路打开，请求不会发出。在发生错误或者短路时，开发者可以提供fallback。Hystrix fallback prevents cascading failures断路阻止了级联失败，并且允许高负载或者失败的服务有时间去恢复。fallback可以是另一个Hystrix保护的调用，静态数据或者空值。fallback可能是链式的，导致第一个fallback做的一些业务调用又回退到静态数据。1.1 如何引入Hystrix1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt;12345678910111213141516171819202122@SpringBootApplication@EnableCircuitBreakerpublic class Application &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(Application.class).web(true).run(args); &#125;&#125;@Componentpublic class StoreIntegration &#123; @HystrixCommand(fallbackMethod = &quot;defaultStores&quot;) public Object getStores(Map&lt;String, Object&gt; parameters) &#123; //do stuff that might fail &#125; public Object defaultStores(Map&lt;String, Object&gt; parameters) &#123; return /* something useful */; &#125;&#125;@HystrixCommand由一个名为“javanica”的Netflix contrib库提供。Spring Cloud自动将包含该注释的Spring bean包装在连接到Hystrix断路器的代理中。断路器计算何时打开和关闭电路，以及在发生故障时该怎么办。要配置@HystrixCommand，您可以使用带有@HystrixProperty注释列表的commandProperties属性。这里查看细节。Hystrix properties。1.2 传播安全上下文或者使用Spring Scopes如果你想传播一些线程本地上下文到@HystrixCommand中，用默认声明是不起作用的，因为它在一个线程池中执行命令。当调用者使用一些配置或者直接在注解中让它去使用一个不同的隔离策略，你可以切换Hystrix去使用同一个线程。例如：123456@HystrixCommand(fallbackMethod = &quot;stubMyService&quot;, commandProperties = &#123; @HystrixProperty(name=&quot;execution.isolation.strategy&quot;, value=&quot;SEMAPHORE&quot;) &#125;)...如果使用@SessionScope或@RequestScope，则同样适用。你将知道何时需要执行此操作，因为一个运行时异常表示无法找到该scope内的上下文。你也可以设置hystrix.shareSecurityContext属性为true。这样会自动配置一个Hystrix并发策略插件，它将会把SecurityContext从你的主线程传递到Hystrix命令使用的线程。Hystrix不支持注册多个hystrix并发策略，所以可以通过声明你自己的HystrixConcurrencyStrategy bean来扩展。Spring cloud将在你的spring上下文中查找并把它封装进它自己的插件。1.3 健康指标连接断路器的状态也暴露在应用程序的/health端点中。123456789&#123; &quot;hystrix&quot;: &#123; &quot;openCircuitBreakers&quot;: [ &quot;StoreIntegration::getStoresByLocationLink&quot; ], &quot;status&quot;: &quot;CIRCUIT_OPEN&quot; &#125;, &quot;status&quot;: &quot;UP&quot;&#125;1.4 Hystrix指标流添加spring-boot-starter-actuator依赖来启用Hystrix指标流。这将暴露管理端点/hystrix.stream。1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;2. Hystrix Dashboard原文链接Hystrix的主要优点之一就是它收集的关于每个HystrixCommand的指标集合。Hystrix仪表板以高效的方式显示每个断路器的运行状况。Hystrix Dashboard3. Hystrix超时和Ribbon Client原文链接当使用Hystrix命令包装Ribbon client，你需要确保配置的Hystrix超时时间大于配置的Ribbon超时时间，包括任何潜在的重试。例如，如果你的ribbon连接超时是1秒，ribbon client可能重试3次，然后Hystrix超时应该略大于3秒。3.1 如何引入Hystrix Dashboard1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-netflix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt;运行Hystrix Dashboard使用@EnableHystrixDashboard注释Spring Boot主类。然后访问/hystrix并将仪表板指向Hystrix客户端应用程序中的单个实例的/hystrix.stream端点。提示： 连接到使用HTTPS的/hystrix.stream端点时，服务器使用的证书必须由JVM信任。如果证书不可信，你必须将证书导入到JVM中，以便Hystrix仪表板能成功连接到流终端。3.2 Turbine从单个实例来看，Hystrix数据在整个系统的健康状况方面并不是很有用。Turbine是一个应用程序，它将所有相关的/hystrix.stream端点汇总到一个用于Hystrix仪表板的组合/turbine.stream中。单个实例通过Eureka找到。运行Turbine与使用@EnableTurbine注释注释主类一样简单(例如，在classpath引入spring-cloud-starter-netflix-turbine)。来自Turbine 1 wiki)的文档配置属性都适用。唯一的区别是turbine.instanceUrlSuffix不需要预先添加端口，因为这是自动处理的，除非turbine.instanceInsertPort=false。提示： 默认情况下，Turbine在注册实例上查找/hystrix.stream端点是通过在Eureka中查找其homePageUrl条目，然后将/hystrix.stream附加到上面。这意味着如果spring-boot-actuator在自己的端口上运行（这是默认的），对/hystrix.stream的调用将失败。要使Turbine在正确的端口找到Hystrix流，你需要将management.port添加到实例的metadata：1234eureka: instance: metadata-map: management.port: $&#123;management.port:8081&#125;配置turbine.appConfig是Turbine用于查找实例的Eureka中注册的serviceId的列表。Turbine stream然后在Hystrix仪表板中使用一个类似如下的url：http://my.turbine.sever:8080/turbine.stream?cluster=&lt;CLUSTERNAME&gt;(cluster参数可以被省略，如果名称是“default”)。cluster参数必须与turbine.aggregator.clusterConfig中的条目匹配。从Eureka返回的值是大写，因此，如果有一个名为“customers”的应用程序在Eureka注册，我们预计这个例子将起作用：1234turbine: aggregator: clusterConfig: CUSTOMERS appConfig: customersclusterName可以通过turb.clusterNameExpression中的SPEL表达式来定制，指定InstanceInfo的一个实例。默认值是appName，这意味着Eureka serviceId最终作为集群key(即customers的InstanceInfo具有“CUSTOMERS”的appName)。另一个示例是turb.clusterNameExpression=aSGName，它将从AWS ASG名称获取集群名称。另一个例子：12345turbine: aggregator: clusterConfig: SYSTEM,USER appConfig: customers,stores,ui,admin clusterNameExpression: metadata[&apos;cluster&apos;]在这种情况下，来自4个服务的集群名称将从其metadata映射中提取出来，预期包含“SYSTEM”和“USER”的值。要为所有应用程序使用“default”集群，你需要一个字符串文字表达式(使用单引号，如果使用YAML，则使用双引号进行转义):123turbine: appConfig: customers,stores clusterNameExpression: &quot;&apos;default&apos;&quot;Spring Cloud提供了一个spring-cloud-starter-netflix-turbine，它拥有运行Turbine服务器所需的所有依赖。只需创建一个Spring Boot应用程序并使用@EnableTurbine对其进行注释。提示： 默认情况下，Spring Cloud允许Turbine使用主机和端口来允许每个主机，每个集群使用多个进程。如果你希望Turbine中内置的本机Netflix行为不允许每个主机，每个集群（实例id的key是主机名）都有多个进程，那么请设置属性turbine.combineHostPort=false。3.3 Turbine Stream在某些环境下（例如在PaaS设置中），从所有分布式Hystrix命令中提取指标的传统Turbine模型不起作用。在这种情况下，你可能希望让你的Hystrix命令将度量标准推送到Turbine，Spring Cloud通过消息传递来实现。你需要在客户端上执行的操作是添加依赖关系到你选择的spring-cloud-netflix-hystrix-stream和spring-cloud-starter-stream-*(有关broker和如何配置客户端凭据的详细信息，请参阅Spring Cloud Stream文档，但它应该为本地broker开箱即用)。在server端只需创建一个Spring Boot应用程序并使用@EnableTurbineStream对其进行注释，默认情况下它将在8989端口(将Hystrix仪表板指向该端口，任何路径)运行。你可以使用server.port或turbine.stream.port来自定义端口。如果在classpath中也有spring-boot-starter-web和spring-boot-starter-actuator，那么你可以通过提供一个不同的management.port，在单独的端口(默认情况下使用Tomcat)打开Actuator端点。然后你可以将Hystrix仪表板指向Turbine Stream Server，而不是单独的Hystrix流。如果Turbine Stream在myhost上的8989端口上运行，则将http:// myhost:8989放在Hystrix仪表板的流输入字段中。电路将以它们各自的serviceId为前缀，接着是一个点，然后是电路名称。Spring Cloud提供了一个spring-cloud-starter-netflix-turbine-stream，它拥有运行Turbine Stream server所需的所有依赖关系，只需添加你选择的Stream绑定程序，例如：spring-cloud-starter-stream-rabbit。你需要Java 8来运行应用程序，因为它是基于Netty的。","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://maoyunfei.github.io/tags/Spring-Cloud/"}]},{"title":"客户端侧的负载均衡--Ribbon","slug":"spring/spring cloud/客户端侧的负载均衡--Ribbon","date":"2018-01-12T16:00:00.000Z","updated":"2018-03-04T11:51:48.763Z","comments":true,"path":"spring/d662598d/","link":"","permalink":"https://maoyunfei.github.io/spring/d662598d/","excerpt":"原文链接Ribbon是一个客户端负载均衡器，它可以让您对HTTP和TCP客户端的行为有很大的控制权。 Feign已经使用Ribbon，所以如果您使用的是@FeignClient，那么这个部分也适用。Ribbon中一个重要的概念是named client。Spring Cloud使用RibbonClientConfiguration根据需要为每个named client创建一个新的集合作为ApplicationContext，这包含（除其他外）ILoadBalancer，RestClient和ServerListFilter。","text":"原文链接Ribbon是一个客户端负载均衡器，它可以让您对HTTP和TCP客户端的行为有很大的控制权。 Feign已经使用Ribbon，所以如果您使用的是@FeignClient，那么这个部分也适用。Ribbon中一个重要的概念是named client。Spring Cloud使用RibbonClientConfiguration根据需要为每个named client创建一个新的集合作为ApplicationContext，这包含（除其他外）ILoadBalancer，RestClient和ServerListFilter。1. 如何引入Ribbon1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&lt;/dependency&gt;2. 自定义Ribbon Client你可以使用&lt;client&gt;.ribbon.*属性来配置ribbon client。Spring Cloud还允许你通过使用@RibbonClient声明其他配置（在RibbonClientConfiguration上）来完全控制客户端。例：1234@Configuration@RibbonClient(name = &quot;foo&quot;, configuration = FooConfiguration.class)public class TestConfiguration &#123;&#125;在这种情况下，ribbon client由已经在RibbonClientConfiguration中的组件和FooConfiguration中的任何组件（后者通常会覆盖前者）组成。(备注：使用RibbonClientConfiguration中的Bean和自定义的FooConfiguration中的Bean来配置ribbon client, FooConfiguration中的Bean会覆盖RibbonClientConfiguration中的Bean)注意： 上面的FooConfiguration必须用@Configuration，但是注意它不能在应用上下文被@ComponentScan扫描到，否则它将被所有@RibbonClient所共享。如果你使用@ComponentScan或者@SpringBootApplication,你需要避免它被包括在内(例如：把它放在一个单独的，不重叠的包或者在@ComponentScan中明确指定要扫描的包)。(备注：我是在src/main/java下新建一个package,将自定义的RibbonConfiguration配置Bean放在这个包下)Spring Cloud Netflix默认给ribbon提供以下的bean(BeanType beanName: ClassName):IClientConfig ribbonClientConfig: DefaultClientConfigImplIRule ribbonRule: ZoneAvoidanceRuleIPing ribbonPing: NoOpPingServerList&lt;Server&gt; ribbonServerList: ConfigurationBasedServerListServerListFilter&lt;Server&gt; ribbonServerListFilter: ZonePreferenceServerListFilterILoadBalancer ribbonLoadBalancer: ZoneAwareLoadBalancerServerListUpdater ribbonServerListUpdater: PollingServerListUpdater创建这些类型的bean并将其放置在@RibbonClient配置Bean（例如上面的FooConfiguration）中，可以覆盖所描述的每个bean。例：1234567@Configurationpublic class FooConfiguration &#123; @Bean public IPing ribbonPing(IClientConfig config) &#123; return new PingUrl(); &#125;&#125;这将用PingUrl代替NoOpPing。3. 使用properties来自定义Ribbon ClientSpring Cloud Netflix现在支持使用properties来定制Ribbon client，以便与Ribbon文档兼容。这使你可以在不同的环境启动时更改行为。支持的属性如下所列，并应以&lt;clientName&gt;.ribbon为前缀：NFLoadBalancerClassName: should implement ILoadBalancerNFLoadBalancerRuleClassName: should implement IRuleNFLoadBalancerPingClassName: should implement IPingNIWSServerListClassName: should implement ServerListNIWSServerListFilterClassName: should implement ServerListFilter提示： 在这些属性中定义的类优先于使用@RibbonClient(configuration=MyRibbonConfig.class)定义的bean和Spring Cloud Netflix提供的默认类。要为一个名为users的服务设置IRule，可以如下设置：123users: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRule4. Ribbon和Eureka一起使用当Eureka和Ribbon一起使用(例如，二者都在classpath), ribbonServerList被DiscoveryEnabledNIWSServerList的一个扩展覆盖了，该扩展的server list来自于Eureka。同时用NIWSDiscoveryPing替代IPing,通过Eureka来判断服务状态是否为UP。默认安装的ServerList是一个DomainExtractingServerList，这样做的目的是在不使用AWS AMI metadata(这是Netflix所依赖的)的情况下为负载均衡器提供物理metadata。默认情况下，server list将使用实例metadata中提供的“zone”信息构建（所以在远程客户端上设置eureka.instance.metadataMap.zone）,如果没有设置zone，可以使用服务器hostname的域名作为zone的代理（如果设置了标志approximateZoneFromHostname）。一旦zone信息可用，就可以在ServerListFilter中使用。默认情况下，它将用于定位与client位于同一个zone的server，因为默认值是ZonePreferenceServerListFilter。默认地client的zone的确定方式与远程实例相同，即通过eureka.instance.metadataMap.zone。提示： 如果没有设置zone数据，则根据client配置（而不是实例配置）进行猜测。我们把eureka.client.availabilityZones(这是一个从region名称到zone列表的map)，并取出实例所在region的第一个zone（即eureka.client.region，默认为“us-east-1“，为了与本地Netflix的兼容性）。5. Ribbon不和Eureka一起使用Eureka是一个远程服务发现的一个简便实现，所以你不需要在client端硬编码url，但是如果你不喜欢使用eureka，Ribbon和Feign仍然很合适。假设你已经为“stores”声明了@RibbonClient, 并且没有使用eureka。Ribbon client默认使用一个配置的server list,你可以像这样提供配置：application.yml123stores: ribbon: listOfServers: example.com,google.com6. 在Ribbon中禁用Eureka设置属性ribbon.eureka.enabled = false将明确禁止在Ribbon中使用Eureka。application.yml123ribbon: eureka: enabled: false7. 直接使用Ribbon API你可以直接使用LoadBalancerClient，例如：12345678910public class MyClass &#123; @Autowired private LoadBalancerClient loadBalancer; public void doStuff() &#123; ServiceInstance instance = loadBalancer.choose(&quot;stores&quot;); URI storesUri = URI.create(String.format(&quot;http://%s:%s&quot;, instance.getHost(), instance.getPort())); // ... do something with the URI &#125;&#125;8. Ribbon的缓存配置每个named client的Ribbon都有一个Spring Cloud维护的对应子应用程序上下文,这个应用程序的上下文是当对named client第一次请求时懒加载的。可以将此延迟加载行为更改为在启动时立即加载这些子应用程序上下文，通过指定Ribbon client的名称来配置。application.yml1234ribbon: eager-load: enabled: true clients: client1, client2, client3","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://maoyunfei.github.io/tags/Spring-Cloud/"}]},{"title":"Declarative REST Client--Feign","slug":"spring/spring cloud/Declarative REST Client--Feign","date":"2018-01-12T16:00:00.000Z","updated":"2018-03-04T11:51:48.764Z","comments":true,"path":"spring/2db5c206/","link":"","permalink":"https://maoyunfei.github.io/spring/2db5c206/","excerpt":"原文链接Feign是一个声明式的web服务client。它让编写web服务客户端更简单。使用Feign需要创建一个接口并在上面加注解。它有可插拔的注解支持，包括Feign的注解和JAX-RS的注解。Feign也支持可插拔式的编码器(encoder)和解码器(decoder)。Spring Cloud增加了对Spring MVC注解的支持，并且使用了Spring Web中默认使用的HttpMessageConverters。Spring Cloud整合Ribbon和Eureka，在使用Feign时提供负载均衡的http client。","text":"原文链接Feign是一个声明式的web服务client。它让编写web服务客户端更简单。使用Feign需要创建一个接口并在上面加注解。它有可插拔的注解支持，包括Feign的注解和JAX-RS的注解。Feign也支持可插拔式的编码器(encoder)和解码器(decoder)。Spring Cloud增加了对Spring MVC注解的支持，并且使用了Spring Web中默认使用的HttpMessageConverters。Spring Cloud整合Ribbon和Eureka，在使用Feign时提供负载均衡的http client。1.1 如何引入Feignpom.xml1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&lt;/dependency&gt;Application.java12345678910@SpringBootApplication@EnableEurekaClient@EnableFeignClientspublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125;StoreClient.java12345678@FeignClient(&quot;stores&quot;)public interface StoreClient &#123; @RequestMapping(method = RequestMethod.GET, value = &quot;/stores&quot;) List&lt;Store&gt; getStores(); @RequestMapping(method = RequestMethod.POST, value = &quot;/stores/&#123;storeId&#125;&quot;, consumes = &quot;application/json&quot;) Store update(@PathVariable(&quot;storeId&quot;) Long storeId, Store store);&#125;在@FeignClient注解中的值“stores”是一个任意client name,被用来创建一个Ribbon负载均衡器。你也可以使用url属性来指定一个URL。在application context中的bean名称是这个接口的全限定名。你可以使用@FeignClient注解的qualifier属性来指定你自己的别名。上面的Ribbon client会去获取“stores”服务的物理地址。如果你的应用是一个Eureka client，它将解析在Eureka server注册的服务。如果你不想使用Eureka, 你可以在你的配置文件中额外配置一个服务列表。1.2 覆盖Feign默认配置Spring Cloud Feign支持的一个重要概念是named client。每个Feign client都是集合的一部分，它们一起工作来连接远程服务.作为应用开发者，你使用@FeignClient注解来给这个集合一个名字。Spring Cloud使用FeignClientsConfiguration创建一个新的集合，作为每个指定客户端的ApplicationContext。这包括feign.Decoder,feign.Encoder,feign.Contract等。通过使用@FeignClient声明额外的配置（在FeignClientsConfiguration之上），Spring Cloud可让你完全控制Ribbon client。例如：1234@FeignClient(name = &quot;stores&quot;, configuration = FooConfiguration.class)public interface StoreClient &#123; //..&#125;在这种情况下，ribbon client由已经在FeignClientsConfiguration中的组件和FooConfiguration中的任何组件（后者将覆盖前者）组成。提示： FooConfiguration不需要@Configuraion注解。(备注：这一点和ribbon client完全相反，@RibbonClient的configuration必须被@Configuration注解。)它不能在应用上下文被@ComponentScan扫描到，否则它将被所有@FeignClient所共享。(备注：在这个特性上，和RibbonClient一样)name和url属性支持占位符,例如：1234@FeignClient(name = &quot;$&#123;feign.name&#125;&quot;, url = &quot;$&#123;feign.url&#125;&quot;)public interface StoreClient &#123; //..&#125;Spring Cloud Netflix默认提供以下bean (BeanType beanName：ClassName):Decoder feignDecoder: ResponseEntityDecoder(封装的SpringDecoder)Encoder feignEncoder: SpringEncoderLogger feignLogger: Slf4jLoggerContract feignContract: SpringMvcContractFeign.Builder feignBuilder: HystrixFeign.BuilderClient feignClient: 如果ribbon开启是LoadBalancerFeignClient, 否则是默认的feign client。通过设置feign.okhttp.enabled或feign.httpclient.enabled为true，可以使用OkHttpClient和ApacheHttpClient的feign client，并将它们放到classpath。Spring Cloud Netflix默认情况下不提供以下bean，但仍从应用程序上下文中查找这些类型的bean以创建feign client：Logger.LevelRetryerErrorDecoderRequest.OptionsCollection&lt;RequestInterceptor&gt;SetterFactory创建这些类型的bean并将其放入@FeignClient配置（例如上面的FooConfiguration）就能够覆盖所描述的每个bean。例如：123456789101112@Configurationpublic class FooConfiguration &#123; @Bean public Contract feignContract() &#123; return new feign.Contract.Default(); &#125; @Bean public BasicAuthRequestInterceptor basicAuthRequestInterceptor() &#123; return new BasicAuthRequestInterceptor(&quot;user&quot;, &quot;password&quot;); &#125;&#125;这用feign.Contract.Default代替了SpringMvcContract，并且将一个RequestInterceptor添加到RequestInterceptor的集合中。@FeignClient也可以使用配置属性进行配置。application.yml12345678910111213feign: client: config: feignName: connectTimeout: 5000 readTimeout: 5000 loggerLevel: full errorDecoder: com.example.SimpleErrorDecoder retryer: com.example.SimpleRetryer requestInterceptors: - com.example.FooRequestInterceptor - com.example.BarRequestInterceptor decode404: false默认配置可以在@EnableFeignClients属性defaultConfiguration中以与上述类似的方式指定。不同的是，这个配置将适用于所有的feign client。如果你更喜欢使用配置属性来配置所有@FeignClient，则可以使用default这个feign名称来创建配置属性。application.yml1234567feign: client: config: default: connectTimeout: 5000 readTimeout: 5000 loggerLevel: basic如果我们同时创建@Configuration bean和配置属性，配置属性将会胜出。它将覆盖@Configuration的值。但是如果你想改变@Configuration的优先级，你可以把feign.client.default-to-properties设为false。提示： 如果你需要在你的RequestInterceptor中使用ThreadLocal域变量，你要么把Hystrix的thread isolation strategy设为SEMAPHORE，要么在Feign中禁用Hystrix。application.yml123456789101112# To disable Hystrix in Feignfeign: hystrix: enabled: false# To set thread isolation to SEMAPHOREhystrix: command: default: execution: isolation: strategy: SEMAPHORE1.3 手动创建Feign Client在某些情况下，可能需要在不方便使用以上方法的时自定义你的Feign Client。在这种情况下，你可以使用Feign Builder API创建client。下面是一个例子，它创建两个具有相同接口的Feign client，但用每个客户端配置了一个单独的请求拦截器。12345678910111213141516171819202122@Import(FeignClientsConfiguration.class)class FooController &#123; private FooClient fooClient; private FooClient adminClient; @Autowired public FooController( Decoder decoder, Encoder encoder, Client client) &#123; this.fooClient = Feign.builder().client(client) .encoder(encoder) .decoder(decoder) .requestInterceptor(new BasicAuthRequestInterceptor(&quot;user&quot;, &quot;user&quot;)) .target(FooClient.class, &quot;http://PROD-SVC&quot;); this.adminClient = Feign.builder().client(client) .encoder(encoder) .decoder(decoder) .requestInterceptor(new BasicAuthRequestInterceptor(&quot;admin&quot;, &quot;admin&quot;)) .target(FooClient.class, &quot;http://PROD-SVC&quot;); &#125;&#125;提示： 在上面的例子中，FeignClientsConfiguration.class是由Spring Cloud Netflix提供的默认配置。PROD-SVC是client要请求的服务的名称。1.4 Feign的Hystrix支持如果Hystrix在classpath上并且feign.hystrix.enabled=true,那么Feign将用一个断路器来包装所有的方法。返回一个com.netflix.hystrix.HystrixCommand也是可以的。这将让你使用响应式模式(调用.toObservable()或.observe()或异步使用（调用.queue())要基于每个client禁用Hystrix支持，需要创建一个具有“prototype”范围的Feign.Builder，例如：12345678@Configurationpublic class FooConfiguration &#123; @Bean @Scope(&quot;prototype&quot;) public Feign.Builder feignBuilder() &#123; return Feign.builder(); &#125;&#125;警告： 在Spring Cloud Dalston发布之前，如果Hystrix在classpath上(备注：pom.xml中有spring-cloud-starter-hystrix依赖)，Feign默认情况下会将所有方法封装在断路器中。 Spring Cloud Dalston改变了这种默认行为，赞成采用选择加入的方式。(备注：Dalston前的版本中 feign.hystrix.enabled 默认值为true，Dalston及其之后的版本中 feign.hystrix.enabled 默认值为false)1.5 Feign Hystrix FallbacksHystrix支持fallback的概念：一个默认的代码路径，在断路或出现错误时执行。为给定的@FeignClient启用fallback功能，将fallback属性设置为实现fallback的类名称。你还需要将你的实现声明为Spring bean。123456789101112@FeignClient(name = &quot;hello&quot;, fallback = HystrixClientFallback.class)protected interface HystrixClient &#123; @RequestMapping(method = RequestMethod.GET, value = &quot;/hello&quot;) Hello iFailSometimes();&#125;static class HystrixClientFallback implements HystrixClient &#123; @Override public Hello iFailSometimes() &#123; return new Hello(&quot;fallback&quot;); &#125;&#125;如果需要访问fallback触发的原因，则可以使用@FeignClient中的fallbackFactory属性。123456789101112131415161718@FeignClient(name = &quot;hello&quot;, fallbackFactory = HystrixClientFallbackFactory.class)protected interface HystrixClient &#123; @RequestMapping(method = RequestMethod.GET, value = &quot;/hello&quot;) Hello iFailSometimes();&#125;@Componentstatic class HystrixClientFallbackFactory implements FallbackFactory&lt;HystrixClient&gt; &#123; @Override public HystrixClient create(Throwable cause) &#123; return new HystrixClientWithFallBackFactory() &#123; @Override public Hello iFailSometimes() &#123; return new Hello(&quot;fallback; reason was: &quot; + cause.getMessage()); &#125; &#125;; &#125;&#125;警告： Feign的fallback和Hystrix的fallback工作有一个限制。fallback当前不支持返回类型为com.netflix.hystrix.HystrixCommand和rx.Observable的方法。1.6 Feign和@Primary当使用Feign的Hystrix fallback时，ApplicationContext中有多个同一类型的Bean。这将会导致@Autowired不工作，因为没有一个确切的bean或者一个标记为primary的。要解决这个问题，Spring Cloud Netflix让所有的Feign实例为@Primary，所以Spring Framework将知道注入哪个bean。在一些情况下，这可能是不可取的。要关闭这个特性，设置@FeignClient的primary属性为false。1234@FeignClient(name = &quot;hello&quot;, primary = false)public interface HelloClient &#123; // methods here&#125;1.7 Feign的继承支持Feign通过单继承接口支持样板apis。这允许将通用操作分组为方便的基础接口。UserService.java12345public interface UserService &#123; @RequestMapping(method = RequestMethod.GET, value =&quot;/users/&#123;id&#125;&quot;) User getUser(@PathVariable(&quot;id&quot;) long id);&#125;UserResource.java1234@RestControllerpublic class UserResource implements UserService &#123;&#125;UserClient.java123456package project.user;@FeignClient(&quot;users&quot;)public interface UserClient extends UserService &#123;&#125;提示： 一般不建议在server和client之间共享一个接口。它引入了紧密的耦合，而且实际上以当前的形式用于Spring MVC并不起作用（方法参数映射不被继承）。1.8 Feign请求响应的压缩你可以考虑为你的Feign请求开启请求或响应的GZIP压缩。你可以通过开启以下属性来完成此操作：12eign.compression.request.enabled=truefeign.compression.response.enabled=trueFeign请求压缩为你提供了类似于设置Web服务器的设置：123feign.compression.request.enabled=truefeign.compression.request.mime-types=text/xml,application/xml,application/jsonfeign.compression.request.min-request-size=2048这些属性允许你选择压缩的media type和最小请求阈值长度。1.9 Feign日志为每一个Feign client创建一个logger，logger默认的名字是用来创建Feign client的接口的全限定类名。Feign的日志只响应DEBUG级别。application.ymllogging.level.project.user.UserClient: DEBUG你可以为每一个client配置一个Logger.Level对象，告诉Feign去记录什么。有以下选择：NONE, 不记录 (默认).BASIC, 只记录请求方法、URL、响应状态码和执行时间。HEADERS, 记录请求头和响应头的基本信息。FULL, 记录请求和响应的headers、body和metadata。例如：以下将设置Logger.Level设为FULL:1234567@Configurationpublic class FooConfiguration &#123; @Bean Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125;&#125;","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://maoyunfei.github.io/tags/Spring-Cloud/"}]},{"title":"具有负载均衡功能的RestTemplate","slug":"spring/spring cloud/具有负载均衡功能的RestTemplate","date":"2018-01-11T16:00:00.000Z","updated":"2018-03-04T11:51:48.761Z","comments":true,"path":"spring/96993ac3/","link":"","permalink":"https://maoyunfei.github.io/spring/96993ac3/","excerpt":"原文链接通过@LoadBalanced和@Bean修饰可以生成一个具有负载均衡功能的RestTemplate。12345678@Configurationpublic class MyConfiguration &#123; @LoadBalanced @Bean RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125;","text":"原文链接通过@LoadBalanced和@Bean修饰可以生成一个具有负载均衡功能的RestTemplate。12345678@Configurationpublic class MyConfiguration &#123; @LoadBalanced @Bean RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125;提示： 从Spring Boot 1.4开始不再提供自动配置的RestTemplate Bean,你必须自己创建。Retrying Failed RequestsRestTemplatede的失败重试,默认是不可用的，如果需要开启，需要设置spring.cloud.loadbalancer.retry.enabled=true并且添加Spring Retry依赖。1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt;&lt;/dependency&gt;具有负载均衡功能的RestTemplate将遵循Ribbon关于重试的配置，如client.ribbon.MaxAutoRetries，client.ribbon.MaxAutoRetriesNextServer，client.ribbon.OkToRetryOnAllOperations。Ribbon具体的配置。Multiple RestTemplate objects原文链接如果需要同时使用具有负载均衡功能和普通的RestTemplate，可以如下配置：1234567891011121314151617181920212223242526272829303132@Configurationpublic class MyConfiguration &#123; @LoadBalanced @Bean RestTemplate loadBalanced() &#123; return new RestTemplate(); &#125; @Primary @Bean RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125;public class MyClass &#123; @Autowired private RestTemplate restTemplate; @Autowired @LoadBalanced private RestTemplate loadBalanced; public String doOtherStuff() &#123; return loadBalanced.getForObject(&quot;http://stores/stores&quot;, String.class); &#125; public String doStuff() &#123; return restTemplate.getForObject(&quot;http://example.com&quot;, String.class); &#125;&#125;RestTemplate bean上的@Primary注解表明当@Autowired时没有特殊修饰符时使用该实例。","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://maoyunfei.github.io/tags/Spring-Cloud/"}]},{"title":"服务发现--Netflix Eureka","slug":"spring/spring cloud/服务发现--Netflix Eureka","date":"2018-01-10T16:00:00.000Z","updated":"2018-03-04T11:51:48.765Z","comments":true,"path":"spring/6213b905/","link":"","permalink":"https://maoyunfei.github.io/spring/6213b905/","excerpt":"Eureka Clients原文链接如何引入Eureka Client1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt;","text":"Eureka Clients原文链接如何引入Eureka Client1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt;注册到Eurake当一个client注册到Eureka，它提供自己的meta-data，例如host,port,health indicator URL,home page等。Eureka接受心跳信息从属于一个服务的每个实例。如果心跳在一个配置的时间内失败，实例将从注册中心移除。12345678@EnableEurekaClient@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125;application.yml1234eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/Authenticating with the Eureka Server在URLs中加上认证信息，如```http://user:password@localhost:8761/eureka```。12345678* Why is it so Slow to Register a Service?一个实例涉及和注册中心的周期性的心跳，默认周期为30s。一个服务不被客户端发现直到实例，服务端和客户端都在它们本地缓存有了相同的metadata。你可以用```eureka.instance.leaseRenewalIntervalInSeconds```来改变周期，这会加速client和其他server的连接进程。在生产环境最好遵守默认配置，因为在server有一些关于续约周期的内部计算。## &lt;span id=&quot;1.2&quot;&gt;Eureka Server[原文链接](http://cloud.spring.io/spring-cloud-static/Dalston.SR4/single/spring-cloud.html#spring-cloud-eureka-server)### 如何引入Eureka Serverorg.springframework.cloudspring-cloud-starter-eureka-server1### 如何运行一个Eureka Server@SpringBootApplication@EnableEurekaServerpublic class Application {public static void main(String[] args) { new SpringApplicationBuilder(Application.class).web(true).run(args); } }123456Eureka Server有一个UI主页来查看注册的服务信息，```/eureka/```。### Standalone Mode在单机模式下，更喜欢关闭client端的行为，如`registerWithEureka`，`fetchRegistry`，所以它不会试图去到达它的peers。*application.yml (Standalone Eureka Server)*server:port: 8761eureka:instance:hostname: localhostclient:registerWithEureka: falsefetchRegistry: falseserviceUrl:defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/123456注意`serverUrl`指向本地实例的host。### Peer AwarenessEureka可以变得高可用通过运行多个实例并让它们相互注册。事实上，这是默认的行为，所以我们只需要给peer添加一个有效的`serviceUrl`。*application.yml (Two Peer Aware Eureka Servers)*spring:profiles: peer1eureka:instance:hostname: peer1client:serviceUrl:defaultZone: http://peer2/eureka/spring:profiles: peer2eureka:instance:hostname: peer2client:serviceUrl:defaultZone: http://peer1/eureka/`你可以添加多个peers到一个系统，只要它们互相至少有一边连接，它们将互相同步注册信息。如果peers存在物理分区，该系统原则上可能存在裂脑问题。Prefer IP Address通常，Eureka更喜欢暴露它的IP地址而不是它的hostname，设置eureka.instance.preferIpAddress为true,当注册时，它将使用它的IP地址而不是hostname。","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://maoyunfei.github.io/tags/Spring-Cloud/"}]},{"title":"spring boot读取配置文件顺序","slug":"spring/spring boot/spring boot读取配置文件顺序","date":"2018-01-09T16:00:00.000Z","updated":"2018-03-04T10:00:30.115Z","comments":true,"path":"spring/5886b3b2/","link":"","permalink":"https://maoyunfei.github.io/spring/5886b3b2/","excerpt":"","text":"","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://maoyunfei.github.io/tags/Spring-Boot/"}]},{"title":"spring boot内嵌tomcat访问日志常用配置","slug":"spring/spring boot/spring boot内嵌tomcat访问日志常用配置","date":"2018-01-08T16:00:00.000Z","updated":"2018-03-04T10:05:02.869Z","comments":true,"path":"spring/76c7f26f/","link":"","permalink":"https://maoyunfei.github.io/spring/76c7f26f/","excerpt":"tomcat access log 常用配置123456789# tomcat access log configserver: tomcat: accesslog: enabled: true #是否开启日志 directory: /tmp/accesslogs/mobile-site #日志存储目录 pattern: &apos;%t %a %A %m %U%q %s %D %I %B&apos; #日志格式 prefix: access #日志文件前缀 rename-on-rotate: true #是否启用日志轮转","text":"tomcat access log 常用配置123456789# tomcat access log configserver: tomcat: accesslog: enabled: true #是否开启日志 directory: /tmp/accesslogs/mobile-site #日志存储目录 pattern: &apos;%t %a %A %m %U%q %s %D %I %B&apos; #日志格式 prefix: access #日志文件前缀 rename-on-rotate: true #是否启用日志轮转pattern的配置：%a - Remote IP address，远程ip地址，注意不一定是原始ip地址，中间可能经过nginx等的转发%A - Local IP address，本地ip%b - Bytes sent, excluding HTTP headers, or ‘-‘ if no bytes were sent%B - Bytes sent, excluding HTTP headers%h - Remote host name (or IP address if enableLookups for the connector is false)，远程主机名称(如果resolveHosts为false则展示IP)%H - Request protocol，请求协议%l - Remote logical username from identd (always returns ‘-‘)%m - Request method，请求方法（GET，POST）%p - Local port，接受请求的本地端口%q - Query string (prepended with a ‘?’ if it exists, otherwise an empty string%r - First line of the request，HTTP请求的第一行（包括请求方法，请求的URI）%s - HTTP status code of the response，HTTP的响应代码，如：200,404%S - User session ID%t - Date and time, in Common Log Format format，日期和时间，Common Log Format格式%u - Remote user that was authenticated%U - Requested URL path%v - Local server name%D - Time taken to process the request, in millis，处理请求的时间，单位毫秒%T - Time taken to process the request, in seconds，处理请求的时间，单位秒%I - current Request thread name (can compare later with stacktraces)，当前请求的线程名，可以和打印的log对比查找问题","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://maoyunfei.github.io/tags/Spring-Boot/"}]},{"title":"\\@ConfigurationProperties和@EnableConfigurationProperties","slug":"spring/spring boot/@ConfigurationProperties和@EnableConfigurationProperties","date":"2018-01-07T16:00:00.000Z","updated":"2018-03-04T11:55:21.417Z","comments":true,"path":"spring/4b6e90e4/","link":"","permalink":"https://maoyunfei.github.io/spring/4b6e90e4/","excerpt":"在Spring Boot中使用 @ConfigurationProperties 注解开始创建一个@ConfigurationProperties bean:1234567891011121314151617@ConfigurationProperties(locations = \"classpath:mail.properties\", ignoreUnknownFields = false, prefix = \"mail\")public class MailProperties &#123; public static class Smtp &#123; private boolean auth; private boolean starttlsEnable; // ... getters and setters &#125; @NotBlank private String host; private int port; private String from; private String username; private String password; @NotNull private Smtp smtp; // ... getters and setters&#125;","text":"在Spring Boot中使用 @ConfigurationProperties 注解开始创建一个@ConfigurationProperties bean:1234567891011121314151617@ConfigurationProperties(locations = \"classpath:mail.properties\", ignoreUnknownFields = false, prefix = \"mail\")public class MailProperties &#123; public static class Smtp &#123; private boolean auth; private boolean starttlsEnable; // ... getters and setters &#125; @NotBlank private String host; private int port; private String from; private String username; private String password; @NotNull private Smtp smtp; // ... getters and setters&#125;…从如下属性中创建(mail.properties):1234567mail.host=localhostmail.port=25mail.smtp.auth=falsemail.smtp.starttls-enable=falsemail.from=me@localhostmail.username=mail.password=方案一1234567891011121314151617181920212223@Configuration@ConfigurationProperties(locations = \"classpath:mail.properties\", prefix = \"mail\")public class MailConfiguration &#123; public static class Smtp &#123; private boolean auth; private boolean starttlsEnable; // ... getters and setters &#125; @NotBlank private String host; private int port; private String from; private String username; private String password; @NotNull private Smtp smtp; // ... getters and setters @Bean public JavaMailSender javaMailSender() &#123; // omitted for readability &#125;&#125;方案二123456789@Configuration@EnableConfigurationProperties(MailProperties.class) public class MailConfiguration &#123; @Autowired private MailProperties mailProperties; @Bean public JavaMailSender javaMailSender() &#123; // omitted for readability &#125; &#125;注意: @EnableConfigurationProperties这个注解告诉Spring Boot能支持指定特定类型的@ConfigurationProperties。如果不指定会看到如下异常:1org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [demo.mail.MailProperties] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: &#123;@org.springframework.beans.factory.annotation.Autowired(required=true)&#125;方案一不使用@EnableConfigurationProperties注解，使用@Configuration或者@Component注解使其被component scan发现。方案二使用@EnableConfigurationProperties注解，使其指定的配置类被EnableConfigurationPropertiesImportSelector注册到应用上下文。","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://maoyunfei.github.io/tags/Spring-Boot/"}]},{"title":"\\@Async注解的自定义Executor","slug":"spring/spring boot/@Async注解的自定义Executor","date":"2018-01-06T16:00:00.000Z","updated":"2018-03-04T11:55:21.422Z","comments":true,"path":"spring/555f9026/","link":"","permalink":"https://maoyunfei.github.io/spring/555f9026/","excerpt":"How To Do @Async in Spring默认情况下，Spring使用SimpleAsyncTaskExecutor来异步运行这些方法。默认值可以在两个级别重写 - 在应用程序级别或单个方法级别。","text":"How To Do @Async in Spring默认情况下，Spring使用SimpleAsyncTaskExecutor来异步运行这些方法。默认值可以在两个级别重写 - 在应用程序级别或单个方法级别。","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://maoyunfei.github.io/tags/Spring-Boot/"}]},{"title":"Linux wc命令","slug":"linux/linux command/wc","date":"2018-01-05T16:00:00.000Z","updated":"2018-03-04T09:52:45.666Z","comments":true,"path":"linux/3bb57d1c/","link":"","permalink":"https://maoyunfei.github.io/linux/3bb57d1c/","excerpt":"Linux wc命令用于计算字数。利用wc指令我们可以计算文件的Byte数、字数、或是行数，若不指定文件名称、或是所给予的文件名为“-”，则wc指令会从标准输入设备读取数据。","text":"Linux wc命令用于计算字数。利用wc指令我们可以计算文件的Byte数、字数、或是行数，若不指定文件名称、或是所给予的文件名为“-”，则wc指令会从标准输入设备读取数据。语法wc [-clw][--help][--version][文件...]参数：-c或–bytes或–chars 只显示Bytes数。-l或–lines 只显示行数。-w或–words 只显示字数。–help 在线帮助。–version 显示版本信息。实例统计单个文件在默认的情况下，wc将计算指定文件的行数、字数，以及字节数。使用的命令为：wc testfile先查看testfile文件的内容，可以看到：123456789$ cat testfile Linux networks are becoming more and more common, but scurity is often an overlooked issue. Unfortunately, in today’s environment all networks are potential hacker targets, fro0m tp-secret military research networks to small home LANs. Linux Network Securty focuses on securing Linux in a networked environment, where the security of the entire network needs to be considered rather than just isolated machines. It uses a mix of theory and practicl techniques to teach administrators how to install and use security applications, as well as how the applcations work and why they are necesary.使用wc统计，结果如下：123$ wc testfile # testfile文件的统计信息3 92 598 testfile # testfile文件的行数为3、单词数92、字节数598其中，3 个数字分别表示testfile文件的行数、单词数，以及该文件的字节数。统计多个文件如果想同时统计多个文件的信息，例如同时统计testfile、testfile_1、testfile_2，可使用如下命令：wc testfile testfile_1 testfile_2 #统计三个文件的信息输出结果如下：123456$ wc testfile testfile_1 testfile_2 #统计三个文件的信息 3 92 598 testfile #第一个文件行数为3、单词数92、字节数598 9 18 78 testfile_1 #第二个文件的行数为9、单词数18、字节数78 3 6 32 testfile_2 #第三个文件的行数为3、单词数6、字节数32 15 116 708 总用量 #三个文件总共的行数为15、单词数116、字节数708统计管道输出12ls -l | wc -lps -ef | grep java | wc -l","categories":[{"name":"Linux","slug":"linux","permalink":"https://maoyunfei.github.io/categories/linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"https://maoyunfei.github.io/tags/Linux命令/"}]},{"title":"Linux top命令","slug":"linux/linux command/top","date":"2018-01-04T16:00:00.000Z","updated":"2018-03-04T09:52:45.665Z","comments":true,"path":"linux/4c6cbbb6/","link":"","permalink":"https://maoyunfei.github.io/linux/4c6cbbb6/","excerpt":"Linux top命令用于实时显示 process 的动态。使用权限：所有使用者。","text":"Linux top命令用于实时显示 process 的动态。使用权限：所有使用者。语法top [-] [d delay] [q] [c] [S] [s] [i] [n] [b]参数说明：d : 改变显示的更新速度，或是在交谈式指令列( interactive command)按 sq : 没有任何延迟的显示速度，如果使用者是有 superuser 的权限，则 top 将会以最高的优先序执行c : 切换显示模式，共有两种模式，一是只显示执行档的名称，另一种是显示完整的路径与名称S : 累积模式，会将己完成或消失的子行程 ( dead child process ) 的 CPU time 累积起来s : 安全模式，将交谈式指令取消, 避免潜在的危机i : 不显示任何闲置 (idle) 或无用 (zombie) 的行程n : 更新的次数，完成后将会退出 topb : 批次档模式，搭配 “n” 参数一起使用，可以用来将 top 的结果输出到档案内实例显示进程信息# top显示完整命令# top -c以批处理模式显示程序信息# top -b以累积模式显示程序信息# top -S设置信息更新次数123top -n 2//表示更新两次后终止更新显示设置信息更新时间123# top -d 3//表示更新周期为3秒显示指定的进程信息123# top -p 139//显示进程号为139的进程信息，CPU、内存占用率等显示更新十次后退出top -n 10使用者将不能利用交谈式指令来对行程下命令top -s将更新显示二次的结果输入到名称为 top.log 的档案里top -n 2 -b &lt; top.log提示：根据top命令显示的内容可以进一步根据pid查看具体是哪个进程，使用命令ps aux | grep {pid}","categories":[{"name":"Linux","slug":"linux","permalink":"https://maoyunfei.github.io/categories/linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"https://maoyunfei.github.io/tags/Linux命令/"}]},{"title":"Linux ps命令","slug":"linux/linux command/ps","date":"2018-01-03T16:00:00.000Z","updated":"2018-03-04T09:52:45.665Z","comments":true,"path":"linux/56aee8cb/","link":"","permalink":"https://maoyunfei.github.io/linux/56aee8cb/","excerpt":"Linux ps命令用于显示当前进程(process)的状态","text":"Linux ps命令用于显示当前进程(process)的状态语法ps [options] [--help]参数ps 的参数非常多, 在此仅列出几个常用的参数并大略介绍含义-A 列出所有的行程-u 显示指定用户的进程-e 等于“-A”-f 以格式化显示a 显示所有涉及终端的进程信息u 显示面向用户的输出x 显示没有终端的进程au(x) 输出格式 :USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND实例显示进程信息1234567891011121314# ps -A 显示进程信息PID TTY TIME CMD 1 ? 00:00:02 init 2 ? 00:00:00 kthreadd 3 ? 00:00:00 migration/0 4 ? 00:00:00 ksoftirqd/0 5 ? 00:00:00 watchdog/0……省略部分结果31160 ? 00:00:00 dhclient31211 ? 00:00:00 aptd31302 ? 00:00:00 sshd31374 pts/2 00:00:00 bash31396 pts/2 00:00:00 ps显示指定用户信息1234567891011121314# ps -u root 显示root进程用户信息 PID TTY TIME CMD 1 ? 00:00:02 init 2 ? 00:00:00 kthreadd 3 ? 00:00:00 migration/0 4 ? 00:00:00 ksoftirqd/0 5 ? 00:00:00 watchdog/0……省略部分结果 31160 ? 00:00:00 dhclient31211 ? 00:00:00 aptd31302 ? 00:00:00 sshd31374 pts/2 00:00:00 bash31397 pts/2 00:00:00 ps显示所有进程信息，连同命令行12345678910111213# ps -ef 显示所有命令，连带命令行UID PID PPID C STIME TTY TIME CMDroot 1 0 0 10:22 ? 00:00:02 /sbin/initroot 2 0 0 10:22 ? 00:00:00 [kthreadd]root 3 2 0 10:22 ? 00:00:00 [migration/0]root 4 2 0 10:22 ? 00:00:00 [ksoftirqd/0]root 5 2 0 10:22 ? 00:00:00 [watchdog/0]……省略部分结果root 31302 2095 0 17:42 ? 00:00:00 sshd: root@pts/2 root 31374 31302 0 17:42 pts/2 00:00:00 -bashroot 31400 1 0 17:46 ? 00:00:00 /usr/bin/python /usr/sbin/aptdroot 31407 31374 0 17:48 pts/2 00:00:00 ps -efps与grep常用组合用法，查找特定进程123456# ps -ef | grep sshUID PID PPID C STIME TTY TIME CMDroot 2720 1 0 Nov02 ? 00:00:00 /usr/sbin/sshdroot 17394 2720 0 14:58 ? 00:00:00 sshd: root@pts/0 root 17465 17398 0 15:57 pts/0 00:00:00 grep ssh列出目前所有的正在内存当中的程序123456789101112# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.0 10368 676 ? Ss Nov02 0:00 init [3] root 2 0.0 0.0 0 0 ? S&lt; Nov02 0:01 [migration/0]root 3 0.0 0.0 0 0 ? SN Nov02 0:00 [ksoftirqd/0]root 4 0.0 0.0 0 0 ? S&lt; Nov02 0:01 [migration/1]root 5 0.0 0.0 0 0 ? SN Nov02 0:00 [ksoftirqd/1]root 6 0.0 0.0 0 0 ? S&lt; Nov02 29:57 [events/0]root 7 0.0 0.0 0 0 ? S&lt; Nov02 0:00 [events/1]root 8 0.0 0.0 0 0 ? S&lt; Nov02 0:00 ……省略部分结果ps aux可以显示进程占用CPU和内存情况。","categories":[{"name":"Linux","slug":"linux","permalink":"https://maoyunfei.github.io/categories/linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"https://maoyunfei.github.io/tags/Linux命令/"}]},{"title":"Linux grep命令","slug":"linux/linux command/grep","date":"2018-01-02T16:00:00.000Z","updated":"2018-03-04T09:52:45.664Z","comments":true,"path":"linux/b177a18e/","link":"","permalink":"https://maoyunfei.github.io/linux/b177a18e/","excerpt":"Linux grep命令用于查找文件里符合条件的字符串。若不指定任何文件名称，或是所给予的文件名为“-”，则grep指令会从标准输入设备读取数据。","text":"Linux grep命令用于查找文件里符合条件的字符串。若不指定任何文件名称，或是所给予的文件名为“-”，则grep指令会从标准输入设备读取数据。语法grep [-abcEFGhHilLnqrsvVwxy][-A&lt;显示列数&gt;][-B&lt;显示列数&gt;][-C&lt;显示列数&gt;][-d&lt;进行动作&gt;][-e&lt;范本样式&gt;][-f&lt;范本文件&gt;][--help][范本样式][文件或目录...]参数-a或–text 不要忽略二进制的数据。-A&lt;显示列数&gt;或–after-context=&lt;显示列数&gt; 除了显示符合范本样式的那一列之外，并显示该列之后的内容。-b或–byte-offset 在显示符合范本样式的那一列之前，标示出该列第一个字符的位编号。-B&lt;显示列数&gt;或–before-context=&lt;显示列数&gt; 除了显示符合范本样式的那一列之外，并显示该列之前的内容。-c或–count 计算符合范本样式的列数。-C&lt;显示列数&gt;或–context=&lt;显示列数&gt;或-&lt;显示列数&gt; 除了显示符合范本样式的那一列之外，并显示该列之前后的内容。-d&lt;进行动作&gt;或–directories=&lt;进行动作&gt; 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。-e&lt;范本样式&gt;或–regexp=&lt;范本样式&gt; 指定字符串做为查找文件内容的范本样式。-E或–extended-regexp 将范本样式为延伸的普通表示法来使用。-f&lt;范本文件&gt;或–file=&lt;范本文件&gt; 指定范本文件，其内容含有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每列一个范本样式。-F或–fixed-regexp 将范本样式视为固定字符串的列表。-G或–basic-regexp 将范本样式视为普通的表示法来使用。-h或–no-filename 在显示符合范本样式的那一列之前，不标示该列所属的文件名称。-H或–with-filename 在显示符合范本样式的那一列之前，表示该列所属的文件名称。-i或–ignore-case 忽略字符大小写的差别。-l或–file-with-matches 列出文件内容符合指定的范本样式的文件名称。-L或–files-without-match 列出文件内容不符合指定的范本样式的文件名称。-n或–line-number 在显示符合范本样式的那一列之前，标示出该列的列数编号。-o 输出每一行中所有符合条件的内容-q或–quiet或–silent 不显示任何信息。-r或–recursive 此参数的效果和指定”-d recurse”参数相同。-s或–no-messages 不显示错误信息。-v或–revert-match 反转查找。-V或–version 显示版本信息。-w或–word-regexp 只显示全字符合的列。-x或–line-regexp 只显示全列符合的列。-y 此参数的效果和指定”-i”参数相同。–help 在线帮助。实例12345$ grep test test* #查找后缀有“test”的文件包含“test”字符串的文件 testfile1:This a Linux testfile! #列出testfile1 文件中包含test字符的行 testfile_2:This is a linux testfile! #列出testfile_2 文件中包含test字符的行 testfile_2:Linux test #列出testfile_2 文件中包含test字符的行1234567$ grep -r update /etc/acpi #以递归的方式查找“etc/acpi”下包含“update”的文件 /etc/acpi/ac.d/85-anacron.sh:# (Things like the slocate updatedb cause a lot of IO.) Rather than /etc/acpi/resume.d/85-anacron.sh:# (Things like the slocate updatedb cause a lot of IO.) Rather than /etc/acpi/events/thinkpad-cmos:action=/usr/sbin/thinkpad-keys--update12345678910$ grep -v test *test* #查找文件名中包含test 的文件中不包含test的行testfile1:helLinux! testfile1:Linis a free Unix-type operating system. testfile1:Lin testfile_1:HELLO LINUX! testfile_1:LINUX IS A FREE UNIX-TYPE OPTERATING SYSTEM. testfile_1:THIS IS A LINUX TESTFILE! testfile_2:HELLO LINUX! testfile_2:Linux is a free unix-type opterating system.","categories":[{"name":"Linux","slug":"linux","permalink":"https://maoyunfei.github.io/categories/linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"https://maoyunfei.github.io/tags/Linux命令/"}]},{"title":"Linux dig 命令","slug":"linux/linux command/dig","date":"2018-01-01T16:00:00.000Z","updated":"2018-03-04T09:52:45.667Z","comments":true,"path":"linux/152528eb/","link":"","permalink":"https://maoyunfei.github.io/linux/152528eb/","excerpt":"dig是域信息检索器的简称(Domain Information Groper)，可以执行查询域名相关的任务。","text":"dig是域信息检索器的简称(Domain Information Groper)，可以执行查询域名相关的任务。语法dig [选项参数] {domian}示例一：dig www.baidu.com示例二：+short 输出精简答复dig www.baidu.com +short示例三：+trace 追踪DNS解析过程dig www.baidu.com +trace","categories":[{"name":"Linux","slug":"linux","permalink":"https://maoyunfei.github.io/categories/linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"https://maoyunfei.github.io/tags/Linux命令/"}]},{"title":"Linux awk 命令","slug":"linux/linux command/awk","date":"2017-12-31T16:00:00.000Z","updated":"2018-03-04T09:52:45.666Z","comments":true,"path":"linux/c0a16f03/","link":"","permalink":"https://maoyunfei.github.io/linux/c0a16f03/","excerpt":"原文链接AWK是一种处理文本文件的语言，是一个强大的文本分析工具。之所以叫AWK是因为其取了三位创始人Alfred Aho，Peter Weinberger, 和 Brian Kernighan 的Family Name的首字符。","text":"原文链接AWK是一种处理文本文件的语言，是一个强大的文本分析工具。之所以叫AWK是因为其取了三位创始人Alfred Aho，Peter Weinberger, 和 Brian Kernighan 的Family Name的首字符。语法123awk [选项参数] &apos;script&apos; var=value file(s)或awk [选项参数] -f scriptfile var=value file(s)常用选项参数说明-F fs指定输入文件的分隔符，fs是一个字符串或者是一个正则表达式，如-F:。-V var=value赋值一个用户定义变量-f scripfile从脚本文件中读取awk命令。基本用法log.txt文本内容如下：12342 this is a test3 Are you like awkThis&apos;s a test10 There are orange,apple,mongo用法一awk ‘{[pattern] action}’ {filenames} # 行匹配语句 awk ‘’ 只能用单引号实例：123456789101112131415# 每行按空格或TAB分割，输出文本中的1、4项 $ awk &apos;&#123;print $1,$4&#125;&apos; log.txt --------------------------------------------- 2 a 3 like This&apos;s 10 orange,apple,mongo # 格式化输出 $ awk &apos;&#123;printf &quot;%-8s %-10s\\n&quot;,$1,$4&#125;&apos; log.txt --------------------------------------------- 2 a 3 like This&apos;s 10 orange,apple,mongo用法二awk -F #-F相当于内置变量FS, 指定分割字符实例：1234567891011121314151617181920212223# 使用&quot;,&quot;分割 $ awk -F, &apos;&#123;print $1,$2&#125;&apos; log.txt --------------------------------------------- 2 this is a test 3 Are you like awk This&apos;s a test 10 There are orange apple # 或者使用内建变量 $ awk &apos;BEGIN&#123;FS=&quot;,&quot;&#125; &#123;print $1,$2&#125;&apos; log.txt --------------------------------------------- 2 this is a test 3 Are you like awk This&apos;s a test 10 There are orange apple # 使用多个分隔符.先使用空格分割，然后对分割结果再使用&quot;,&quot;分割 $ awk -F &apos;[ ,]&apos; &apos;&#123;print $1,$2,$5&#125;&apos; log.txt --------------------------------------------- 2 this test 3 Are awk This&apos;s a 10 There apple用法三awk -v # 设置变量实例：12345678910111213$ awk -va=1 &apos;&#123;print $1,$1+a&#125;&apos; log.txt --------------------------------------------- 2 3 3 4 This&apos;s 1 10 11 $ awk -va=1 -vb=s &apos;&#123;print $1,$1+a,$1b&#125;&apos; log.txt --------------------------------------------- 2 3 2s 3 4 3s This&apos;s 1 This&apos;ss 10 11 10s用法四awk -f {awk脚本} {文件名}实例：$ awk -f cal.awk log.txt运算符运算符描述= += -= *= /= %= ^= **=赋值?:C条件表达式||逻辑或&amp;&amp;逻辑与~ ~!匹配正则表达式和不匹配正则表达式&lt; &lt;= &gt; &gt;= != ==关系运算符空格连接+ -加，减* / %乘，除与求余+ - !一元加，减和逻辑非^ ***求幂++ –增加或减少，作为前缀或后缀$字段引用in数组成员过滤第一列大于2的行12345$ awk &apos;$1&gt;2&apos; log.txt #命令#输出3 Are you like awkThis&apos;s a test10 There are orange,apple,mongo过滤第一列等于2的行123$ awk &apos;$1==2 &#123;print $1,$3&#125;&apos; log.txt #命令#输出2 is过滤第一列大于2并且第二列等于’Are’的行123$ awk &apos;$1&gt;2 &amp;&amp; $2==&quot;Are&quot; &#123;print $1,$2,$3&#125;&apos; log.txt #命令#输出3 Are you内置变量变量描述\\$n当前记录的第n个字段，字段间由FS分隔\\$0完整的输入记录ARGC命令行参数的数目ARGIND命令行中当前文件的位置(从0开始算)ARGV包含命令行参数的数组CONVFMT数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组ERRNO最后一个系统错误的描述FIELDWIDTHS字段宽度列表(用空格键分隔)FILENAME当前文件名FNR各文件分别计数的行号FS字段分隔符(默认是任何空格)IGNORECASE如果为真，则进行忽略大小写的匹配NF输入字段分割符NR已经读出的记录数，就是行号，从1开始OFMT数字的输出格式(默认值是%.6g)OFS输出记录分隔符（输出换行符），输出时用指定的符号代替换行符ORS输出记录分隔符(默认值是一个换行符)RLENGTH由match函数所匹配的字符串的长度RS记录分隔符(默认是一个换行符)RSTART由match函数所匹配的字符串的第一个位置SUBSEP数组下标分隔符(默认值是/034)使用正则，字符串匹配1234# 输出第二列包含 &quot;th&quot;，并打印第二列与第四列$ awk &apos;$2 ~ /th/ &#123;print $2,$4&#125;&apos; log.txt---------------------------------------------this a~ 表示模式开始。//中是模式12345# 输出包含&quot;re&quot; 的行$ awk &apos;/re/ &apos; log.txt---------------------------------------------3 Are you like awk10 There are orange,apple,mongo忽略大小写1234$ awk &apos;BEGIN&#123;IGNORECASE=1&#125; /this/&apos; log.txt---------------------------------------------2 this is a testThis&apos;s a test模式取反1234567891011$ awk &apos;$2 !~ /th/ &#123;print $2,$4&#125;&apos; log.txt---------------------------------------------Are likeaThere orange,apple,mongo$ awk &apos;!/th/ &#123;print $2,$4&#125;&apos; log.txt---------------------------------------------Are likeaThere orange,apple,mongoawk脚本关于awk脚本，我们需要注意两个关键词BEGIN和END。BEGIN{ 这里面放的是执行前的语句 }END {这里面放的是处理完所有的行后要执行的语句 }{这里面放的是处理每一行时要执行的语句}假设有这么一个文件（学生成绩表）：123456$ cat score.txtMarry 2143 78 84 77Jack 2321 66 78 45Tom 2122 48 77 71Mike 2537 87 97 95Bob 2415 40 57 62我们的awk脚本如下：123456789101112131415161718192021222324$ cat cal.awk#!/bin/awk -f#运行前BEGIN &#123; math = 0 english = 0 computer = 0 printf &quot;NAME NO. MATH ENGLISH COMPUTER TOTAL\\n&quot; printf &quot;---------------------------------------------\\n&quot;&#125;#运行中&#123; math+=$3 english+=$4 computer+=$5 printf &quot;%-6s %-6s %4d %8d %8d %8d\\n&quot;, $1, $2, $3,$4,$5, $3+$4+$5&#125;#运行后END &#123; printf &quot;---------------------------------------------\\n&quot; printf &quot; TOTAL:%10d %8d %8d \\n&quot;, math, english, computer printf &quot;AVERAGE:%10.2f %8.2f %8.2f\\n&quot;, math/NR, english/NR, computer/NR&#125;我们来看一下执行结果：1234567891011$ awk -f cal.awk score.txtNAME NO. MATH ENGLISH COMPUTER TOTAL---------------------------------------------Marry 2143 78 84 77 239Jack 2321 66 78 45 189Tom 2122 48 77 71 196Mike 2537 87 97 95 279Bob 2415 40 57 62 159--------------------------------------------- TOTAL: 319 393 350AVERAGE: 63.80 78.60 70.00","categories":[{"name":"Linux","slug":"linux","permalink":"https://maoyunfei.github.io/categories/linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"https://maoyunfei.github.io/tags/Linux命令/"}]}]}